{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01\n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon = 1\n",
    "        # the below epsilon decay rate has been calculated from the graph as shown at the end of the file\n",
    "        self.epsilon_decay = 0.9991\n",
    "        #self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state,env):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment\n",
    "        #print(\"Get Action state is \",state)\n",
    "        possible_actions_index,actions = env.requests(state) # Find possible action indexes and append 0\n",
    "        possible_actions_index.append(0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # explore: choose a random action from all possible actions\n",
    "            # Give a random action only amongst possible action\n",
    "            return random.sample(possible_actions_index,1)[0]\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state = state.reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state)\n",
    "            # Give action with max q_value only amongst possible action\n",
    "            return np.where(q_value[0] == np.max(np.array([q_value[0][i] for i in possible_actions_index])))[0][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state,done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state,done))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self,env):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                \n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                done.append(done_boolean)\n",
    "                update_output[i] = next_state\n",
    "                \n",
    "                # Write your code from here\n",
    "                \n",
    "            # 1. Predict the target from earlier model           \n",
    "            target = self.model.predict(update_input)\n",
    "            \n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "                \n",
    "                #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                # Find possible actions from next state\n",
    "                next_possible_actions_index,_ = env.requests(update_output[i])\n",
    "                next_possible_actions_index.append(0)\n",
    "                if not done[i]:\n",
    "                    # Only take the max q_value from valid actions from next state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(np.array([target_qval[i][j] for j in next_possible_actions_index]))\n",
    "                else:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                \n",
    "                \n",
    "        # 4. Fit your model and track the loss values\n",
    "            #print(\"Training Model\")\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            #print(\"Model Training Model\")\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State is  [2, 7, 3]\n",
      "episode 0, reward -73.0, memory_length 133, epsilon 0.9991, time 728.0, rides 132\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 1, reward -226.0, memory_length 248, epsilon 0.9982008099999999, time 734.0, rides 114\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 2, reward -462.0, memory_length 371, epsilon 0.9973024292709999, time 728.0, rides 122\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 3, reward -322.0, memory_length 512, epsilon 0.996404857084656, time 730.0, rides 140\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 4, reward -198.0, memory_length 643, epsilon 0.9955080927132798, time 729.0, rides 130\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 5, reward -141.0, memory_length 763, epsilon 0.9946121354298378, time 723.0, rides 119\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6, reward -69.0, memory_length 888, epsilon 0.993716984507951, time 738.0, rides 124\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7, reward -265.0, memory_length 1007, epsilon 0.9928226392218938, time 730.0, rides 118\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 8, reward -384.0, memory_length 1122, epsilon 0.9919290988465941, time 733.0, rides 114\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 9, reward -318.0, memory_length 1253, epsilon 0.9910363626576322, time 728.0, rides 130\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 10, reward -407.0, memory_length 1370, epsilon 0.9901444299312403, time 725.0, rides 116\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 11, reward -356.0, memory_length 1494, epsilon 0.9892532999443022, time 728.0, rides 123\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 12, reward -243.0, memory_length 1614, epsilon 0.9883629719743523, time 731.0, rides 119\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 13, reward -209.0, memory_length 1751, epsilon 0.9874734452995754, time 733.0, rides 136\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 14, reward -347.0, memory_length 1886, epsilon 0.9865847191988057, time 730.0, rides 134\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 15, reward -414.0, memory_length 2000, epsilon 0.9856967929515268, time 728.0, rides 132\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 16, reward -180.0, memory_length 2000, epsilon 0.9848096658378704, time 735.0, rides 129\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 17, reward -111.0, memory_length 2000, epsilon 0.9839233371386163, time 729.0, rides 133\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 18, reward -340.0, memory_length 2000, epsilon 0.9830378061351915, time 725.0, rides 120\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 19, reward -390.0, memory_length 2000, epsilon 0.9821530721096698, time 735.0, rides 118\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 20, reward -407.0, memory_length 2000, epsilon 0.9812691343447711, time 726.0, rides 125\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 21, reward -388.0, memory_length 2000, epsilon 0.9803859921238608, time 722.0, rides 123\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 22, reward -140.0, memory_length 2000, epsilon 0.9795036447309493, time 732.0, rides 119\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 23, reward -307.0, memory_length 2000, epsilon 0.9786220914506915, time 728.0, rides 126\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 24, reward -150.0, memory_length 2000, epsilon 0.9777413315683858, time 735.0, rides 117\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 25, reward -271.0, memory_length 2000, epsilon 0.9768613643699743, time 729.0, rides 121\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 26, reward -277.0, memory_length 2000, epsilon 0.9759821891420413, time 732.0, rides 123\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 27, reward 16.0, memory_length 2000, epsilon 0.9751038051718134, time 736.0, rides 121\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 28, reward -373.0, memory_length 2000, epsilon 0.9742262117471587, time 732.0, rides 119\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 29, reward -369.0, memory_length 2000, epsilon 0.9733494081565863, time 726.0, rides 136\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 30, reward -421.0, memory_length 2000, epsilon 0.9724733936892453, time 729.0, rides 123\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 31, reward -7.0, memory_length 2000, epsilon 0.971598167634925, time 729.0, rides 126\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 32, reward -355.0, memory_length 2000, epsilon 0.9707237292840536, time 731.0, rides 136\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 33, reward -459.0, memory_length 2000, epsilon 0.969850077927698, time 722.0, rides 134\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 34, reward -397.0, memory_length 2000, epsilon 0.968977212857563, time 728.0, rides 124\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 35, reward -445.0, memory_length 2000, epsilon 0.9681051333659911, time 734.0, rides 126\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 36, reward -433.0, memory_length 2000, epsilon 0.9672338387459617, time 723.0, rides 121\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 37, reward -116.0, memory_length 2000, epsilon 0.9663633282910903, time 732.0, rides 120\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 38, reward -298.0, memory_length 2000, epsilon 0.9654936012956283, time 730.0, rides 128\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 39, reward -196.0, memory_length 2000, epsilon 0.9646246570544622, time 726.0, rides 129\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 40, reward -153.0, memory_length 2000, epsilon 0.9637564948631132, time 728.0, rides 121\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 41, reward -91.0, memory_length 2000, epsilon 0.9628891140177364, time 724.0, rides 133\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 42, reward -181.0, memory_length 2000, epsilon 0.9620225138151204, time 735.0, rides 131\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 43, reward -287.0, memory_length 2000, epsilon 0.9611566935526867, time 727.0, rides 129\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 44, reward -393.0, memory_length 2000, epsilon 0.9602916525284894, time 728.0, rides 130\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 45, reward -430.0, memory_length 2000, epsilon 0.9594273900412137, time 730.0, rides 147\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 46, reward -287.0, memory_length 2000, epsilon 0.9585639053901766, time 730.0, rides 132\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 47, reward -426.0, memory_length 2000, epsilon 0.9577011978753254, time 726.0, rides 135\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 48, reward -157.0, memory_length 2000, epsilon 0.9568392667972375, time 737.0, rides 124\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 49, reward -230.0, memory_length 2000, epsilon 0.95597811145712, time 735.0, rides 131\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 50, reward -270.0, memory_length 2000, epsilon 0.9551177311568085, time 723.0, rides 133\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 51, reward -171.0, memory_length 2000, epsilon 0.9542581251987674, time 734.0, rides 129\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 52, reward -303.0, memory_length 2000, epsilon 0.9533992928860885, time 736.0, rides 125\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 53, reward -328.0, memory_length 2000, epsilon 0.952541233522491, time 731.0, rides 135\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 54, reward -262.0, memory_length 2000, epsilon 0.9516839464123207, time 729.0, rides 124\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 55, reward -143.0, memory_length 2000, epsilon 0.9508274308605495, time 727.0, rides 121\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 56, reward -319.0, memory_length 2000, epsilon 0.949971686172775, time 738.0, rides 127\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 57, reward -335.0, memory_length 2000, epsilon 0.9491167116552195, time 732.0, rides 117\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 58, reward 1.0, memory_length 2000, epsilon 0.9482625066147298, time 737.0, rides 127\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 59, reward -503.0, memory_length 2000, epsilon 0.9474090703587765, time 724.0, rides 125\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 60, reward -271.0, memory_length 2000, epsilon 0.9465564021954537, time 728.0, rides 121\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 61, reward -584.0, memory_length 2000, epsilon 0.9457045014334777, time 738.0, rides 118\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 62, reward -431.0, memory_length 2000, epsilon 0.9448533673821876, time 729.0, rides 120\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 63, reward -360.0, memory_length 2000, epsilon 0.9440029993515436, time 745.0, rides 123\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 64, reward -298.0, memory_length 2000, epsilon 0.9431533966521273, time 731.0, rides 134\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 65, reward -441.0, memory_length 2000, epsilon 0.9423045585951404, time 732.0, rides 127\n",
      "Initial State is  [2, 20, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 66, reward -62.0, memory_length 2000, epsilon 0.9414564844924047, time 729.0, rides 129\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 67, reward -274.0, memory_length 2000, epsilon 0.9406091736563615, time 725.0, rides 121\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 68, reward -290.0, memory_length 2000, epsilon 0.9397626254000708, time 743.0, rides 127\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 69, reward -162.0, memory_length 2000, epsilon 0.9389168390372108, time 728.0, rides 123\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 70, reward -233.0, memory_length 2000, epsilon 0.9380718138820773, time 723.0, rides 123\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 71, reward -346.0, memory_length 2000, epsilon 0.9372275492495834, time 729.0, rides 134\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 72, reward -187.0, memory_length 2000, epsilon 0.9363840444552588, time 726.0, rides 123\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 73, reward -132.0, memory_length 2000, epsilon 0.9355412988152491, time 731.0, rides 138\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 74, reward -402.0, memory_length 2000, epsilon 0.9346993116463154, time 731.0, rides 124\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 75, reward -91.0, memory_length 2000, epsilon 0.9338580822658337, time 733.0, rides 144\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 76, reward -116.0, memory_length 2000, epsilon 0.9330176099917944, time 734.0, rides 124\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 77, reward -173.0, memory_length 2000, epsilon 0.9321778941428017, time 726.0, rides 138\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 78, reward -455.0, memory_length 2000, epsilon 0.9313389340380732, time 724.0, rides 127\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 79, reward -437.0, memory_length 2000, epsilon 0.930500728997439, time 734.0, rides 123\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 80, reward -153.0, memory_length 2000, epsilon 0.9296632783413412, time 728.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 81, reward -436.0, memory_length 2000, epsilon 0.928826581390834, time 725.0, rides 117\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 82, reward -518.0, memory_length 2000, epsilon 0.9279906374675821, time 734.0, rides 130\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 83, reward -149.0, memory_length 2000, epsilon 0.9271554458938613, time 729.0, rides 130\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 84, reward -65.0, memory_length 2000, epsilon 0.9263210059925568, time 735.0, rides 132\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 85, reward -137.0, memory_length 2000, epsilon 0.9254873170871636, time 737.0, rides 124\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 86, reward -325.0, memory_length 2000, epsilon 0.9246543785017851, time 721.0, rides 131\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 87, reward -21.0, memory_length 2000, epsilon 0.9238221895611335, time 733.0, rides 136\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 88, reward -441.0, memory_length 2000, epsilon 0.9229907495905284, time 727.0, rides 123\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 89, reward -259.0, memory_length 2000, epsilon 0.922160057915897, time 730.0, rides 126\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 90, reward -223.0, memory_length 2000, epsilon 0.9213301138637726, time 723.0, rides 131\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 91, reward -306.0, memory_length 2000, epsilon 0.9205009167612952, time 732.0, rides 137\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 92, reward -161.0, memory_length 2000, epsilon 0.91967246593621, time 735.0, rides 124\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 93, reward -77.0, memory_length 2000, epsilon 0.9188447607168674, time 724.0, rides 123\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 94, reward -36.0, memory_length 2000, epsilon 0.9180178004322221, time 728.0, rides 110\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 95, reward -16.0, memory_length 2000, epsilon 0.9171915844118331, time 735.0, rides 123\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 96, reward 4.0, memory_length 2000, epsilon 0.9163661119858625, time 729.0, rides 122\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 97, reward -267.0, memory_length 2000, epsilon 0.9155413824850752, time 731.0, rides 130\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 98, reward 21.0, memory_length 2000, epsilon 0.9147173952408386, time 730.0, rides 121\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 99, reward -283.0, memory_length 2000, epsilon 0.9138941495851218, time 733.0, rides 118\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 100, reward -380.0, memory_length 2000, epsilon 0.9130716448504952, time 725.0, rides 117\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 101, reward -62.0, memory_length 2000, epsilon 0.9122498803701298, time 728.0, rides 122\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 102, reward -356.0, memory_length 2000, epsilon 0.9114288554777966, time 741.0, rides 128\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 103, reward -49.0, memory_length 2000, epsilon 0.9106085695078666, time 723.0, rides 125\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 104, reward -308.0, memory_length 2000, epsilon 0.9097890217953095, time 724.0, rides 115\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 105, reward -222.0, memory_length 2000, epsilon 0.9089702116756937, time 727.0, rides 132\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 106, reward -55.0, memory_length 2000, epsilon 0.9081521384851856, time 729.0, rides 124\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 107, reward -214.0, memory_length 2000, epsilon 0.9073348015605489, time 726.0, rides 140\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 108, reward -110.0, memory_length 2000, epsilon 0.9065182002391444, time 731.0, rides 129\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 109, reward -116.0, memory_length 2000, epsilon 0.9057023338589292, time 723.0, rides 119\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 110, reward -369.0, memory_length 2000, epsilon 0.9048872017584562, time 723.0, rides 133\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 111, reward -140.0, memory_length 2000, epsilon 0.9040728032768736, time 734.0, rides 136\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 112, reward -29.0, memory_length 2000, epsilon 0.9032591377539244, time 733.0, rides 128\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 113, reward 178.0, memory_length 2000, epsilon 0.9024462045299458, time 728.0, rides 121\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 114, reward -331.0, memory_length 2000, epsilon 0.9016340029458689, time 726.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 115, reward -196.0, memory_length 2000, epsilon 0.9008225323432176, time 725.0, rides 116\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 116, reward -344.0, memory_length 2000, epsilon 0.9000117920641088, time 723.0, rides 137\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 117, reward -76.0, memory_length 2000, epsilon 0.8992017814512511, time 722.0, rides 131\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 118, reward -58.0, memory_length 2000, epsilon 0.8983924998479449, time 728.0, rides 124\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 119, reward 12.0, memory_length 2000, epsilon 0.8975839465980817, time 732.0, rides 123\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 120, reward -120.0, memory_length 2000, epsilon 0.8967761210461435, time 725.0, rides 128\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 121, reward -18.0, memory_length 2000, epsilon 0.8959690225372019, time 731.0, rides 117\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 122, reward -278.0, memory_length 2000, epsilon 0.8951626504169184, time 736.0, rides 118\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 123, reward -306.0, memory_length 2000, epsilon 0.8943570040315432, time 729.0, rides 133\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 124, reward -8.0, memory_length 2000, epsilon 0.8935520827279148, time 726.0, rides 119\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 125, reward 73.0, memory_length 2000, epsilon 0.8927478858534597, time 727.0, rides 117\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 126, reward -200.0, memory_length 2000, epsilon 0.8919444127561915, time 730.0, rides 125\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 127, reward -55.0, memory_length 2000, epsilon 0.891141662784711, time 725.0, rides 131\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 128, reward -119.0, memory_length 2000, epsilon 0.8903396352882047, time 725.0, rides 128\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 129, reward -358.0, memory_length 2000, epsilon 0.8895383296164453, time 734.0, rides 128\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 130, reward -366.0, memory_length 2000, epsilon 0.8887377451197905, time 724.0, rides 138\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 131, reward -297.0, memory_length 2000, epsilon 0.8879378811491827, time 724.0, rides 125\n",
      "Initial State is  [2, 7, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 132, reward -156.0, memory_length 2000, epsilon 0.8871387370561484, time 729.0, rides 131\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 133, reward 30.0, memory_length 2000, epsilon 0.8863403121927979, time 728.0, rides 144\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 134, reward 106.0, memory_length 2000, epsilon 0.8855426059118243, time 729.0, rides 122\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 135, reward -89.0, memory_length 2000, epsilon 0.8847456175665037, time 736.0, rides 119\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 136, reward 132.0, memory_length 2000, epsilon 0.8839493465106939, time 737.0, rides 129\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 137, reward -63.0, memory_length 2000, epsilon 0.8831537920988343, time 723.0, rides 122\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 138, reward -94.0, memory_length 2000, epsilon 0.8823589536859453, time 728.0, rides 135\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 139, reward -156.0, memory_length 2000, epsilon 0.8815648306276279, time 730.0, rides 126\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 140, reward -39.0, memory_length 2000, epsilon 0.880771422280063, time 728.0, rides 132\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 141, reward -101.0, memory_length 2000, epsilon 0.879978728000011, time 726.0, rides 111\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 142, reward -69.0, memory_length 2000, epsilon 0.8791867471448109, time 727.0, rides 122\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 143, reward -345.0, memory_length 2000, epsilon 0.8783954790723806, time 738.0, rides 136\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 144, reward -223.0, memory_length 2000, epsilon 0.8776049231412154, time 733.0, rides 130\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 145, reward -212.0, memory_length 2000, epsilon 0.8768150787103883, time 729.0, rides 145\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 146, reward -304.0, memory_length 2000, epsilon 0.876025945139549, time 727.0, rides 130\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 147, reward -3.0, memory_length 2000, epsilon 0.8752375217889234, time 726.0, rides 137\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 148, reward -73.0, memory_length 2000, epsilon 0.8744498080193134, time 729.0, rides 118\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 149, reward -278.0, memory_length 2000, epsilon 0.873662803192096, time 734.0, rides 133\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 150, reward -294.0, memory_length 2000, epsilon 0.8728765066692231, time 731.0, rides 145\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 151, reward -23.0, memory_length 2000, epsilon 0.8720909178132208, time 730.0, rides 119\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 152, reward -317.0, memory_length 2000, epsilon 0.8713060359871889, time 737.0, rides 130\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 153, reward -75.0, memory_length 2000, epsilon 0.8705218605548004, time 731.0, rides 136\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 154, reward -444.0, memory_length 2000, epsilon 0.869738390880301, time 721.0, rides 122\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 155, reward 244.0, memory_length 2000, epsilon 0.8689556263285088, time 729.0, rides 122\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 156, reward -284.0, memory_length 2000, epsilon 0.8681735662648131, time 731.0, rides 127\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 157, reward -2.0, memory_length 2000, epsilon 0.8673922100551748, time 735.0, rides 120\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 158, reward -301.0, memory_length 2000, epsilon 0.8666115570661251, time 735.0, rides 118\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 159, reward -213.0, memory_length 2000, epsilon 0.8658316066647657, time 725.0, rides 126\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 160, reward -296.0, memory_length 2000, epsilon 0.8650523582187674, time 728.0, rides 137\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 161, reward -274.0, memory_length 2000, epsilon 0.8642738110963705, time 733.0, rides 120\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 162, reward -169.0, memory_length 2000, epsilon 0.8634959646663837, time 722.0, rides 128\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 163, reward -297.0, memory_length 2000, epsilon 0.8627188182981839, time 725.0, rides 126\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 164, reward 371.0, memory_length 2000, epsilon 0.8619423713617155, time 729.0, rides 123\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 165, reward -184.0, memory_length 2000, epsilon 0.8611666232274899, time 731.0, rides 122\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 166, reward -28.0, memory_length 2000, epsilon 0.8603915732665852, time 732.0, rides 126\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 167, reward -275.0, memory_length 2000, epsilon 0.8596172208506453, time 729.0, rides 140\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 168, reward -35.0, memory_length 2000, epsilon 0.8588435653518797, time 722.0, rides 120\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 169, reward -201.0, memory_length 2000, epsilon 0.858070606143063, time 734.0, rides 116\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 170, reward -148.0, memory_length 2000, epsilon 0.8572983425975342, time 734.0, rides 117\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 171, reward -420.0, memory_length 2000, epsilon 0.8565267740891964, time 732.0, rides 115\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 172, reward -56.0, memory_length 2000, epsilon 0.8557558999925161, time 732.0, rides 135\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 173, reward -174.0, memory_length 2000, epsilon 0.8549857196825228, time 729.0, rides 139\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 174, reward 19.0, memory_length 2000, epsilon 0.8542162325348085, time 727.0, rides 131\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 175, reward -301.0, memory_length 2000, epsilon 0.8534474379255271, time 726.0, rides 129\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 176, reward -344.0, memory_length 2000, epsilon 0.8526793352313942, time 721.0, rides 130\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 177, reward -51.0, memory_length 2000, epsilon 0.851911923829686, time 722.0, rides 129\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 178, reward -293.0, memory_length 2000, epsilon 0.8511452030982393, time 728.0, rides 139\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 179, reward 6.0, memory_length 2000, epsilon 0.8503791724154508, time 727.0, rides 123\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 180, reward -190.0, memory_length 2000, epsilon 0.8496138311602769, time 730.0, rides 118\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 181, reward -125.0, memory_length 2000, epsilon 0.8488491787122326, time 734.0, rides 144\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 182, reward -325.0, memory_length 2000, epsilon 0.8480852144513916, time 728.0, rides 119\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 183, reward 147.0, memory_length 2000, epsilon 0.8473219377583854, time 726.0, rides 126\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 184, reward -140.0, memory_length 2000, epsilon 0.8465593480144028, time 722.0, rides 126\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 185, reward -359.0, memory_length 2000, epsilon 0.8457974446011898, time 728.0, rides 128\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 186, reward -310.0, memory_length 2000, epsilon 0.8450362269010487, time 732.0, rides 125\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 187, reward 195.0, memory_length 2000, epsilon 0.8442756942968378, time 732.0, rides 133\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 188, reward -178.0, memory_length 2000, epsilon 0.8435158461719706, time 728.0, rides 142\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 189, reward -245.0, memory_length 2000, epsilon 0.8427566819104159, time 725.0, rides 118\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 190, reward -468.0, memory_length 2000, epsilon 0.8419982008966965, time 733.0, rides 126\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 191, reward -81.0, memory_length 2000, epsilon 0.8412404025158895, time 725.0, rides 136\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 192, reward -259.0, memory_length 2000, epsilon 0.8404832861536252, time 727.0, rides 133\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 193, reward -74.0, memory_length 2000, epsilon 0.8397268511960869, time 731.0, rides 124\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 194, reward -441.0, memory_length 2000, epsilon 0.8389710970300104, time 725.0, rides 117\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 195, reward -340.0, memory_length 2000, epsilon 0.8382160230426834, time 724.0, rides 141\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 196, reward -456.0, memory_length 2000, epsilon 0.837461628621945, time 729.0, rides 129\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 197, reward -85.0, memory_length 2000, epsilon 0.8367079131561852, time 732.0, rides 127\n",
      "Initial State is  [3, 11, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 198, reward 97.0, memory_length 2000, epsilon 0.8359548760343446, time 726.0, rides 129\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 199, reward 1.0, memory_length 2000, epsilon 0.8352025166459137, time 723.0, rides 133\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 200, reward -184.0, memory_length 2000, epsilon 0.8344508343809324, time 729.0, rides 129\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 201, reward -407.0, memory_length 2000, epsilon 0.8336998286299895, time 726.0, rides 123\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 202, reward -289.0, memory_length 2000, epsilon 0.8329494987842225, time 735.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 203, reward -369.0, memory_length 2000, epsilon 0.8321998442353167, time 736.0, rides 131\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 204, reward -198.0, memory_length 2000, epsilon 0.8314508643755049, time 727.0, rides 128\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 205, reward -473.0, memory_length 2000, epsilon 0.8307025585975669, time 730.0, rides 125\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 206, reward -244.0, memory_length 2000, epsilon 0.8299549262948291, time 730.0, rides 130\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 207, reward -210.0, memory_length 2000, epsilon 0.8292079668611638, time 727.0, rides 112\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 208, reward -256.0, memory_length 2000, epsilon 0.8284616796909887, time 736.0, rides 133\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 209, reward -58.0, memory_length 2000, epsilon 0.8277160641792668, time 726.0, rides 130\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 210, reward -136.0, memory_length 2000, epsilon 0.8269711197215055, time 729.0, rides 128\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 211, reward -54.0, memory_length 2000, epsilon 0.8262268457137562, time 733.0, rides 118\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 212, reward -243.0, memory_length 2000, epsilon 0.8254832415526138, time 734.0, rides 132\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 213, reward -131.0, memory_length 2000, epsilon 0.8247403066352164, time 732.0, rides 126\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 214, reward -307.0, memory_length 2000, epsilon 0.8239980403592446, time 728.0, rides 121\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 215, reward -35.0, memory_length 2000, epsilon 0.8232564421229213, time 732.0, rides 120\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 216, reward -356.0, memory_length 2000, epsilon 0.8225155113250107, time 724.0, rides 125\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 217, reward -499.0, memory_length 2000, epsilon 0.8217752473648181, time 733.0, rides 122\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 218, reward -99.0, memory_length 2000, epsilon 0.8210356496421898, time 725.0, rides 137\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 219, reward -183.0, memory_length 2000, epsilon 0.8202967175575118, time 725.0, rides 140\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 220, reward -116.0, memory_length 2000, epsilon 0.81955845051171, time 728.0, rides 116\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 221, reward -254.0, memory_length 2000, epsilon 0.8188208479062494, time 731.0, rides 118\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 222, reward 3.0, memory_length 2000, epsilon 0.8180839091431338, time 733.0, rides 129\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 223, reward -160.0, memory_length 2000, epsilon 0.8173476336249049, time 732.0, rides 128\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 224, reward -208.0, memory_length 2000, epsilon 0.8166120207546425, time 730.0, rides 120\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 225, reward -347.0, memory_length 2000, epsilon 0.8158770699359633, time 724.0, rides 119\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 226, reward -131.0, memory_length 2000, epsilon 0.8151427805730209, time 725.0, rides 134\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 227, reward -168.0, memory_length 2000, epsilon 0.8144091520705052, time 735.0, rides 130\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 228, reward -342.0, memory_length 2000, epsilon 0.8136761838336418, time 730.0, rides 135\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 229, reward -135.0, memory_length 2000, epsilon 0.8129438752681916, time 726.0, rides 127\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 230, reward -195.0, memory_length 2000, epsilon 0.8122122257804502, time 730.0, rides 124\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 231, reward -208.0, memory_length 2000, epsilon 0.8114812347772478, time 733.0, rides 116\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 232, reward 68.0, memory_length 2000, epsilon 0.8107509016659482, time 726.0, rides 119\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 233, reward 20.0, memory_length 2000, epsilon 0.8100212258544488, time 730.0, rides 114\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 234, reward -363.0, memory_length 2000, epsilon 0.8092922067511797, time 728.0, rides 129\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 235, reward -48.0, memory_length 2000, epsilon 0.8085638437651037, time 728.0, rides 111\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 236, reward -170.0, memory_length 2000, epsilon 0.8078361363057152, time 730.0, rides 124\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 237, reward -323.0, memory_length 2000, epsilon 0.80710908378304, time 727.0, rides 127\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 238, reward -180.0, memory_length 2000, epsilon 0.8063826856076353, time 732.0, rides 130\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 239, reward -85.0, memory_length 2000, epsilon 0.8056569411905884, time 726.0, rides 124\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 240, reward 139.0, memory_length 2000, epsilon 0.8049318499435169, time 734.0, rides 131\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 241, reward 79.0, memory_length 2000, epsilon 0.8042074112785677, time 727.0, rides 139\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 242, reward -105.0, memory_length 2000, epsilon 0.8034836246084169, time 733.0, rides 138\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 243, reward -226.0, memory_length 2000, epsilon 0.8027604893462693, time 734.0, rides 139\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 244, reward -346.0, memory_length 2000, epsilon 0.8020380049058576, time 728.0, rides 135\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 245, reward -46.0, memory_length 2000, epsilon 0.8013161707014423, time 728.0, rides 119\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 246, reward -250.0, memory_length 2000, epsilon 0.800594986147811, time 730.0, rides 122\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 247, reward -295.0, memory_length 2000, epsilon 0.799874450660278, time 727.0, rides 126\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 248, reward -148.0, memory_length 2000, epsilon 0.7991545636546837, time 725.0, rides 131\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 249, reward -184.0, memory_length 2000, epsilon 0.7984353245473945, time 725.0, rides 119\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 250, reward 104.0, memory_length 2000, epsilon 0.7977167327553019, time 731.0, rides 129\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 251, reward -265.0, memory_length 2000, epsilon 0.7969987876958221, time 734.0, rides 134\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 252, reward 77.0, memory_length 2000, epsilon 0.7962814887868959, time 726.0, rides 124\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 253, reward -114.0, memory_length 2000, epsilon 0.7955648354469876, time 725.0, rides 127\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 254, reward -330.0, memory_length 2000, epsilon 0.7948488270950853, time 728.0, rides 128\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 255, reward -72.0, memory_length 2000, epsilon 0.7941334631506998, time 721.0, rides 133\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 256, reward -86.0, memory_length 2000, epsilon 0.7934187430338642, time 732.0, rides 135\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 257, reward -31.0, memory_length 2000, epsilon 0.7927046661651337, time 726.0, rides 131\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 258, reward -301.0, memory_length 2000, epsilon 0.7919912319655851, time 737.0, rides 121\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 259, reward 23.0, memory_length 2000, epsilon 0.791278439856816, time 728.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 260, reward -116.0, memory_length 2000, epsilon 0.7905662892609449, time 723.0, rides 134\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 261, reward -56.0, memory_length 2000, epsilon 0.78985477960061, time 722.0, rides 128\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 262, reward -249.0, memory_length 2000, epsilon 0.7891439102989695, time 730.0, rides 124\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 263, reward -363.0, memory_length 2000, epsilon 0.7884336807797003, time 722.0, rides 132\n",
      "Initial State is  [3, 21, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 264, reward 101.0, memory_length 2000, epsilon 0.7877240904669985, time 730.0, rides 127\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 265, reward -17.0, memory_length 2000, epsilon 0.7870151387855783, time 729.0, rides 132\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 266, reward 11.0, memory_length 2000, epsilon 0.7863068251606713, time 723.0, rides 131\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 267, reward -42.0, memory_length 2000, epsilon 0.7855991490180266, time 731.0, rides 122\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 268, reward -303.0, memory_length 2000, epsilon 0.7848921097839104, time 736.0, rides 114\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 269, reward -242.0, memory_length 2000, epsilon 0.7841857068851049, time 733.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 270, reward 39.0, memory_length 2000, epsilon 0.7834799397489083, time 730.0, rides 138\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 271, reward 211.0, memory_length 2000, epsilon 0.7827748078031342, time 734.0, rides 131\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 272, reward -213.0, memory_length 2000, epsilon 0.7820703104761114, time 725.0, rides 125\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 273, reward 54.0, memory_length 2000, epsilon 0.7813664471966829, time 730.0, rides 128\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 274, reward 21.0, memory_length 2000, epsilon 0.7806632173942059, time 728.0, rides 130\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 275, reward -22.0, memory_length 2000, epsilon 0.7799606204985511, time 723.0, rides 132\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 276, reward -243.0, memory_length 2000, epsilon 0.7792586559401024, time 722.0, rides 129\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 277, reward -143.0, memory_length 2000, epsilon 0.7785573231497562, time 726.0, rides 129\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 278, reward -10.0, memory_length 2000, epsilon 0.7778566215589214, time 727.0, rides 125\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 279, reward -79.0, memory_length 2000, epsilon 0.7771565505995184, time 732.0, rides 129\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 280, reward -132.0, memory_length 2000, epsilon 0.7764571097039789, time 727.0, rides 120\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 281, reward -68.0, memory_length 2000, epsilon 0.7757582983052452, time 723.0, rides 120\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 282, reward -146.0, memory_length 2000, epsilon 0.7750601158367705, time 731.0, rides 136\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 283, reward -276.0, memory_length 2000, epsilon 0.7743625617325174, time 733.0, rides 127\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 284, reward -198.0, memory_length 2000, epsilon 0.7736656354269581, time 728.0, rides 117\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 285, reward -194.0, memory_length 2000, epsilon 0.7729693363550738, time 731.0, rides 125\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 286, reward -248.0, memory_length 2000, epsilon 0.7722736639523542, time 730.0, rides 116\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 287, reward -225.0, memory_length 2000, epsilon 0.7715786176547971, time 724.0, rides 131\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 288, reward -34.0, memory_length 2000, epsilon 0.7708841968989077, time 728.0, rides 122\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 289, reward -311.0, memory_length 2000, epsilon 0.7701904011216987, time 736.0, rides 124\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 290, reward 96.0, memory_length 2000, epsilon 0.7694972297606891, time 732.0, rides 133\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 291, reward -42.0, memory_length 2000, epsilon 0.7688046822539045, time 734.0, rides 132\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 292, reward -338.0, memory_length 2000, epsilon 0.768112758039876, time 730.0, rides 132\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 293, reward -181.0, memory_length 2000, epsilon 0.76742145655764, time 729.0, rides 125\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 294, reward -32.0, memory_length 2000, epsilon 0.7667307772467382, time 731.0, rides 131\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 295, reward -168.0, memory_length 2000, epsilon 0.7660407195472161, time 729.0, rides 134\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 296, reward -392.0, memory_length 2000, epsilon 0.7653512828996236, time 737.0, rides 124\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 297, reward -8.0, memory_length 2000, epsilon 0.7646624667450139, time 734.0, rides 125\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 298, reward -54.0, memory_length 2000, epsilon 0.7639742705249434, time 726.0, rides 118\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 299, reward -59.0, memory_length 2000, epsilon 0.763286693681471, time 728.0, rides 125\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 300, reward -206.0, memory_length 2000, epsilon 0.7625997356571577, time 735.0, rides 127\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 301, reward -181.0, memory_length 2000, epsilon 0.7619133958950662, time 735.0, rides 133\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 302, reward -309.0, memory_length 2000, epsilon 0.7612276738387607, time 725.0, rides 125\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 303, reward -300.0, memory_length 2000, epsilon 0.7605425689323058, time 733.0, rides 133\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 304, reward -153.0, memory_length 2000, epsilon 0.7598580806202667, time 740.0, rides 121\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 305, reward 46.0, memory_length 2000, epsilon 0.7591742083477084, time 726.0, rides 125\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 306, reward 71.0, memory_length 2000, epsilon 0.7584909515601955, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 307, reward -191.0, memory_length 2000, epsilon 0.7578083097037913, time 736.0, rides 131\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 308, reward -62.0, memory_length 2000, epsilon 0.7571262822250578, time 728.0, rides 126\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 309, reward 33.0, memory_length 2000, epsilon 0.7564448685710553, time 736.0, rides 129\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 310, reward 137.0, memory_length 2000, epsilon 0.7557640681893414, time 725.0, rides 119\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 311, reward 9.0, memory_length 2000, epsilon 0.7550838805279709, time 727.0, rides 124\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 312, reward 113.0, memory_length 2000, epsilon 0.7544043050354957, time 735.0, rides 143\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 313, reward 31.0, memory_length 2000, epsilon 0.7537253411609638, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 314, reward -67.0, memory_length 2000, epsilon 0.7530469883539189, time 731.0, rides 146\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 315, reward -201.0, memory_length 2000, epsilon 0.7523692460644004, time 723.0, rides 129\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 316, reward -62.0, memory_length 2000, epsilon 0.7516921137429424, time 724.0, rides 122\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 317, reward -236.0, memory_length 2000, epsilon 0.7510155908405738, time 735.0, rides 121\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 318, reward 138.0, memory_length 2000, epsilon 0.7503396768088173, time 729.0, rides 127\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 319, reward 234.0, memory_length 2000, epsilon 0.7496643710996893, time 727.0, rides 137\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 320, reward 83.0, memory_length 2000, epsilon 0.7489896731656995, time 735.0, rides 118\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 321, reward 58.0, memory_length 2000, epsilon 0.7483155824598504, time 732.0, rides 115\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 322, reward 119.0, memory_length 2000, epsilon 0.7476420984356366, time 724.0, rides 126\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 323, reward -105.0, memory_length 2000, epsilon 0.7469692205470445, time 724.0, rides 129\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 324, reward 143.0, memory_length 2000, epsilon 0.7462969482485522, time 723.0, rides 121\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 325, reward -162.0, memory_length 2000, epsilon 0.7456252809951285, time 731.0, rides 121\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 326, reward -22.0, memory_length 2000, epsilon 0.7449542182422328, time 722.0, rides 124\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 327, reward -285.0, memory_length 2000, epsilon 0.7442837594458148, time 737.0, rides 137\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 328, reward -133.0, memory_length 2000, epsilon 0.7436139040623135, time 735.0, rides 141\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 329, reward -88.0, memory_length 2000, epsilon 0.7429446515486574, time 723.0, rides 139\n",
      "Initial State is  [2, 17, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 330, reward -43.0, memory_length 2000, epsilon 0.7422760013622636, time 731.0, rides 140\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 331, reward -218.0, memory_length 2000, epsilon 0.7416079529610375, time 725.0, rides 128\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 332, reward -240.0, memory_length 2000, epsilon 0.7409405058033726, time 731.0, rides 117\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 333, reward -277.0, memory_length 2000, epsilon 0.7402736593481495, time 736.0, rides 117\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 334, reward -64.0, memory_length 2000, epsilon 0.7396074130547361, time 738.0, rides 141\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 335, reward -103.0, memory_length 2000, epsilon 0.7389417663829868, time 742.0, rides 129\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 336, reward -74.0, memory_length 2000, epsilon 0.7382767187932421, time 724.0, rides 142\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 337, reward 248.0, memory_length 2000, epsilon 0.7376122697463282, time 731.0, rides 125\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 338, reward 22.0, memory_length 2000, epsilon 0.7369484187035565, time 726.0, rides 128\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 339, reward 50.0, memory_length 2000, epsilon 0.7362851651267234, time 734.0, rides 122\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 340, reward -45.0, memory_length 2000, epsilon 0.7356225084781093, time 729.0, rides 135\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 341, reward -173.0, memory_length 2000, epsilon 0.734960448220479, time 733.0, rides 117\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 342, reward 21.0, memory_length 2000, epsilon 0.7342989838170806, time 737.0, rides 134\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 343, reward 112.0, memory_length 2000, epsilon 0.7336381147316452, time 726.0, rides 124\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 344, reward -67.0, memory_length 2000, epsilon 0.7329778404283868, time 727.0, rides 109\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 345, reward 116.0, memory_length 2000, epsilon 0.7323181603720013, time 730.0, rides 133\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 346, reward -9.0, memory_length 2000, epsilon 0.7316590740276665, time 726.0, rides 138\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 347, reward 128.0, memory_length 2000, epsilon 0.7310005808610416, time 727.0, rides 123\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 348, reward -252.0, memory_length 2000, epsilon 0.7303426803382667, time 736.0, rides 131\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 349, reward 18.0, memory_length 2000, epsilon 0.7296853719259622, time 727.0, rides 125\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 350, reward -44.0, memory_length 2000, epsilon 0.7290286550912288, time 729.0, rides 120\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 351, reward -145.0, memory_length 2000, epsilon 0.7283725293016468, time 726.0, rides 121\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 352, reward -213.0, memory_length 2000, epsilon 0.7277169940252752, time 725.0, rides 133\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 353, reward 7.0, memory_length 2000, epsilon 0.7270620487306525, time 733.0, rides 133\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 354, reward 161.0, memory_length 2000, epsilon 0.7264076928867949, time 735.0, rides 135\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 355, reward 80.0, memory_length 2000, epsilon 0.7257539259631968, time 726.0, rides 126\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 356, reward -102.0, memory_length 2000, epsilon 0.7251007474298299, time 736.0, rides 124\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 357, reward 97.0, memory_length 2000, epsilon 0.724448156757143, time 723.0, rides 134\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 358, reward -49.0, memory_length 2000, epsilon 0.7237961534160616, time 729.0, rides 120\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 359, reward -71.0, memory_length 2000, epsilon 0.7231447368779872, time 724.0, rides 145\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 360, reward 13.0, memory_length 2000, epsilon 0.722493906614797, time 727.0, rides 127\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 361, reward -284.0, memory_length 2000, epsilon 0.7218436620988437, time 732.0, rides 136\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 362, reward -152.0, memory_length 2000, epsilon 0.7211940028029546, time 733.0, rides 120\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 363, reward -247.0, memory_length 2000, epsilon 0.720544928200432, time 733.0, rides 138\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 364, reward 183.0, memory_length 2000, epsilon 0.7198964377650516, time 730.0, rides 119\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 365, reward -42.0, memory_length 2000, epsilon 0.7192485309710631, time 725.0, rides 144\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 366, reward 11.0, memory_length 2000, epsilon 0.7186012072931891, time 726.0, rides 133\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 367, reward -63.0, memory_length 2000, epsilon 0.7179544662066252, time 731.0, rides 111\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 368, reward 185.0, memory_length 2000, epsilon 0.7173083071870392, time 733.0, rides 110\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 369, reward -614.0, memory_length 2000, epsilon 0.7166627297105709, time 731.0, rides 117\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 370, reward -477.0, memory_length 2000, epsilon 0.7160177332538313, time 737.0, rides 120\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 371, reward -12.0, memory_length 2000, epsilon 0.7153733172939029, time 737.0, rides 130\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 372, reward 182.0, memory_length 2000, epsilon 0.7147294813083384, time 725.0, rides 135\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 373, reward 104.0, memory_length 2000, epsilon 0.7140862247751608, time 733.0, rides 130\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 374, reward -97.0, memory_length 2000, epsilon 0.7134435471728632, time 733.0, rides 131\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 375, reward -235.0, memory_length 2000, epsilon 0.7128014479804076, time 721.0, rides 127\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 376, reward -264.0, memory_length 2000, epsilon 0.7121599266772252, time 721.0, rides 145\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 377, reward 233.0, memory_length 2000, epsilon 0.7115189827432157, time 724.0, rides 139\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 378, reward 57.0, memory_length 2000, epsilon 0.7108786156587468, time 744.0, rides 125\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 379, reward -64.0, memory_length 2000, epsilon 0.7102388249046538, time 737.0, rides 138\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 380, reward 371.0, memory_length 2000, epsilon 0.7095996099622397, time 736.0, rides 137\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 381, reward -37.0, memory_length 2000, epsilon 0.7089609703132737, time 732.0, rides 109\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 382, reward 41.0, memory_length 2000, epsilon 0.7083229054399917, time 726.0, rides 111\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 383, reward 0.0, memory_length 2000, epsilon 0.7076854148250956, time 727.0, rides 118\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 384, reward -72.0, memory_length 2000, epsilon 0.7070484979517531, time 737.0, rides 123\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 385, reward -53.0, memory_length 2000, epsilon 0.7064121543035965, time 732.0, rides 131\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 386, reward -198.0, memory_length 2000, epsilon 0.7057763833647233, time 731.0, rides 131\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 387, reward 10.0, memory_length 2000, epsilon 0.705141184619695, time 721.0, rides 125\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 388, reward -153.0, memory_length 2000, epsilon 0.7045065575535373, time 728.0, rides 119\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 389, reward -55.0, memory_length 2000, epsilon 0.7038725016517391, time 737.0, rides 123\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 390, reward -59.0, memory_length 2000, epsilon 0.7032390164002525, time 724.0, rides 116\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 391, reward -2.0, memory_length 2000, epsilon 0.7026061012854923, time 729.0, rides 117\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 392, reward -9.0, memory_length 2000, epsilon 0.7019737557943353, time 729.0, rides 120\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 393, reward 229.0, memory_length 2000, epsilon 0.7013419794141204, time 727.0, rides 116\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 394, reward -124.0, memory_length 2000, epsilon 0.7007107716326476, time 728.0, rides 123\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 395, reward 153.0, memory_length 2000, epsilon 0.7000801319381782, time 725.0, rides 129\n",
      "Initial State is  [3, 14, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 396, reward 18.0, memory_length 2000, epsilon 0.6994500598194339, time 726.0, rides 115\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 397, reward 215.0, memory_length 2000, epsilon 0.6988205547655963, time 726.0, rides 115\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 398, reward -187.0, memory_length 2000, epsilon 0.6981916162663073, time 734.0, rides 123\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 399, reward -336.0, memory_length 2000, epsilon 0.6975632438116677, time 726.0, rides 120\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 400, reward -116.0, memory_length 2000, epsilon 0.6969354368922371, time 729.0, rides 144\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 401, reward -288.0, memory_length 2000, epsilon 0.6963081949990341, time 726.0, rides 110\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 402, reward 68.0, memory_length 2000, epsilon 0.6956815176235349, time 727.0, rides 120\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 403, reward 94.0, memory_length 2000, epsilon 0.6950554042576738, time 735.0, rides 133\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 404, reward 124.0, memory_length 2000, epsilon 0.6944298543938419, time 724.0, rides 126\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 405, reward -226.0, memory_length 2000, epsilon 0.6938048675248873, time 724.0, rides 131\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 406, reward -79.0, memory_length 2000, epsilon 0.693180443144115, time 728.0, rides 123\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 407, reward -171.0, memory_length 2000, epsilon 0.6925565807452853, time 731.0, rides 125\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 408, reward -166.0, memory_length 2000, epsilon 0.6919332798226145, time 740.0, rides 134\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 409, reward 52.0, memory_length 2000, epsilon 0.6913105398707742, time 732.0, rides 134\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 410, reward -160.0, memory_length 2000, epsilon 0.6906883603848905, time 726.0, rides 131\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 411, reward -1.0, memory_length 2000, epsilon 0.6900667408605441, time 728.0, rides 116\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 412, reward -41.0, memory_length 2000, epsilon 0.6894456807937696, time 728.0, rides 135\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 413, reward -168.0, memory_length 2000, epsilon 0.6888251796810552, time 736.0, rides 135\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 414, reward -167.0, memory_length 2000, epsilon 0.6882052370193422, time 727.0, rides 121\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 415, reward -112.0, memory_length 2000, epsilon 0.6875858523060248, time 730.0, rides 122\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 416, reward 15.0, memory_length 2000, epsilon 0.6869670250389494, time 732.0, rides 117\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 417, reward -184.0, memory_length 2000, epsilon 0.6863487547164143, time 728.0, rides 134\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 418, reward 266.0, memory_length 2000, epsilon 0.6857310408371695, time 732.0, rides 126\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 419, reward 67.0, memory_length 2000, epsilon 0.6851138829004161, time 728.0, rides 138\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 420, reward -82.0, memory_length 2000, epsilon 0.6844972804058057, time 732.0, rides 125\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 421, reward 138.0, memory_length 2000, epsilon 0.6838812328534405, time 728.0, rides 111\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 422, reward -51.0, memory_length 2000, epsilon 0.6832657397438724, time 730.0, rides 133\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 423, reward 242.0, memory_length 2000, epsilon 0.6826508005781029, time 729.0, rides 120\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 424, reward -236.0, memory_length 2000, epsilon 0.6820364148575826, time 738.0, rides 123\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 425, reward -58.0, memory_length 2000, epsilon 0.6814225820842108, time 736.0, rides 122\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 426, reward -60.0, memory_length 2000, epsilon 0.680809301760335, time 727.0, rides 122\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 427, reward -304.0, memory_length 2000, epsilon 0.6801965733887507, time 735.0, rides 132\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 428, reward 111.0, memory_length 2000, epsilon 0.6795843964727009, time 727.0, rides 136\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 429, reward 51.0, memory_length 2000, epsilon 0.6789727705158755, time 738.0, rides 133\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 430, reward 104.0, memory_length 2000, epsilon 0.6783616950224112, time 731.0, rides 124\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 431, reward -170.0, memory_length 2000, epsilon 0.677751169496891, time 723.0, rides 127\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 432, reward -68.0, memory_length 2000, epsilon 0.6771411934443438, time 733.0, rides 123\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 433, reward -183.0, memory_length 2000, epsilon 0.6765317663702438, time 729.0, rides 132\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 434, reward 186.0, memory_length 2000, epsilon 0.6759228877805106, time 730.0, rides 134\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 435, reward -235.0, memory_length 2000, epsilon 0.6753145571815081, time 737.0, rides 130\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 436, reward -238.0, memory_length 2000, epsilon 0.6747067740800448, time 734.0, rides 127\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 437, reward -119.0, memory_length 2000, epsilon 0.6740995379833727, time 725.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 438, reward 111.0, memory_length 2000, epsilon 0.6734928483991877, time 732.0, rides 120\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 439, reward -44.0, memory_length 2000, epsilon 0.6728867048356284, time 734.0, rides 129\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 440, reward 80.0, memory_length 2000, epsilon 0.6722811068012763, time 728.0, rides 113\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 441, reward 95.0, memory_length 2000, epsilon 0.6716760538051552, time 726.0, rides 134\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 442, reward -50.0, memory_length 2000, epsilon 0.6710715453567305, time 726.0, rides 140\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 443, reward -12.0, memory_length 2000, epsilon 0.6704675809659094, time 729.0, rides 134\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 444, reward -29.0, memory_length 2000, epsilon 0.6698641601430401, time 730.0, rides 133\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 445, reward 120.0, memory_length 2000, epsilon 0.6692612823989114, time 728.0, rides 128\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 446, reward 94.0, memory_length 2000, epsilon 0.6686589472447524, time 730.0, rides 137\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 447, reward -102.0, memory_length 2000, epsilon 0.6680571541922321, time 734.0, rides 119\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 448, reward 79.0, memory_length 2000, epsilon 0.6674559027534591, time 729.0, rides 120\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 449, reward -177.0, memory_length 2000, epsilon 0.666855192440981, time 726.0, rides 139\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 450, reward -103.0, memory_length 2000, epsilon 0.6662550227677841, time 732.0, rides 124\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 451, reward -78.0, memory_length 2000, epsilon 0.6656553932472932, time 727.0, rides 123\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 452, reward 68.0, memory_length 2000, epsilon 0.6650563033933706, time 727.0, rides 131\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 453, reward -97.0, memory_length 2000, epsilon 0.6644577527203166, time 735.0, rides 128\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 454, reward 51.0, memory_length 2000, epsilon 0.6638597407428684, time 720.0, rides 118\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 455, reward -118.0, memory_length 2000, epsilon 0.6632622669761997, time 731.0, rides 120\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 456, reward -19.0, memory_length 2000, epsilon 0.6626653309359212, time 726.0, rides 142\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 457, reward -134.0, memory_length 2000, epsilon 0.6620689321380788, time 721.0, rides 128\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 458, reward -204.0, memory_length 2000, epsilon 0.6614730700991546, time 732.0, rides 138\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 459, reward 304.0, memory_length 2000, epsilon 0.6608777443360653, time 736.0, rides 119\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 460, reward -19.0, memory_length 2000, epsilon 0.6602829543661628, time 724.0, rides 131\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 461, reward 276.0, memory_length 2000, epsilon 0.6596886997072332, time 724.0, rides 131\n",
      "Initial State is  [1, 13, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 462, reward -31.0, memory_length 2000, epsilon 0.6590949798774967, time 733.0, rides 116\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 463, reward -53.0, memory_length 2000, epsilon 0.6585017943956069, time 723.0, rides 120\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 464, reward 80.0, memory_length 2000, epsilon 0.6579091427806508, time 732.0, rides 137\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 465, reward -235.0, memory_length 2000, epsilon 0.6573170245521482, time 725.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 466, reward -134.0, memory_length 2000, epsilon 0.6567254392300513, time 738.0, rides 121\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 467, reward -61.0, memory_length 2000, epsilon 0.6561343863347443, time 722.0, rides 140\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 468, reward 204.0, memory_length 2000, epsilon 0.655543865387043, time 733.0, rides 130\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 469, reward 152.0, memory_length 2000, epsilon 0.6549538759081946, time 733.0, rides 124\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 470, reward -232.0, memory_length 2000, epsilon 0.6543644174198773, time 722.0, rides 125\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 471, reward 229.0, memory_length 2000, epsilon 0.6537754894441994, time 729.0, rides 114\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 472, reward -78.0, memory_length 2000, epsilon 0.6531870915036996, time 729.0, rides 130\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 473, reward -49.0, memory_length 2000, epsilon 0.6525992231213462, time 723.0, rides 147\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 474, reward 117.0, memory_length 2000, epsilon 0.652011883820537, time 727.0, rides 133\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 475, reward -17.0, memory_length 2000, epsilon 0.6514250731250985, time 736.0, rides 113\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 476, reward -26.0, memory_length 2000, epsilon 0.6508387905592858, time 723.0, rides 123\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 477, reward 24.0, memory_length 2000, epsilon 0.6502530356477825, time 728.0, rides 128\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 478, reward -138.0, memory_length 2000, epsilon 0.6496678079156994, time 735.0, rides 135\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 479, reward 276.0, memory_length 2000, epsilon 0.6490831068885753, time 738.0, rides 141\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 480, reward 382.0, memory_length 2000, epsilon 0.6484989320923755, time 721.0, rides 140\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 481, reward 64.0, memory_length 2000, epsilon 0.6479152830534923, time 729.0, rides 128\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 482, reward 169.0, memory_length 2000, epsilon 0.6473321592987442, time 731.0, rides 123\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 483, reward 160.0, memory_length 2000, epsilon 0.6467495603553753, time 726.0, rides 118\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 484, reward 159.0, memory_length 2000, epsilon 0.6461674857510555, time 730.0, rides 118\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 485, reward 8.0, memory_length 2000, epsilon 0.6455859350138796, time 730.0, rides 137\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 486, reward 69.0, memory_length 2000, epsilon 0.6450049076723671, time 733.0, rides 121\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 487, reward 376.0, memory_length 2000, epsilon 0.6444244032554619, time 726.0, rides 121\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 488, reward 176.0, memory_length 2000, epsilon 0.6438444212925319, time 736.0, rides 118\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 489, reward 287.0, memory_length 2000, epsilon 0.6432649613133686, time 732.0, rides 133\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 490, reward -10.0, memory_length 2000, epsilon 0.6426860228481865, time 723.0, rides 108\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 491, reward -74.0, memory_length 2000, epsilon 0.6421076054276231, time 730.0, rides 120\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 492, reward -211.0, memory_length 2000, epsilon 0.6415297085827383, time 723.0, rides 130\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 493, reward 7.0, memory_length 2000, epsilon 0.6409523318450138, time 730.0, rides 132\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 494, reward -84.0, memory_length 2000, epsilon 0.6403754747463533, time 737.0, rides 128\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 495, reward 164.0, memory_length 2000, epsilon 0.6397991368190815, time 723.0, rides 125\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 496, reward 375.0, memory_length 2000, epsilon 0.6392233175959443, time 728.0, rides 137\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 497, reward 246.0, memory_length 2000, epsilon 0.638648016610108, time 721.0, rides 118\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 498, reward 226.0, memory_length 2000, epsilon 0.6380732333951589, time 734.0, rides 128\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 499, reward 318.0, memory_length 2000, epsilon 0.6374989674851033, time 724.0, rides 121\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 500, reward -90.0, memory_length 2000, epsilon 0.6369252184143667, time 729.0, rides 124\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 501, reward -22.0, memory_length 2000, epsilon 0.6363519857177937, time 728.0, rides 120\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 502, reward 385.0, memory_length 2000, epsilon 0.6357792689306477, time 721.0, rides 114\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 503, reward 11.0, memory_length 2000, epsilon 0.6352070675886101, time 724.0, rides 125\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 504, reward -212.0, memory_length 2000, epsilon 0.6346353812277804, time 727.0, rides 140\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 505, reward 302.0, memory_length 2000, epsilon 0.6340642093846754, time 734.0, rides 135\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 506, reward -55.0, memory_length 2000, epsilon 0.6334935515962292, time 726.0, rides 117\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 507, reward 147.0, memory_length 2000, epsilon 0.6329234073997926, time 727.0, rides 120\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 508, reward 36.0, memory_length 2000, epsilon 0.6323537763331327, time 725.0, rides 130\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 509, reward -70.0, memory_length 2000, epsilon 0.631784657934433, time 724.0, rides 126\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 510, reward 288.0, memory_length 2000, epsilon 0.6312160517422919, time 728.0, rides 114\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 511, reward 8.0, memory_length 2000, epsilon 0.6306479572957239, time 731.0, rides 137\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 512, reward 214.0, memory_length 2000, epsilon 0.6300803741341577, time 725.0, rides 119\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 513, reward 95.0, memory_length 2000, epsilon 0.629513301797437, time 733.0, rides 123\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 514, reward 182.0, memory_length 2000, epsilon 0.6289467398258193, time 724.0, rides 126\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 515, reward -192.0, memory_length 2000, epsilon 0.628380687759976, time 732.0, rides 140\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 516, reward -362.0, memory_length 2000, epsilon 0.627815145140992, time 733.0, rides 133\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 517, reward 240.0, memory_length 2000, epsilon 0.6272501115103651, time 725.0, rides 135\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 518, reward -253.0, memory_length 2000, epsilon 0.6266855864100058, time 730.0, rides 121\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 519, reward 76.0, memory_length 2000, epsilon 0.6261215693822368, time 738.0, rides 143\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 520, reward -19.0, memory_length 2000, epsilon 0.6255580599697929, time 721.0, rides 121\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 521, reward -69.0, memory_length 2000, epsilon 0.6249950577158201, time 729.0, rides 122\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 522, reward 376.0, memory_length 2000, epsilon 0.6244325621638759, time 721.0, rides 130\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 523, reward 39.0, memory_length 2000, epsilon 0.6238705728579284, time 735.0, rides 122\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 524, reward 27.0, memory_length 2000, epsilon 0.6233090893423562, time 741.0, rides 121\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 525, reward -60.0, memory_length 2000, epsilon 0.6227481111619481, time 725.0, rides 130\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 526, reward 110.0, memory_length 2000, epsilon 0.6221876378619023, time 730.0, rides 144\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 527, reward -154.0, memory_length 2000, epsilon 0.6216276689878266, time 729.0, rides 143\n",
      "Initial State is  [0, 1, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 528, reward 255.0, memory_length 2000, epsilon 0.6210682040857376, time 729.0, rides 130\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 529, reward 317.0, memory_length 2000, epsilon 0.6205092427020604, time 720.0, rides 139\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 530, reward 135.0, memory_length 2000, epsilon 0.6199507843836286, time 733.0, rides 134\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 531, reward 195.0, memory_length 2000, epsilon 0.6193928286776833, time 726.0, rides 129\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 532, reward -224.0, memory_length 2000, epsilon 0.6188353751318734, time 729.0, rides 123\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 533, reward -97.0, memory_length 2000, epsilon 0.6182784232942546, time 729.0, rides 127\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 534, reward 79.0, memory_length 2000, epsilon 0.6177219727132898, time 731.0, rides 130\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 535, reward -105.0, memory_length 2000, epsilon 0.6171660229378478, time 730.0, rides 130\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 536, reward 11.0, memory_length 2000, epsilon 0.6166105735172037, time 733.0, rides 125\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 537, reward 295.0, memory_length 2000, epsilon 0.6160556240010382, time 727.0, rides 132\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 538, reward 140.0, memory_length 2000, epsilon 0.6155011739394373, time 733.0, rides 144\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 539, reward 68.0, memory_length 2000, epsilon 0.6149472228828917, time 736.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 540, reward 142.0, memory_length 2000, epsilon 0.6143937703822971, time 725.0, rides 120\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 541, reward -48.0, memory_length 2000, epsilon 0.613840815988953, time 725.0, rides 129\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 542, reward 54.0, memory_length 2000, epsilon 0.6132883592545629, time 725.0, rides 132\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 543, reward 200.0, memory_length 2000, epsilon 0.6127363997312338, time 728.0, rides 129\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 544, reward -108.0, memory_length 2000, epsilon 0.6121849369714757, time 727.0, rides 122\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 545, reward 265.0, memory_length 2000, epsilon 0.6116339705282013, time 729.0, rides 130\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 546, reward -179.0, memory_length 2000, epsilon 0.611083499954726, time 737.0, rides 123\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 547, reward 164.0, memory_length 2000, epsilon 0.6105335248047667, time 740.0, rides 135\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 548, reward 192.0, memory_length 2000, epsilon 0.6099840446324425, time 724.0, rides 136\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 549, reward -2.0, memory_length 2000, epsilon 0.6094350589922732, time 732.0, rides 132\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 550, reward 163.0, memory_length 2000, epsilon 0.6088865674391802, time 731.0, rides 121\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 551, reward 58.0, memory_length 2000, epsilon 0.608338569528485, time 726.0, rides 130\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 552, reward -209.0, memory_length 2000, epsilon 0.6077910648159093, time 728.0, rides 122\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 553, reward 172.0, memory_length 2000, epsilon 0.607244052857575, time 740.0, rides 131\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 554, reward -138.0, memory_length 2000, epsilon 0.6066975332100032, time 722.0, rides 128\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 555, reward -251.0, memory_length 2000, epsilon 0.6061515054301142, time 724.0, rides 131\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 556, reward 123.0, memory_length 2000, epsilon 0.6056059690752271, time 728.0, rides 124\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 557, reward 209.0, memory_length 2000, epsilon 0.6050609237030594, time 723.0, rides 111\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 558, reward 102.0, memory_length 2000, epsilon 0.6045163688717267, time 731.0, rides 130\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 559, reward 83.0, memory_length 2000, epsilon 0.6039723041397421, time 732.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 560, reward -17.0, memory_length 2000, epsilon 0.6034287290660163, time 730.0, rides 152\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 561, reward 100.0, memory_length 2000, epsilon 0.6028856432098568, time 727.0, rides 127\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 562, reward -206.0, memory_length 2000, epsilon 0.6023430461309679, time 725.0, rides 151\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 563, reward 235.0, memory_length 2000, epsilon 0.6018009373894501, time 731.0, rides 140\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 564, reward 340.0, memory_length 2000, epsilon 0.6012593165457996, time 732.0, rides 123\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 565, reward 72.0, memory_length 2000, epsilon 0.6007181831609083, time 735.0, rides 119\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 566, reward 179.0, memory_length 2000, epsilon 0.6001775367960634, time 725.0, rides 120\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 567, reward 192.0, memory_length 2000, epsilon 0.599637377012947, time 727.0, rides 138\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 568, reward 47.0, memory_length 2000, epsilon 0.5990977033736353, time 734.0, rides 125\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 569, reward -79.0, memory_length 2000, epsilon 0.598558515440599, time 730.0, rides 120\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 570, reward 109.0, memory_length 2000, epsilon 0.5980198127767025, time 736.0, rides 131\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 571, reward 46.0, memory_length 2000, epsilon 0.5974815949452035, time 726.0, rides 145\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 572, reward 42.0, memory_length 2000, epsilon 0.5969438615097528, time 736.0, rides 142\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 573, reward 31.0, memory_length 2000, epsilon 0.5964066120343939, time 731.0, rides 128\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 574, reward 152.0, memory_length 2000, epsilon 0.595869846083563, time 727.0, rides 129\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 575, reward -33.0, memory_length 2000, epsilon 0.5953335632220877, time 734.0, rides 140\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 576, reward 81.0, memory_length 2000, epsilon 0.5947977630151878, time 724.0, rides 137\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 577, reward 427.0, memory_length 2000, epsilon 0.5942624450284741, time 731.0, rides 125\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 578, reward 98.0, memory_length 2000, epsilon 0.5937276088279485, time 730.0, rides 127\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 579, reward 163.0, memory_length 2000, epsilon 0.5931932539800033, time 733.0, rides 139\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 580, reward 226.0, memory_length 2000, epsilon 0.5926593800514213, time 732.0, rides 117\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 581, reward 78.0, memory_length 2000, epsilon 0.592125986609375, time 734.0, rides 122\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 582, reward -25.0, memory_length 2000, epsilon 0.5915930732214265, time 733.0, rides 123\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 583, reward 56.0, memory_length 2000, epsilon 0.5910606394555272, time 727.0, rides 129\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 584, reward 371.0, memory_length 2000, epsilon 0.5905286848800172, time 730.0, rides 121\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 585, reward 83.0, memory_length 2000, epsilon 0.5899972090636252, time 726.0, rides 122\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 586, reward -89.0, memory_length 2000, epsilon 0.589466211575468, time 726.0, rides 123\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 587, reward 232.0, memory_length 2000, epsilon 0.58893569198505, time 735.0, rides 117\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 588, reward 369.0, memory_length 2000, epsilon 0.5884056498622635, time 731.0, rides 125\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 589, reward 167.0, memory_length 2000, epsilon 0.5878760847773875, time 725.0, rides 125\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 590, reward -102.0, memory_length 2000, epsilon 0.5873469963010879, time 734.0, rides 140\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 591, reward -118.0, memory_length 2000, epsilon 0.5868183840044169, time 727.0, rides 118\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 592, reward -129.0, memory_length 2000, epsilon 0.5862902474588129, time 730.0, rides 145\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 593, reward 259.0, memory_length 2000, epsilon 0.5857625862360999, time 731.0, rides 132\n",
      "Initial State is  [3, 0, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 594, reward -184.0, memory_length 2000, epsilon 0.5852353999084874, time 730.0, rides 132\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 595, reward 21.0, memory_length 2000, epsilon 0.5847086880485698, time 731.0, rides 126\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 596, reward 331.0, memory_length 2000, epsilon 0.584182450229326, time 722.0, rides 128\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 597, reward 57.0, memory_length 2000, epsilon 0.5836566860241196, time 726.0, rides 118\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 598, reward -19.0, memory_length 2000, epsilon 0.5831313950066979, time 735.0, rides 124\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 599, reward 71.0, memory_length 2000, epsilon 0.5826065767511919, time 724.0, rides 148\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 600, reward 89.0, memory_length 2000, epsilon 0.5820822308321157, time 737.0, rides 134\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 601, reward 211.0, memory_length 2000, epsilon 0.5815583568243669, time 724.0, rides 135\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 602, reward 83.0, memory_length 2000, epsilon 0.5810349543032249, time 728.0, rides 127\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 603, reward -45.0, memory_length 2000, epsilon 0.580512022844352, time 726.0, rides 135\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 604, reward 24.0, memory_length 2000, epsilon 0.579989562023792, time 736.0, rides 124\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 605, reward 193.0, memory_length 2000, epsilon 0.5794675714179707, time 729.0, rides 124\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 606, reward 380.0, memory_length 2000, epsilon 0.5789460506036945, time 729.0, rides 125\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 607, reward -7.0, memory_length 2000, epsilon 0.5784249991581512, time 735.0, rides 138\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 608, reward 53.0, memory_length 2000, epsilon 0.5779044166589088, time 735.0, rides 128\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 609, reward 241.0, memory_length 2000, epsilon 0.5773843026839157, time 729.0, rides 131\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 610, reward 403.0, memory_length 2000, epsilon 0.5768646568115002, time 738.0, rides 146\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 611, reward 339.0, memory_length 2000, epsilon 0.5763454786203699, time 731.0, rides 140\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 612, reward -11.0, memory_length 2000, epsilon 0.5758267676896115, time 727.0, rides 128\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 613, reward 242.0, memory_length 2000, epsilon 0.5753085235986909, time 730.0, rides 125\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 614, reward 54.0, memory_length 2000, epsilon 0.574790745927452, time 728.0, rides 132\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 615, reward 28.0, memory_length 2000, epsilon 0.5742734342561173, time 732.0, rides 133\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 616, reward 348.0, memory_length 2000, epsilon 0.5737565881652869, time 730.0, rides 123\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 617, reward 71.0, memory_length 2000, epsilon 0.573240207235938, time 728.0, rides 125\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 618, reward 290.0, memory_length 2000, epsilon 0.5727242910494257, time 728.0, rides 134\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 619, reward 128.0, memory_length 2000, epsilon 0.5722088391874812, time 724.0, rides 137\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 620, reward -92.0, memory_length 2000, epsilon 0.5716938512322125, time 725.0, rides 138\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 621, reward 268.0, memory_length 2000, epsilon 0.5711793267661035, time 731.0, rides 139\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 622, reward 53.0, memory_length 2000, epsilon 0.570665265372014, time 731.0, rides 131\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 623, reward -76.0, memory_length 2000, epsilon 0.5701516666331792, time 726.0, rides 132\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 624, reward 164.0, memory_length 2000, epsilon 0.5696385301332093, time 728.0, rides 114\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 625, reward 90.0, memory_length 2000, epsilon 0.5691258554560894, time 726.0, rides 116\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 626, reward -69.0, memory_length 2000, epsilon 0.5686136421861789, time 728.0, rides 132\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 627, reward 72.0, memory_length 2000, epsilon 0.5681018899082114, time 726.0, rides 143\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 628, reward -58.0, memory_length 2000, epsilon 0.5675905982072941, time 729.0, rides 118\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 629, reward 552.0, memory_length 2000, epsilon 0.5670797666689075, time 726.0, rides 138\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 630, reward 137.0, memory_length 2000, epsilon 0.5665693948789055, time 723.0, rides 118\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 631, reward 132.0, memory_length 2000, epsilon 0.5660594824235144, time 721.0, rides 134\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 632, reward 408.0, memory_length 2000, epsilon 0.5655500288893333, time 734.0, rides 143\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 633, reward -30.0, memory_length 2000, epsilon 0.5650410338633328, time 726.0, rides 131\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 634, reward 152.0, memory_length 2000, epsilon 0.5645324969328558, time 723.0, rides 134\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 635, reward 415.0, memory_length 2000, epsilon 0.5640244176856162, time 727.0, rides 125\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 636, reward 227.0, memory_length 2000, epsilon 0.5635167957096991, time 725.0, rides 131\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 637, reward 325.0, memory_length 2000, epsilon 0.5630096305935605, time 723.0, rides 134\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 638, reward 108.0, memory_length 2000, epsilon 0.5625029219260262, time 729.0, rides 120\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 639, reward 247.0, memory_length 2000, epsilon 0.5619966692962928, time 727.0, rides 132\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 640, reward -27.0, memory_length 2000, epsilon 0.5614908722939261, time 724.0, rides 112\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 641, reward 283.0, memory_length 2000, epsilon 0.5609855305088616, time 728.0, rides 131\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 642, reward -211.0, memory_length 2000, epsilon 0.5604806435314036, time 732.0, rides 127\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 643, reward 284.0, memory_length 2000, epsilon 0.5599762109522253, time 722.0, rides 128\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 644, reward -25.0, memory_length 2000, epsilon 0.5594722323623683, time 733.0, rides 128\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 645, reward 154.0, memory_length 2000, epsilon 0.5589687073532422, time 726.0, rides 125\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 646, reward 315.0, memory_length 2000, epsilon 0.5584656355166243, time 729.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 647, reward -137.0, memory_length 2000, epsilon 0.5579630164446594, time 733.0, rides 119\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 648, reward -7.0, memory_length 2000, epsilon 0.5574608497298592, time 736.0, rides 125\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 649, reward -33.0, memory_length 2000, epsilon 0.5569591349651023, time 733.0, rides 121\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 650, reward 129.0, memory_length 2000, epsilon 0.5564578717436337, time 729.0, rides 122\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 651, reward -119.0, memory_length 2000, epsilon 0.5559570596590644, time 735.0, rides 122\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 652, reward -23.0, memory_length 2000, epsilon 0.5554566983053713, time 729.0, rides 124\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 653, reward -151.0, memory_length 2000, epsilon 0.5549567872768965, time 724.0, rides 123\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 654, reward 194.0, memory_length 2000, epsilon 0.5544573261683472, time 742.0, rides 127\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 655, reward 177.0, memory_length 2000, epsilon 0.5539583145747957, time 725.0, rides 144\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 656, reward 365.0, memory_length 2000, epsilon 0.5534597520916784, time 727.0, rides 115\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 657, reward 43.0, memory_length 2000, epsilon 0.552961638314796, time 729.0, rides 128\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 658, reward -90.0, memory_length 2000, epsilon 0.5524639728403126, time 735.0, rides 119\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 659, reward 220.0, memory_length 2000, epsilon 0.5519667552647562, time 735.0, rides 122\n",
      "Initial State is  [2, 23, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 660, reward 271.0, memory_length 2000, epsilon 0.551469985185018, time 724.0, rides 130\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 661, reward -149.0, memory_length 2000, epsilon 0.5509736621983514, time 727.0, rides 120\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 662, reward -157.0, memory_length 2000, epsilon 0.550477785902373, time 725.0, rides 139\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 663, reward 140.0, memory_length 2000, epsilon 0.5499823558950608, time 726.0, rides 121\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 664, reward -43.0, memory_length 2000, epsilon 0.5494873717747553, time 726.0, rides 132\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 665, reward 167.0, memory_length 2000, epsilon 0.548992833140158, time 724.0, rides 122\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 666, reward 205.0, memory_length 2000, epsilon 0.5484987395903319, time 729.0, rides 126\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 667, reward 111.0, memory_length 2000, epsilon 0.5480050907247006, time 735.0, rides 129\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 668, reward 219.0, memory_length 2000, epsilon 0.5475118861430484, time 730.0, rides 140\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 669, reward 69.0, memory_length 2000, epsilon 0.5470191254455196, time 725.0, rides 127\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 670, reward -52.0, memory_length 2000, epsilon 0.5465268082326186, time 742.0, rides 115\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 671, reward 101.0, memory_length 2000, epsilon 0.5460349341052092, time 728.0, rides 122\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 672, reward 251.0, memory_length 2000, epsilon 0.5455435026645145, time 737.0, rides 127\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 673, reward 398.0, memory_length 2000, epsilon 0.5450525135121164, time 734.0, rides 126\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 674, reward 264.0, memory_length 2000, epsilon 0.5445619662499555, time 728.0, rides 130\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 675, reward 44.0, memory_length 2000, epsilon 0.5440718604803305, time 726.0, rides 134\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 676, reward 93.0, memory_length 2000, epsilon 0.5435821958058982, time 725.0, rides 128\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 677, reward 209.0, memory_length 2000, epsilon 0.5430929718296729, time 730.0, rides 124\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 678, reward -163.0, memory_length 2000, epsilon 0.5426041881550262, time 739.0, rides 139\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 679, reward 17.0, memory_length 2000, epsilon 0.5421158443856867, time 726.0, rides 125\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 680, reward 391.0, memory_length 2000, epsilon 0.5416279401257396, time 726.0, rides 133\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 681, reward 222.0, memory_length 2000, epsilon 0.5411404749796264, time 722.0, rides 120\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 682, reward 237.0, memory_length 2000, epsilon 0.5406534485521447, time 724.0, rides 123\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 683, reward 201.0, memory_length 2000, epsilon 0.5401668604484477, time 736.0, rides 123\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 684, reward 496.0, memory_length 2000, epsilon 0.5396807102740442, time 727.0, rides 129\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 685, reward -92.0, memory_length 2000, epsilon 0.5391949976347975, time 728.0, rides 137\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 686, reward 131.0, memory_length 2000, epsilon 0.5387097221369261, time 727.0, rides 123\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 687, reward 113.0, memory_length 2000, epsilon 0.5382248833870029, time 732.0, rides 120\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 688, reward 320.0, memory_length 2000, epsilon 0.5377404809919546, time 734.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 689, reward 184.0, memory_length 2000, epsilon 0.5372565145590619, time 730.0, rides 109\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 690, reward 125.0, memory_length 2000, epsilon 0.5367729836959587, time 726.0, rides 129\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 691, reward 216.0, memory_length 2000, epsilon 0.5362898880106324, time 729.0, rides 126\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 692, reward 213.0, memory_length 2000, epsilon 0.5358072271114228, time 724.0, rides 138\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 693, reward 48.0, memory_length 2000, epsilon 0.5353250006070225, time 735.0, rides 125\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 694, reward 149.0, memory_length 2000, epsilon 0.5348432081064761, time 725.0, rides 133\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 695, reward 452.0, memory_length 2000, epsilon 0.5343618492191803, time 732.0, rides 141\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 696, reward 158.0, memory_length 2000, epsilon 0.533880923554883, time 728.0, rides 133\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 697, reward 89.0, memory_length 2000, epsilon 0.5334004307236836, time 723.0, rides 123\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 698, reward 279.0, memory_length 2000, epsilon 0.5329203703360322, time 732.0, rides 131\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 699, reward 109.0, memory_length 2000, epsilon 0.5324407420027298, time 730.0, rides 124\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 700, reward 119.0, memory_length 2000, epsilon 0.5319615453349273, time 726.0, rides 110\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 701, reward 316.0, memory_length 2000, epsilon 0.5314827799441258, time 725.0, rides 132\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 702, reward 356.0, memory_length 2000, epsilon 0.5310044454421762, time 728.0, rides 118\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 703, reward 299.0, memory_length 2000, epsilon 0.5305265414412782, time 731.0, rides 141\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 704, reward 322.0, memory_length 2000, epsilon 0.5300490675539811, time 726.0, rides 128\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 705, reward 233.0, memory_length 2000, epsilon 0.5295720233931824, time 729.0, rides 127\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 706, reward 146.0, memory_length 2000, epsilon 0.5290954085721286, time 728.0, rides 140\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 707, reward 197.0, memory_length 2000, epsilon 0.5286192227044136, time 727.0, rides 125\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 708, reward 15.0, memory_length 2000, epsilon 0.5281434654039796, time 727.0, rides 111\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 709, reward -220.0, memory_length 2000, epsilon 0.527668136285116, time 734.0, rides 135\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 710, reward 255.0, memory_length 2000, epsilon 0.5271932349624594, time 737.0, rides 133\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 711, reward 196.0, memory_length 2000, epsilon 0.5267187610509931, time 731.0, rides 109\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 712, reward 201.0, memory_length 2000, epsilon 0.5262447141660472, time 727.0, rides 127\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 713, reward 551.0, memory_length 2000, epsilon 0.5257710939232978, time 730.0, rides 121\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 714, reward 45.0, memory_length 2000, epsilon 0.5252978999387669, time 732.0, rides 117\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 715, reward -16.0, memory_length 2000, epsilon 0.524825131828822, time 744.0, rides 136\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 716, reward 586.0, memory_length 2000, epsilon 0.524352789210176, time 733.0, rides 135\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 717, reward 346.0, memory_length 2000, epsilon 0.5238808716998868, time 728.0, rides 127\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 718, reward 607.0, memory_length 2000, epsilon 0.5234093789153569, time 736.0, rides 131\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 719, reward 423.0, memory_length 2000, epsilon 0.522938310474333, time 729.0, rides 124\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 720, reward 160.0, memory_length 2000, epsilon 0.5224676659949061, time 723.0, rides 119\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 721, reward 203.0, memory_length 2000, epsilon 0.5219974450955107, time 730.0, rides 107\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 722, reward 235.0, memory_length 2000, epsilon 0.5215276473949247, time 728.0, rides 120\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 723, reward 212.0, memory_length 2000, epsilon 0.5210582725122693, time 726.0, rides 126\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 724, reward 16.0, memory_length 2000, epsilon 0.5205893200670083, time 728.0, rides 117\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 725, reward 363.0, memory_length 2000, epsilon 0.520120789678948, time 734.0, rides 136\n",
      "Initial State is  [2, 20, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 726, reward 105.0, memory_length 2000, epsilon 0.519652680968237, time 725.0, rides 123\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 727, reward 253.0, memory_length 2000, epsilon 0.5191849935553656, time 726.0, rides 141\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 728, reward 416.0, memory_length 2000, epsilon 0.5187177270611658, time 736.0, rides 131\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 729, reward 312.0, memory_length 2000, epsilon 0.5182508811068107, time 729.0, rides 138\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 730, reward 124.0, memory_length 2000, epsilon 0.5177844553138146, time 732.0, rides 120\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 731, reward 196.0, memory_length 2000, epsilon 0.5173184493040321, time 733.0, rides 135\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 732, reward 227.0, memory_length 2000, epsilon 0.5168528626996585, time 728.0, rides 139\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 733, reward 468.0, memory_length 2000, epsilon 0.5163876951232288, time 731.0, rides 133\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 734, reward 120.0, memory_length 2000, epsilon 0.5159229461976179, time 727.0, rides 128\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 735, reward 428.0, memory_length 2000, epsilon 0.51545861554604, time 724.0, rides 128\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 736, reward 449.0, memory_length 2000, epsilon 0.5149947027920485, time 726.0, rides 133\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 737, reward 151.0, memory_length 2000, epsilon 0.5145312075595356, time 729.0, rides 135\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 738, reward 595.0, memory_length 2000, epsilon 0.5140681294727321, time 733.0, rides 123\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 739, reward 217.0, memory_length 2000, epsilon 0.5136054681562066, time 731.0, rides 121\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 740, reward 236.0, memory_length 2000, epsilon 0.5131432232348659, time 723.0, rides 140\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 741, reward 211.0, memory_length 2000, epsilon 0.5126813943339545, time 732.0, rides 131\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 742, reward 382.0, memory_length 2000, epsilon 0.512219981079054, time 723.0, rides 122\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 743, reward 274.0, memory_length 2000, epsilon 0.5117589830960828, time 728.0, rides 141\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 744, reward 141.0, memory_length 2000, epsilon 0.5112984000112963, time 732.0, rides 125\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 745, reward 291.0, memory_length 2000, epsilon 0.5108382314512862, time 732.0, rides 119\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 746, reward -13.0, memory_length 2000, epsilon 0.51037847704298, time 728.0, rides 118\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 747, reward 316.0, memory_length 2000, epsilon 0.5099191364136413, time 733.0, rides 133\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 748, reward 158.0, memory_length 2000, epsilon 0.509460209190869, time 733.0, rides 127\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 749, reward 373.0, memory_length 2000, epsilon 0.5090016950025972, time 723.0, rides 121\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 750, reward 208.0, memory_length 2000, epsilon 0.5085435934770949, time 722.0, rides 117\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 751, reward 182.0, memory_length 2000, epsilon 0.5080859042429655, time 738.0, rides 124\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 752, reward 75.0, memory_length 2000, epsilon 0.5076286269291468, time 729.0, rides 114\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 753, reward 128.0, memory_length 2000, epsilon 0.5071717611649106, time 724.0, rides 123\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 754, reward 289.0, memory_length 2000, epsilon 0.5067153065798622, time 725.0, rides 129\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 755, reward 312.0, memory_length 2000, epsilon 0.5062592628039403, time 720.0, rides 133\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 756, reward 357.0, memory_length 2000, epsilon 0.5058036294674167, time 730.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 757, reward 211.0, memory_length 2000, epsilon 0.505348406200896, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 758, reward 366.0, memory_length 2000, epsilon 0.5048935926353152, time 727.0, rides 127\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 759, reward 270.0, memory_length 2000, epsilon 0.5044391884019434, time 731.0, rides 131\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 760, reward 328.0, memory_length 2000, epsilon 0.5039851931323815, time 723.0, rides 122\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 761, reward 263.0, memory_length 2000, epsilon 0.5035316064585624, time 730.0, rides 125\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 762, reward 271.0, memory_length 2000, epsilon 0.5030784280127497, time 735.0, rides 132\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 763, reward 133.0, memory_length 2000, epsilon 0.5026256574275383, time 725.0, rides 127\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 764, reward 574.0, memory_length 2000, epsilon 0.5021732943358534, time 728.0, rides 123\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 765, reward 18.0, memory_length 2000, epsilon 0.5017213383709511, time 724.0, rides 141\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 766, reward 216.0, memory_length 2000, epsilon 0.5012697891664173, time 729.0, rides 139\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 767, reward 291.0, memory_length 2000, epsilon 0.5008186463561675, time 727.0, rides 128\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 768, reward 306.0, memory_length 2000, epsilon 0.5003679095744469, time 729.0, rides 136\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 769, reward 28.0, memory_length 2000, epsilon 0.49991757845582985, time 723.0, rides 142\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 770, reward 313.0, memory_length 2000, epsilon 0.4994676526352196, time 728.0, rides 130\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 771, reward -69.0, memory_length 2000, epsilon 0.49901813174784787, time 725.0, rides 133\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 772, reward -45.0, memory_length 2000, epsilon 0.4985690154292748, time 728.0, rides 120\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 773, reward 238.0, memory_length 2000, epsilon 0.4981203033153884, time 734.0, rides 137\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 774, reward 296.0, memory_length 2000, epsilon 0.49767199504240456, time 725.0, rides 135\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 775, reward 52.0, memory_length 2000, epsilon 0.49722409024686637, time 732.0, rides 137\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 776, reward -10.0, memory_length 2000, epsilon 0.49677658856564416, time 728.0, rides 133\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 777, reward 360.0, memory_length 2000, epsilon 0.4963294896359351, time 729.0, rides 134\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 778, reward 244.0, memory_length 2000, epsilon 0.49588279309526273, time 732.0, rides 133\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 779, reward 94.0, memory_length 2000, epsilon 0.495436498581477, time 725.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 780, reward 245.0, memory_length 2000, epsilon 0.49499060573275366, time 721.0, rides 124\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 781, reward -55.0, memory_length 2000, epsilon 0.49454511418759417, time 728.0, rides 138\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 782, reward 182.0, memory_length 2000, epsilon 0.49410002358482535, time 725.0, rides 126\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 783, reward 155.0, memory_length 2000, epsilon 0.49365533356359903, time 731.0, rides 135\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 784, reward 356.0, memory_length 2000, epsilon 0.4932110437633918, time 742.0, rides 122\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 785, reward 304.0, memory_length 2000, epsilon 0.49276715382400477, time 725.0, rides 126\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 786, reward -74.0, memory_length 2000, epsilon 0.49232366338556316, time 732.0, rides 119\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 787, reward 351.0, memory_length 2000, epsilon 0.49188057208851615, time 733.0, rides 118\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 788, reward 419.0, memory_length 2000, epsilon 0.4914378795736365, time 729.0, rides 130\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 789, reward 374.0, memory_length 2000, epsilon 0.4909955854820202, time 732.0, rides 135\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 790, reward 247.0, memory_length 2000, epsilon 0.4905536894550864, time 730.0, rides 125\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 791, reward 23.0, memory_length 2000, epsilon 0.49011219113457677, time 725.0, rides 127\n",
      "Initial State is  [2, 13, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 792, reward 527.0, memory_length 2000, epsilon 0.48967109016255567, time 724.0, rides 129\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 793, reward 276.0, memory_length 2000, epsilon 0.48923038618140935, time 732.0, rides 129\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 794, reward 452.0, memory_length 2000, epsilon 0.48879007883384606, time 726.0, rides 136\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 795, reward 579.0, memory_length 2000, epsilon 0.4883501677628956, time 731.0, rides 114\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 796, reward 271.0, memory_length 2000, epsilon 0.48791065261190897, time 727.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 797, reward 79.0, memory_length 2000, epsilon 0.48747153302455826, time 726.0, rides 145\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 798, reward 238.0, memory_length 2000, epsilon 0.48703280864483617, time 726.0, rides 125\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 799, reward 123.0, memory_length 2000, epsilon 0.48659447911705583, time 727.0, rides 142\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 800, reward 215.0, memory_length 2000, epsilon 0.48615654408585046, time 729.0, rides 131\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 801, reward 269.0, memory_length 2000, epsilon 0.48571900319617317, time 726.0, rides 137\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 802, reward 338.0, memory_length 2000, epsilon 0.4852818560932966, time 726.0, rides 129\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 803, reward 397.0, memory_length 2000, epsilon 0.48484510242281265, time 738.0, rides 140\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 804, reward -9.0, memory_length 2000, epsilon 0.4844087418306321, time 732.0, rides 125\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 805, reward -8.0, memory_length 2000, epsilon 0.4839727739629845, time 732.0, rides 136\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 806, reward 79.0, memory_length 2000, epsilon 0.4835371984664178, time 722.0, rides 131\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 807, reward 17.0, memory_length 2000, epsilon 0.48310201498779803, time 726.0, rides 135\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 808, reward 416.0, memory_length 2000, epsilon 0.482667223174309, time 728.0, rides 122\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 809, reward 411.0, memory_length 2000, epsilon 0.48223282267345213, time 727.0, rides 127\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 810, reward 304.0, memory_length 2000, epsilon 0.481798813133046, time 726.0, rides 138\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 811, reward 328.0, memory_length 2000, epsilon 0.48136519420122625, time 734.0, rides 125\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 812, reward 256.0, memory_length 2000, epsilon 0.4809319655264451, time 733.0, rides 131\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 813, reward 177.0, memory_length 2000, epsilon 0.4804991267574713, time 731.0, rides 126\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 814, reward 392.0, memory_length 2000, epsilon 0.48006667754338955, time 727.0, rides 136\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 815, reward -20.0, memory_length 2000, epsilon 0.4796346175336005, time 734.0, rides 143\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 816, reward 165.0, memory_length 2000, epsilon 0.47920294637782024, time 728.0, rides 114\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 817, reward 228.0, memory_length 2000, epsilon 0.4787716637260802, time 727.0, rides 147\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 818, reward 248.0, memory_length 2000, epsilon 0.47834076922872676, time 729.0, rides 135\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 819, reward 431.0, memory_length 2000, epsilon 0.4779102625364209, time 730.0, rides 128\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 820, reward 379.0, memory_length 2000, epsilon 0.4774801433001381, time 738.0, rides 122\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 821, reward 116.0, memory_length 2000, epsilon 0.477050411171168, time 727.0, rides 136\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 822, reward 273.0, memory_length 2000, epsilon 0.4766210658011139, time 739.0, rides 127\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 823, reward 102.0, memory_length 2000, epsilon 0.4761921068418929, time 727.0, rides 127\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 824, reward 155.0, memory_length 2000, epsilon 0.4757635339457352, time 723.0, rides 128\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 825, reward 331.0, memory_length 2000, epsilon 0.475335346765184, time 724.0, rides 147\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 826, reward 205.0, memory_length 2000, epsilon 0.47490754495309534, time 730.0, rides 142\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 827, reward 442.0, memory_length 2000, epsilon 0.47448012816263757, time 731.0, rides 132\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 828, reward 201.0, memory_length 2000, epsilon 0.4740530960472912, time 730.0, rides 131\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 829, reward 139.0, memory_length 2000, epsilon 0.4736264482608486, time 726.0, rides 103\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 830, reward 123.0, memory_length 2000, epsilon 0.47320018445741385, time 720.0, rides 128\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 831, reward 281.0, memory_length 2000, epsilon 0.47277430429140216, time 724.0, rides 123\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 832, reward 351.0, memory_length 2000, epsilon 0.4723488074175399, time 723.0, rides 128\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 833, reward 394.0, memory_length 2000, epsilon 0.4719236934908641, time 735.0, rides 138\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 834, reward 93.0, memory_length 2000, epsilon 0.4714989621667223, time 734.0, rides 132\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 835, reward 165.0, memory_length 2000, epsilon 0.47107461310077225, time 724.0, rides 127\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 836, reward 390.0, memory_length 2000, epsilon 0.47065064594898154, time 722.0, rides 130\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 837, reward 93.0, memory_length 2000, epsilon 0.47022706036762746, time 733.0, rides 146\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 838, reward -231.0, memory_length 2000, epsilon 0.4698038560132966, time 726.0, rides 134\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 839, reward 229.0, memory_length 2000, epsilon 0.46938103254288466, time 737.0, rides 119\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 840, reward 21.0, memory_length 2000, epsilon 0.46895858961359604, time 735.0, rides 129\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 841, reward -92.0, memory_length 2000, epsilon 0.4685365268829438, time 742.0, rides 135\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 842, reward 241.0, memory_length 2000, epsilon 0.46811484400874914, time 735.0, rides 135\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 843, reward 348.0, memory_length 2000, epsilon 0.46769354064914126, time 744.0, rides 142\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 844, reward 242.0, memory_length 2000, epsilon 0.467272616462557, time 726.0, rides 113\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 845, reward 135.0, memory_length 2000, epsilon 0.46685207110774074, time 729.0, rides 121\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 846, reward 340.0, memory_length 2000, epsilon 0.46643190424374376, time 724.0, rides 124\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 847, reward -106.0, memory_length 2000, epsilon 0.4660121155299244, time 727.0, rides 133\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 848, reward 306.0, memory_length 2000, epsilon 0.46559270462594743, time 726.0, rides 129\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 849, reward 30.0, memory_length 2000, epsilon 0.46517367119178404, time 726.0, rides 117\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 850, reward 263.0, memory_length 2000, epsilon 0.4647550148877114, time 736.0, rides 116\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 851, reward 76.0, memory_length 2000, epsilon 0.46433673537431247, time 729.0, rides 114\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 852, reward 3.0, memory_length 2000, epsilon 0.4639188323124756, time 729.0, rides 141\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 853, reward 303.0, memory_length 2000, epsilon 0.46350130536339434, time 723.0, rides 125\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 854, reward 409.0, memory_length 2000, epsilon 0.4630841541885673, time 728.0, rides 103\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 855, reward 2.0, memory_length 2000, epsilon 0.4626673784497976, time 723.0, rides 123\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 856, reward 20.0, memory_length 2000, epsilon 0.4622509778091928, time 728.0, rides 120\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 857, reward 137.0, memory_length 2000, epsilon 0.4618349519291645, time 734.0, rides 122\n",
      "Initial State is  [3, 22, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 858, reward 257.0, memory_length 2000, epsilon 0.46141930047242824, time 729.0, rides 122\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 859, reward -129.0, memory_length 2000, epsilon 0.46100402310200306, time 742.0, rides 128\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 860, reward 418.0, memory_length 2000, epsilon 0.46058911948121123, time 725.0, rides 117\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 861, reward 76.0, memory_length 2000, epsilon 0.46017458927367816, time 737.0, rides 127\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 862, reward 104.0, memory_length 2000, epsilon 0.45976043214333184, time 739.0, rides 134\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 863, reward 121.0, memory_length 2000, epsilon 0.4593466477544028, time 731.0, rides 132\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 864, reward 182.0, memory_length 2000, epsilon 0.45893323577142386, time 732.0, rides 124\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 865, reward 156.0, memory_length 2000, epsilon 0.4585201958592296, time 724.0, rides 122\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 866, reward 197.0, memory_length 2000, epsilon 0.45810752768295626, time 735.0, rides 129\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 867, reward 294.0, memory_length 2000, epsilon 0.4576952309080416, time 730.0, rides 128\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 868, reward 274.0, memory_length 2000, epsilon 0.45728330520022437, time 729.0, rides 123\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 869, reward 348.0, memory_length 2000, epsilon 0.45687175022554416, time 727.0, rides 134\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 870, reward 170.0, memory_length 2000, epsilon 0.45646056565034115, time 731.0, rides 132\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 871, reward 340.0, memory_length 2000, epsilon 0.45604975114125584, time 726.0, rides 139\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 872, reward 178.0, memory_length 2000, epsilon 0.4556393063652287, time 730.0, rides 125\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 873, reward 97.0, memory_length 2000, epsilon 0.45522923098949997, time 724.0, rides 123\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 874, reward 204.0, memory_length 2000, epsilon 0.4548195246816094, time 722.0, rides 131\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 875, reward 238.0, memory_length 2000, epsilon 0.45441018710939596, time 725.0, rides 121\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 876, reward 156.0, memory_length 2000, epsilon 0.4540012179409975, time 729.0, rides 116\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 877, reward 420.0, memory_length 2000, epsilon 0.45359261684485064, time 739.0, rides 136\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 878, reward 279.0, memory_length 2000, epsilon 0.45318438348969026, time 732.0, rides 131\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 879, reward 226.0, memory_length 2000, epsilon 0.4527765175445495, time 732.0, rides 126\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 880, reward 217.0, memory_length 2000, epsilon 0.4523690186787594, time 732.0, rides 148\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 881, reward 277.0, memory_length 2000, epsilon 0.4519618865619485, time 723.0, rides 141\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 882, reward 443.0, memory_length 2000, epsilon 0.45155512086404276, time 728.0, rides 123\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 883, reward 550.0, memory_length 2000, epsilon 0.4511487212552651, time 729.0, rides 131\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 884, reward 147.0, memory_length 2000, epsilon 0.4507426874061354, time 729.0, rides 140\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 885, reward 612.0, memory_length 2000, epsilon 0.45033701898746986, time 727.0, rides 130\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 886, reward 205.0, memory_length 2000, epsilon 0.44993171567038115, time 723.0, rides 126\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 887, reward 355.0, memory_length 2000, epsilon 0.4495267771262778, time 733.0, rides 128\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 888, reward 474.0, memory_length 2000, epsilon 0.4491222030268642, time 730.0, rides 136\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 889, reward 279.0, memory_length 2000, epsilon 0.44871799304414, time 730.0, rides 120\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 890, reward 183.0, memory_length 2000, epsilon 0.4483141468504003, time 725.0, rides 132\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 891, reward 385.0, memory_length 2000, epsilon 0.44791066411823494, time 724.0, rides 143\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 892, reward 146.0, memory_length 2000, epsilon 0.44750754452052854, time 723.0, rides 122\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 893, reward 355.0, memory_length 2000, epsilon 0.4471047877304601, time 733.0, rides 142\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 894, reward 194.0, memory_length 2000, epsilon 0.44670239342150264, time 727.0, rides 129\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 895, reward 168.0, memory_length 2000, epsilon 0.4463003612674233, time 734.0, rides 119\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 896, reward 122.0, memory_length 2000, epsilon 0.44589869094228257, time 725.0, rides 145\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 897, reward 291.0, memory_length 2000, epsilon 0.4454973821204345, time 737.0, rides 125\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 898, reward 123.0, memory_length 2000, epsilon 0.4450964344765261, time 727.0, rides 140\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 899, reward 482.0, memory_length 2000, epsilon 0.4446958476854972, time 725.0, rides 129\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 900, reward 169.0, memory_length 2000, epsilon 0.4442956214225802, time 729.0, rides 122\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 901, reward -12.0, memory_length 2000, epsilon 0.4438957553632999, time 731.0, rides 122\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 902, reward 224.0, memory_length 2000, epsilon 0.4434962491834729, time 733.0, rides 117\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 903, reward 297.0, memory_length 2000, epsilon 0.44309710255920776, time 727.0, rides 135\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 904, reward 320.0, memory_length 2000, epsilon 0.44269831516690444, time 732.0, rides 113\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 905, reward 215.0, memory_length 2000, epsilon 0.4422998866832542, time 733.0, rides 119\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 906, reward 252.0, memory_length 2000, epsilon 0.44190181678523927, time 733.0, rides 133\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 907, reward 269.0, memory_length 2000, epsilon 0.44150410515013255, time 732.0, rides 141\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 908, reward 724.0, memory_length 2000, epsilon 0.44110675145549744, time 744.0, rides 125\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 909, reward 248.0, memory_length 2000, epsilon 0.4407097553791875, time 739.0, rides 126\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 910, reward -228.0, memory_length 2000, epsilon 0.44031311659934624, time 727.0, rides 121\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 911, reward 276.0, memory_length 2000, epsilon 0.43991683479440685, time 725.0, rides 133\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 912, reward -58.0, memory_length 2000, epsilon 0.4395209096430919, time 728.0, rides 123\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 913, reward 230.0, memory_length 2000, epsilon 0.43912534082441307, time 740.0, rides 129\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 914, reward 160.0, memory_length 2000, epsilon 0.4387301280176711, time 741.0, rides 145\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 915, reward 244.0, memory_length 2000, epsilon 0.43833527090245517, time 728.0, rides 140\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 916, reward 353.0, memory_length 2000, epsilon 0.43794076915864294, time 733.0, rides 147\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 917, reward 313.0, memory_length 2000, epsilon 0.43754662246640014, time 731.0, rides 129\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 918, reward 397.0, memory_length 2000, epsilon 0.43715283050618037, time 735.0, rides 134\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 919, reward 390.0, memory_length 2000, epsilon 0.4367593929587248, time 735.0, rides 124\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 920, reward 325.0, memory_length 2000, epsilon 0.43636630950506194, time 726.0, rides 110\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 921, reward 408.0, memory_length 2000, epsilon 0.43597357982650736, time 724.0, rides 140\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 922, reward 403.0, memory_length 2000, epsilon 0.4355812036046635, time 730.0, rides 128\n",
      "Initial State is  [0, 7, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 923, reward 219.0, memory_length 2000, epsilon 0.4351891805214193, time 726.0, rides 122\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 924, reward 390.0, memory_length 2000, epsilon 0.43479751025895, time 737.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 925, reward 285.0, memory_length 2000, epsilon 0.43440619249971696, time 736.0, rides 129\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 926, reward 352.0, memory_length 2000, epsilon 0.4340152269264672, time 725.0, rides 136\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 927, reward 447.0, memory_length 2000, epsilon 0.4336246132222334, time 730.0, rides 120\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 928, reward 527.0, memory_length 2000, epsilon 0.43323435107033337, time 723.0, rides 136\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 929, reward 121.0, memory_length 2000, epsilon 0.43284444015437007, time 733.0, rides 143\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 930, reward 360.0, memory_length 2000, epsilon 0.43245488015823114, time 733.0, rides 131\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 931, reward 364.0, memory_length 2000, epsilon 0.4320656707660887, time 723.0, rides 121\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 932, reward 218.0, memory_length 2000, epsilon 0.43167681166239924, time 732.0, rides 123\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 933, reward 175.0, memory_length 2000, epsilon 0.4312883025319031, time 726.0, rides 143\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 934, reward 227.0, memory_length 2000, epsilon 0.4309001430596244, time 728.0, rides 138\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 935, reward 358.0, memory_length 2000, epsilon 0.4305123329308707, time 729.0, rides 134\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 936, reward 244.0, memory_length 2000, epsilon 0.43012487183123294, time 729.0, rides 125\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 937, reward 315.0, memory_length 2000, epsilon 0.4297377594465848, time 729.0, rides 112\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 938, reward 522.0, memory_length 2000, epsilon 0.42935099546308286, time 726.0, rides 125\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 939, reward 140.0, memory_length 2000, epsilon 0.4289645795671661, time 727.0, rides 132\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 940, reward 334.0, memory_length 2000, epsilon 0.42857851144555564, time 725.0, rides 116\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 941, reward 367.0, memory_length 2000, epsilon 0.42819279078525463, time 724.0, rides 129\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 942, reward 540.0, memory_length 2000, epsilon 0.4278074172735479, time 729.0, rides 128\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 943, reward 389.0, memory_length 2000, epsilon 0.4274223905980017, time 723.0, rides 121\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 944, reward -18.0, memory_length 2000, epsilon 0.4270377104464635, time 733.0, rides 120\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 945, reward 79.0, memory_length 2000, epsilon 0.42665337650706164, time 726.0, rides 126\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 946, reward 343.0, memory_length 2000, epsilon 0.4262693884682053, time 731.0, rides 127\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 947, reward 576.0, memory_length 2000, epsilon 0.42588574601858387, time 731.0, rides 124\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 948, reward 162.0, memory_length 2000, epsilon 0.42550244884716715, time 730.0, rides 132\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 949, reward 541.0, memory_length 2000, epsilon 0.4251194966432047, time 734.0, rides 146\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 950, reward 287.0, memory_length 2000, epsilon 0.4247368890962258, time 727.0, rides 121\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 951, reward 290.0, memory_length 2000, epsilon 0.42435462589603923, time 725.0, rides 126\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 952, reward 661.0, memory_length 2000, epsilon 0.4239727067327328, time 732.0, rides 129\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 953, reward 372.0, memory_length 2000, epsilon 0.4235911312966733, time 726.0, rides 132\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 954, reward 229.0, memory_length 2000, epsilon 0.4232098992785063, time 730.0, rides 136\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 955, reward 177.0, memory_length 2000, epsilon 0.4228290103691556, time 727.0, rides 136\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 956, reward 129.0, memory_length 2000, epsilon 0.42244846425982335, time 730.0, rides 110\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 957, reward 40.0, memory_length 2000, epsilon 0.4220682606419895, time 727.0, rides 126\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 958, reward 468.0, memory_length 2000, epsilon 0.4216883992074117, time 730.0, rides 118\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 959, reward 314.0, memory_length 2000, epsilon 0.421308879648125, time 736.0, rides 126\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 960, reward 111.0, memory_length 2000, epsilon 0.4209297016564417, time 729.0, rides 143\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 961, reward 299.0, memory_length 2000, epsilon 0.4205508649249509, time 734.0, rides 145\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 962, reward 85.0, memory_length 2000, epsilon 0.42017236914651845, time 734.0, rides 137\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 963, reward 295.0, memory_length 2000, epsilon 0.41979421401428657, time 731.0, rides 134\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 964, reward 244.0, memory_length 2000, epsilon 0.41941639922167373, time 731.0, rides 131\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 965, reward 488.0, memory_length 2000, epsilon 0.41903892446237423, time 736.0, rides 126\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 966, reward 245.0, memory_length 2000, epsilon 0.4186617894303581, time 730.0, rides 137\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 967, reward 414.0, memory_length 2000, epsilon 0.4182849938198708, time 731.0, rides 125\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 968, reward 336.0, memory_length 2000, epsilon 0.41790853732543287, time 733.0, rides 122\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 969, reward 332.0, memory_length 2000, epsilon 0.41753241964183996, time 727.0, rides 109\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 970, reward 189.0, memory_length 2000, epsilon 0.4171566404641623, time 732.0, rides 133\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 971, reward 447.0, memory_length 2000, epsilon 0.41678119948774456, time 725.0, rides 129\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 972, reward 292.0, memory_length 2000, epsilon 0.4164060964082056, time 732.0, rides 121\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 973, reward 132.0, memory_length 2000, epsilon 0.4160313309214382, time 725.0, rides 136\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 974, reward 399.0, memory_length 2000, epsilon 0.4156569027236089, time 733.0, rides 134\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 975, reward 457.0, memory_length 2000, epsilon 0.41528281151115765, time 729.0, rides 133\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 976, reward 372.0, memory_length 2000, epsilon 0.4149090569807976, time 728.0, rides 130\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 977, reward 305.0, memory_length 2000, epsilon 0.4145356388295149, time 727.0, rides 117\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 978, reward 520.0, memory_length 2000, epsilon 0.4141625567545683, time 727.0, rides 127\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 979, reward 419.0, memory_length 2000, epsilon 0.41378981045348917, time 726.0, rides 121\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 980, reward 516.0, memory_length 2000, epsilon 0.41341739962408103, time 726.0, rides 115\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 981, reward 321.0, memory_length 2000, epsilon 0.41304532396441934, time 729.0, rides 137\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 982, reward 330.0, memory_length 2000, epsilon 0.41267358317285135, time 730.0, rides 138\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 983, reward 164.0, memory_length 2000, epsilon 0.41230217694799576, time 729.0, rides 129\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 984, reward 285.0, memory_length 2000, epsilon 0.4119311049887426, time 723.0, rides 127\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 985, reward 118.0, memory_length 2000, epsilon 0.4115603669942527, time 727.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 986, reward 237.0, memory_length 2000, epsilon 0.41118996266395785, time 728.0, rides 126\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 987, reward 146.0, memory_length 2000, epsilon 0.4108198916975603, time 730.0, rides 128\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 988, reward 407.0, memory_length 2000, epsilon 0.41045015379503247, time 724.0, rides 133\n",
      "Initial State is  [1, 11, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 989, reward 17.0, memory_length 2000, epsilon 0.4100807486566169, time 726.0, rides 121\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 990, reward 447.0, memory_length 2000, epsilon 0.409711675982826, time 734.0, rides 147\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 991, reward 352.0, memory_length 2000, epsilon 0.40934293547444145, time 721.0, rides 128\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 992, reward 91.0, memory_length 2000, epsilon 0.40897452683251445, time 727.0, rides 124\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 993, reward 286.0, memory_length 2000, epsilon 0.4086064497583652, time 738.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 994, reward 413.0, memory_length 2000, epsilon 0.40823870395358264, time 726.0, rides 125\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 995, reward 287.0, memory_length 2000, epsilon 0.4078712891200244, time 731.0, rides 120\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 996, reward 628.0, memory_length 2000, epsilon 0.4075042049598164, time 728.0, rides 133\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 997, reward 675.0, memory_length 2000, epsilon 0.40713745117535255, time 722.0, rides 132\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 998, reward 392.0, memory_length 2000, epsilon 0.4067710274692947, time 728.0, rides 124\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 999, reward 269.0, memory_length 2000, epsilon 0.40640493354457236, time 733.0, rides 121\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1000, reward 494.0, memory_length 2000, epsilon 0.40603916910438226, time 730.0, rides 128\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 1001, reward 159.0, memory_length 2000, epsilon 0.4056737338521883, time 726.0, rides 125\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1002, reward 393.0, memory_length 2000, epsilon 0.4053086274917213, time 730.0, rides 123\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1003, reward 213.0, memory_length 2000, epsilon 0.4049438497269788, time 725.0, rides 133\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 1004, reward 150.0, memory_length 2000, epsilon 0.4045794002622245, time 729.0, rides 122\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 1005, reward 120.0, memory_length 2000, epsilon 0.4042152788019885, time 731.0, rides 123\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 1006, reward 489.0, memory_length 2000, epsilon 0.4038514850510667, time 724.0, rides 124\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 1007, reward 387.0, memory_length 2000, epsilon 0.4034880187145207, time 729.0, rides 137\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 1008, reward 336.0, memory_length 2000, epsilon 0.40312487949767767, time 729.0, rides 128\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 1009, reward 372.0, memory_length 2000, epsilon 0.4027620671061298, time 729.0, rides 132\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 1010, reward 201.0, memory_length 2000, epsilon 0.4023995812457343, time 731.0, rides 142\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1011, reward 127.0, memory_length 2000, epsilon 0.40203742162261313, time 731.0, rides 132\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 1012, reward 417.0, memory_length 2000, epsilon 0.4016755879431528, time 732.0, rides 137\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 1013, reward 448.0, memory_length 2000, epsilon 0.4013140799140039, time 730.0, rides 135\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 1014, reward 82.0, memory_length 2000, epsilon 0.40095289724208133, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 1015, reward -18.0, memory_length 2000, epsilon 0.40059203963456347, time 732.0, rides 135\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 1016, reward 363.0, memory_length 2000, epsilon 0.40023150679889236, time 729.0, rides 128\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1017, reward 143.0, memory_length 2000, epsilon 0.39987129844277336, time 743.0, rides 123\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1018, reward 871.0, memory_length 2000, epsilon 0.39951141427417486, time 734.0, rides 128\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1019, reward 383.0, memory_length 2000, epsilon 0.3991518540013281, time 732.0, rides 133\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1020, reward 392.0, memory_length 2000, epsilon 0.39879261733272686, time 729.0, rides 151\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 1021, reward 470.0, memory_length 2000, epsilon 0.3984337039771274, time 728.0, rides 118\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 1022, reward 766.0, memory_length 2000, epsilon 0.398075113643548, time 728.0, rides 121\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 1023, reward 129.0, memory_length 2000, epsilon 0.3977168460412688, time 725.0, rides 123\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 1024, reward 518.0, memory_length 2000, epsilon 0.3973589008798316, time 722.0, rides 137\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 1025, reward 213.0, memory_length 2000, epsilon 0.39700127786903977, time 724.0, rides 137\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1026, reward 394.0, memory_length 2000, epsilon 0.3966439767189576, time 723.0, rides 140\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 1027, reward 418.0, memory_length 2000, epsilon 0.39628699713991056, time 729.0, rides 129\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1028, reward 358.0, memory_length 2000, epsilon 0.39593033884248463, time 726.0, rides 130\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1029, reward 111.0, memory_length 2000, epsilon 0.39557400153752637, time 728.0, rides 149\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1030, reward 390.0, memory_length 2000, epsilon 0.3952179849361426, time 732.0, rides 135\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 1031, reward 637.0, memory_length 2000, epsilon 0.39486228874970003, time 730.0, rides 141\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 1032, reward 468.0, memory_length 2000, epsilon 0.3945069126898253, time 723.0, rides 129\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 1033, reward 458.0, memory_length 2000, epsilon 0.39415185646840445, time 738.0, rides 145\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 1034, reward 188.0, memory_length 2000, epsilon 0.39379711979758286, time 731.0, rides 128\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 1035, reward 238.0, memory_length 2000, epsilon 0.39344270238976503, time 732.0, rides 134\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1036, reward 194.0, memory_length 2000, epsilon 0.39308860395761425, time 727.0, rides 115\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 1037, reward 36.0, memory_length 2000, epsilon 0.39273482421405237, time 725.0, rides 134\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 1038, reward 618.0, memory_length 2000, epsilon 0.3923813628722597, time 731.0, rides 134\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 1039, reward 647.0, memory_length 2000, epsilon 0.3920282196456747, time 731.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1040, reward 159.0, memory_length 2000, epsilon 0.3916753942479936, time 729.0, rides 121\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1041, reward 125.0, memory_length 2000, epsilon 0.39132288639317037, time 729.0, rides 140\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 1042, reward 411.0, memory_length 2000, epsilon 0.3909706957954165, time 732.0, rides 132\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1043, reward 296.0, memory_length 2000, epsilon 0.39061882216920063, time 733.0, rides 129\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 1044, reward 326.0, memory_length 2000, epsilon 0.3902672652292484, time 723.0, rides 121\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 1045, reward 445.0, memory_length 2000, epsilon 0.38991602469054204, time 737.0, rides 126\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1046, reward 101.0, memory_length 2000, epsilon 0.38956510026832053, time 728.0, rides 128\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1047, reward 234.0, memory_length 2000, epsilon 0.38921449167807903, time 722.0, rides 122\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1048, reward 520.0, memory_length 2000, epsilon 0.38886419863556876, time 731.0, rides 108\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 1049, reward -27.0, memory_length 2000, epsilon 0.38851422085679677, time 724.0, rides 132\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 1050, reward 496.0, memory_length 2000, epsilon 0.38816455805802563, time 731.0, rides 132\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 1051, reward 60.0, memory_length 2000, epsilon 0.3878152099557734, time 725.0, rides 146\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 1052, reward 388.0, memory_length 2000, epsilon 0.3874661762668132, time 734.0, rides 137\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 1053, reward 208.0, memory_length 2000, epsilon 0.38711745670817305, time 730.0, rides 117\n",
      "Initial State is  [1, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1054, reward 459.0, memory_length 2000, epsilon 0.3867690509971357, time 727.0, rides 136\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 1055, reward 449.0, memory_length 2000, epsilon 0.3864209588512383, time 730.0, rides 115\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 1056, reward 330.0, memory_length 2000, epsilon 0.3860731799882722, time 724.0, rides 119\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 1057, reward 205.0, memory_length 2000, epsilon 0.3857257141262827, time 730.0, rides 150\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 1058, reward 313.0, memory_length 2000, epsilon 0.38537856098356904, time 730.0, rides 119\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 1059, reward 585.0, memory_length 2000, epsilon 0.3850317202786838, time 729.0, rides 129\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 1060, reward 356.0, memory_length 2000, epsilon 0.384685191730433, time 727.0, rides 118\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 1061, reward 90.0, memory_length 2000, epsilon 0.38433897505787556, time 727.0, rides 136\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 1062, reward 231.0, memory_length 2000, epsilon 0.38399306998032345, time 721.0, rides 128\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 1063, reward 623.0, memory_length 2000, epsilon 0.38364747621734113, time 726.0, rides 129\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1064, reward 250.0, memory_length 2000, epsilon 0.3833021934887455, time 735.0, rides 125\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 1065, reward 647.0, memory_length 2000, epsilon 0.38295722151460565, time 732.0, rides 127\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 1066, reward 313.0, memory_length 2000, epsilon 0.3826125600152425, time 728.0, rides 123\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 1067, reward 730.0, memory_length 2000, epsilon 0.3822682087112288, time 729.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1068, reward 396.0, memory_length 2000, epsilon 0.3819241673233887, time 728.0, rides 129\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1069, reward 384.0, memory_length 2000, epsilon 0.38158043557279764, time 726.0, rides 133\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 1070, reward 562.0, memory_length 2000, epsilon 0.3812370131807821, time 731.0, rides 114\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 1071, reward 514.0, memory_length 2000, epsilon 0.3808938998689194, time 731.0, rides 140\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1072, reward 391.0, memory_length 2000, epsilon 0.38055109535903736, time 727.0, rides 114\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 1073, reward 267.0, memory_length 2000, epsilon 0.3802085993732142, time 734.0, rides 123\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 1074, reward 435.0, memory_length 2000, epsilon 0.3798664116337783, time 737.0, rides 134\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 1075, reward 51.0, memory_length 2000, epsilon 0.3795245318633079, time 729.0, rides 124\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 1076, reward 400.0, memory_length 2000, epsilon 0.37918295978463096, time 724.0, rides 126\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 1077, reward 292.0, memory_length 2000, epsilon 0.3788416951208248, time 728.0, rides 124\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 1078, reward 620.0, memory_length 2000, epsilon 0.378500737595216, time 730.0, rides 145\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 1079, reward 332.0, memory_length 2000, epsilon 0.3781600869313803, time 724.0, rides 123\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 1080, reward 269.0, memory_length 2000, epsilon 0.37781974285314207, time 724.0, rides 136\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 1081, reward 636.0, memory_length 2000, epsilon 0.37747970508457424, time 730.0, rides 124\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 1082, reward 271.0, memory_length 2000, epsilon 0.3771399733499981, time 724.0, rides 117\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 1083, reward 593.0, memory_length 2000, epsilon 0.3768005473739831, time 735.0, rides 142\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 1084, reward 636.0, memory_length 2000, epsilon 0.37646142688134654, time 737.0, rides 124\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 1085, reward 717.0, memory_length 2000, epsilon 0.3761226115971533, time 726.0, rides 128\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1086, reward 657.0, memory_length 2000, epsilon 0.3757841012467159, time 730.0, rides 131\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1087, reward 561.0, memory_length 2000, epsilon 0.3754458955555939, time 728.0, rides 122\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 1088, reward 649.0, memory_length 2000, epsilon 0.37510799424959385, time 721.0, rides 136\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1089, reward 341.0, memory_length 2000, epsilon 0.3747703970547692, time 726.0, rides 128\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 1090, reward 493.0, memory_length 2000, epsilon 0.37443310369741994, time 734.0, rides 126\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 1091, reward 323.0, memory_length 2000, epsilon 0.37409611390409225, time 722.0, rides 129\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 1092, reward 447.0, memory_length 2000, epsilon 0.3737594274015786, time 728.0, rides 135\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1093, reward 513.0, memory_length 2000, epsilon 0.37342304391691716, time 731.0, rides 116\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 1094, reward 259.0, memory_length 2000, epsilon 0.37308696317739193, time 722.0, rides 131\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 1095, reward 547.0, memory_length 2000, epsilon 0.3727511849105323, time 726.0, rides 130\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1096, reward 383.0, memory_length 2000, epsilon 0.3724157088441128, time 726.0, rides 127\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 1097, reward 334.0, memory_length 2000, epsilon 0.3720805347061531, time 721.0, rides 139\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 1098, reward 492.0, memory_length 2000, epsilon 0.37174566222491756, time 723.0, rides 129\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 1099, reward 461.0, memory_length 2000, epsilon 0.3714110911289151, time 732.0, rides 128\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1100, reward 254.0, memory_length 2000, epsilon 0.3710768211468991, time 728.0, rides 127\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 1101, reward 337.0, memory_length 2000, epsilon 0.3707428520078669, time 734.0, rides 123\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 1102, reward 557.0, memory_length 2000, epsilon 0.3704091834410598, time 728.0, rides 128\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 1103, reward 263.0, memory_length 2000, epsilon 0.37007581517596283, time 725.0, rides 132\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1104, reward 279.0, memory_length 2000, epsilon 0.36974274694230447, time 725.0, rides 130\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1105, reward 517.0, memory_length 2000, epsilon 0.3694099784700564, time 729.0, rides 128\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 1106, reward 69.0, memory_length 2000, epsilon 0.36907750948943335, time 730.0, rides 126\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1107, reward 233.0, memory_length 2000, epsilon 0.36874533973089285, time 730.0, rides 127\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 1108, reward 179.0, memory_length 2000, epsilon 0.36841346892513505, time 725.0, rides 123\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1109, reward 392.0, memory_length 2000, epsilon 0.36808189680310244, time 727.0, rides 117\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 1110, reward 436.0, memory_length 2000, epsilon 0.36775062309597967, time 727.0, rides 125\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 1111, reward 250.0, memory_length 2000, epsilon 0.3674196475351933, time 725.0, rides 122\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1112, reward 422.0, memory_length 2000, epsilon 0.36708896985241163, time 724.0, rides 128\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 1113, reward 415.0, memory_length 2000, epsilon 0.36675858977954445, time 741.0, rides 122\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 1114, reward 116.0, memory_length 2000, epsilon 0.36642850704874286, time 722.0, rides 113\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 1115, reward 459.0, memory_length 2000, epsilon 0.36609872139239896, time 722.0, rides 144\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 1116, reward 541.0, memory_length 2000, epsilon 0.3657692325431458, time 734.0, rides 121\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 1117, reward 126.0, memory_length 2000, epsilon 0.36544004023385696, time 727.0, rides 117\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1118, reward 402.0, memory_length 2000, epsilon 0.36511114419764645, time 736.0, rides 132\n",
      "Initial State is  [4, 13, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1119, reward 520.0, memory_length 2000, epsilon 0.3647825441678686, time 727.0, rides 132\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 1120, reward 403.0, memory_length 2000, epsilon 0.3644542398781175, time 729.0, rides 119\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1121, reward 442.0, memory_length 2000, epsilon 0.3641262310622272, time 735.0, rides 123\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1122, reward 453.0, memory_length 2000, epsilon 0.36379851745427116, time 723.0, rides 130\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 1123, reward 232.0, memory_length 2000, epsilon 0.3634710987885623, time 737.0, rides 131\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 1124, reward 632.0, memory_length 2000, epsilon 0.3631439747996526, time 731.0, rides 131\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 1125, reward 532.0, memory_length 2000, epsilon 0.36281714522233294, time 728.0, rides 140\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 1126, reward 657.0, memory_length 2000, epsilon 0.36249060979163283, time 729.0, rides 130\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1127, reward 161.0, memory_length 2000, epsilon 0.36216436824282033, time 735.0, rides 146\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 1128, reward 438.0, memory_length 2000, epsilon 0.3618384203114018, time 729.0, rides 130\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 1129, reward 373.0, memory_length 2000, epsilon 0.3615127657331215, time 723.0, rides 131\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 1130, reward 474.0, memory_length 2000, epsilon 0.36118740424396173, time 735.0, rides 119\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 1131, reward 512.0, memory_length 2000, epsilon 0.36086233558014214, time 726.0, rides 132\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1132, reward 512.0, memory_length 2000, epsilon 0.36053755947812, time 733.0, rides 128\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 1133, reward 447.0, memory_length 2000, epsilon 0.36021307567458966, time 724.0, rides 124\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 1134, reward 407.0, memory_length 2000, epsilon 0.3598888839064825, time 729.0, rides 132\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 1135, reward 389.0, memory_length 2000, epsilon 0.35956498391096664, time 728.0, rides 137\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 1136, reward 698.0, memory_length 2000, epsilon 0.35924137542544676, time 734.0, rides 137\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 1137, reward 329.0, memory_length 2000, epsilon 0.35891805818756384, time 731.0, rides 131\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 1138, reward 180.0, memory_length 2000, epsilon 0.35859503193519504, time 727.0, rides 125\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1139, reward 555.0, memory_length 2000, epsilon 0.35827229640645336, time 742.0, rides 129\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1140, reward 380.0, memory_length 2000, epsilon 0.35794985133968754, time 730.0, rides 137\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 1141, reward 374.0, memory_length 2000, epsilon 0.3576276964734818, time 730.0, rides 135\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 1142, reward 236.0, memory_length 2000, epsilon 0.3573058315466557, time 738.0, rides 124\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 1143, reward 256.0, memory_length 2000, epsilon 0.3569842562982637, time 731.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 1144, reward 318.0, memory_length 2000, epsilon 0.35666297046759526, time 726.0, rides 138\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 1145, reward 452.0, memory_length 2000, epsilon 0.3563419737941744, time 731.0, rides 120\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 1146, reward 388.0, memory_length 2000, epsilon 0.3560212660177597, time 725.0, rides 135\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 1147, reward 287.0, memory_length 2000, epsilon 0.3557008468783437, time 727.0, rides 120\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 1148, reward 380.0, memory_length 2000, epsilon 0.3553807161161532, time 730.0, rides 124\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 1149, reward 492.0, memory_length 2000, epsilon 0.35506087347164866, time 732.0, rides 124\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 1150, reward 791.0, memory_length 2000, epsilon 0.35474131868552417, time 732.0, rides 123\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1151, reward 317.0, memory_length 2000, epsilon 0.3544220514987072, time 723.0, rides 124\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 1152, reward 520.0, memory_length 2000, epsilon 0.3541030716523584, time 732.0, rides 129\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 1153, reward 511.0, memory_length 2000, epsilon 0.35378437888787123, time 729.0, rides 131\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 1154, reward 773.0, memory_length 2000, epsilon 0.35346597294687215, time 724.0, rides 139\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 1155, reward 401.0, memory_length 2000, epsilon 0.35314785357121997, time 723.0, rides 120\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 1156, reward 410.0, memory_length 2000, epsilon 0.3528300205030059, time 726.0, rides 131\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 1157, reward 336.0, memory_length 2000, epsilon 0.35251247348455317, time 729.0, rides 123\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1158, reward 338.0, memory_length 2000, epsilon 0.35219521225841705, time 737.0, rides 136\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 1159, reward 480.0, memory_length 2000, epsilon 0.3518782365673845, time 734.0, rides 125\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 1160, reward 492.0, memory_length 2000, epsilon 0.3515615461544738, time 729.0, rides 143\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1161, reward 480.0, memory_length 2000, epsilon 0.3512451407629348, time 730.0, rides 131\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 1162, reward 483.0, memory_length 2000, epsilon 0.35092902013624816, time 725.0, rides 111\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 1163, reward 349.0, memory_length 2000, epsilon 0.3506131840181255, time 726.0, rides 132\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1164, reward 332.0, memory_length 2000, epsilon 0.3502976321525092, time 727.0, rides 127\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 1165, reward 354.0, memory_length 2000, epsilon 0.34998236428357193, time 720.0, rides 127\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 1166, reward 402.0, memory_length 2000, epsilon 0.3496673801557167, time 723.0, rides 132\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1167, reward 335.0, memory_length 2000, epsilon 0.3493526795135765, time 723.0, rides 138\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1168, reward 478.0, memory_length 2000, epsilon 0.3490382621020143, time 732.0, rides 113\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 1169, reward 385.0, memory_length 2000, epsilon 0.34872412766612243, time 734.0, rides 120\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 1170, reward 250.0, memory_length 2000, epsilon 0.3484102759512229, time 729.0, rides 123\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 1171, reward 640.0, memory_length 2000, epsilon 0.3480967067028668, time 733.0, rides 130\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 1172, reward 274.0, memory_length 2000, epsilon 0.34778341966683424, time 731.0, rides 122\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 1173, reward 419.0, memory_length 2000, epsilon 0.3474704145891341, time 729.0, rides 121\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1174, reward 539.0, memory_length 2000, epsilon 0.34715769121600387, time 727.0, rides 124\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 1175, reward 355.0, memory_length 2000, epsilon 0.3468452492939095, time 734.0, rides 119\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 1176, reward 353.0, memory_length 2000, epsilon 0.34653308856954496, time 731.0, rides 139\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 1177, reward 431.0, memory_length 2000, epsilon 0.34622120878983237, time 730.0, rides 128\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 1178, reward 230.0, memory_length 2000, epsilon 0.3459096097019215, time 739.0, rides 124\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1179, reward 712.0, memory_length 2000, epsilon 0.3455982910531898, time 722.0, rides 125\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 1180, reward 223.0, memory_length 2000, epsilon 0.34528725259124193, time 728.0, rides 127\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1181, reward 750.0, memory_length 2000, epsilon 0.3449764940639098, time 723.0, rides 135\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1182, reward 509.0, memory_length 2000, epsilon 0.3446660152192523, time 743.0, rides 126\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 1183, reward 523.0, memory_length 2000, epsilon 0.34435581580555497, time 730.0, rides 114\n",
      "Initial State is  [0, 17, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1184, reward 342.0, memory_length 2000, epsilon 0.34404589557133, time 736.0, rides 128\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 1185, reward 732.0, memory_length 2000, epsilon 0.3437362542653158, time 729.0, rides 132\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1186, reward 407.0, memory_length 2000, epsilon 0.343426891636477, time 735.0, rides 117\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 1187, reward 537.0, memory_length 2000, epsilon 0.34311780743400416, time 723.0, rides 136\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 1188, reward 319.0, memory_length 2000, epsilon 0.3428090014073136, time 731.0, rides 126\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 1189, reward 484.0, memory_length 2000, epsilon 0.342500473306047, time 734.0, rides 132\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 1190, reward 549.0, memory_length 2000, epsilon 0.34219222288007156, time 722.0, rides 121\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 1191, reward 306.0, memory_length 2000, epsilon 0.3418842498794795, time 729.0, rides 116\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 1192, reward 372.0, memory_length 2000, epsilon 0.341576554054588, time 734.0, rides 135\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1193, reward 516.0, memory_length 2000, epsilon 0.3412691351559388, time 745.0, rides 124\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 1194, reward 470.0, memory_length 2000, epsilon 0.34096199293429846, time 724.0, rides 133\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 1195, reward 290.0, memory_length 2000, epsilon 0.3406551271406576, time 728.0, rides 132\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1196, reward 556.0, memory_length 2000, epsilon 0.340348537526231, time 735.0, rides 130\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 1197, reward 557.0, memory_length 2000, epsilon 0.3400422238424574, time 726.0, rides 132\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 1198, reward 741.0, memory_length 2000, epsilon 0.3397361858409992, time 732.0, rides 129\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 1199, reward 580.0, memory_length 2000, epsilon 0.3394304232737423, time 725.0, rides 125\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 1200, reward 682.0, memory_length 2000, epsilon 0.3391249358927959, time 722.0, rides 125\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1201, reward 239.0, memory_length 2000, epsilon 0.3388197234504924, time 731.0, rides 134\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1202, reward 753.0, memory_length 2000, epsilon 0.3385147856993869, time 728.0, rides 131\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 1203, reward 473.0, memory_length 2000, epsilon 0.33821012239225745, time 735.0, rides 131\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 1204, reward 418.0, memory_length 2000, epsilon 0.33790573328210444, time 732.0, rides 110\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1205, reward 428.0, memory_length 2000, epsilon 0.33760161812215056, time 722.0, rides 137\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 1206, reward 346.0, memory_length 2000, epsilon 0.3372977766658406, time 730.0, rides 131\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 1207, reward 581.0, memory_length 2000, epsilon 0.3369942086668413, time 729.0, rides 132\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 1208, reward 431.0, memory_length 2000, epsilon 0.33669091387904115, time 724.0, rides 122\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 1209, reward 654.0, memory_length 2000, epsilon 0.33638789205655, time 733.0, rides 122\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 1210, reward 624.0, memory_length 2000, epsilon 0.3360851429536991, time 730.0, rides 129\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 1211, reward 481.0, memory_length 2000, epsilon 0.3357826663250408, time 729.0, rides 131\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1212, reward 177.0, memory_length 2000, epsilon 0.33548046192534825, time 740.0, rides 128\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1213, reward 428.0, memory_length 2000, epsilon 0.3351785295096154, time 731.0, rides 125\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1214, reward 389.0, memory_length 2000, epsilon 0.33487686883305673, time 735.0, rides 129\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 1215, reward 661.0, memory_length 2000, epsilon 0.33457547965110696, time 728.0, rides 123\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 1216, reward 442.0, memory_length 2000, epsilon 0.33427436171942093, time 730.0, rides 133\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 1217, reward 264.0, memory_length 2000, epsilon 0.33397351479387344, time 728.0, rides 136\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 1218, reward 158.0, memory_length 2000, epsilon 0.33367293863055897, time 731.0, rides 116\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1219, reward 211.0, memory_length 2000, epsilon 0.33337263298579145, time 721.0, rides 125\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 1220, reward 530.0, memory_length 2000, epsilon 0.33307259761610425, time 729.0, rides 138\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 1221, reward 440.0, memory_length 2000, epsilon 0.3327728322782498, time 728.0, rides 121\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1222, reward 464.0, memory_length 2000, epsilon 0.3324733367291993, time 723.0, rides 120\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 1223, reward 97.0, memory_length 2000, epsilon 0.33217411072614306, time 723.0, rides 125\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 1224, reward 665.0, memory_length 2000, epsilon 0.33187515402648954, time 731.0, rides 132\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 1225, reward 374.0, memory_length 2000, epsilon 0.3315764663878657, time 723.0, rides 122\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 1226, reward 153.0, memory_length 2000, epsilon 0.33127804756811663, time 725.0, rides 132\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 1227, reward 482.0, memory_length 2000, epsilon 0.3309798973253053, time 726.0, rides 119\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1228, reward 179.0, memory_length 2000, epsilon 0.3306820154177125, time 731.0, rides 138\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 1229, reward 242.0, memory_length 2000, epsilon 0.3303844016038366, time 737.0, rides 111\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 1230, reward 618.0, memory_length 2000, epsilon 0.33008705564239316, time 728.0, rides 128\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 1231, reward 283.0, memory_length 2000, epsilon 0.329789977292315, time 726.0, rides 126\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 1232, reward 353.0, memory_length 2000, epsilon 0.32949316631275194, time 727.0, rides 133\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 1233, reward 475.0, memory_length 2000, epsilon 0.32919662246307047, time 727.0, rides 127\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 1234, reward 519.0, memory_length 2000, epsilon 0.3289003455028537, time 722.0, rides 122\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 1235, reward 155.0, memory_length 2000, epsilon 0.32860433519190113, time 730.0, rides 144\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 1236, reward 493.0, memory_length 2000, epsilon 0.32830859129022844, time 725.0, rides 118\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 1237, reward 707.0, memory_length 2000, epsilon 0.3280131135580672, time 731.0, rides 121\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 1238, reward 551.0, memory_length 2000, epsilon 0.32771790175586496, time 728.0, rides 109\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 1239, reward 566.0, memory_length 2000, epsilon 0.3274229556442847, time 746.0, rides 130\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1240, reward 644.0, memory_length 2000, epsilon 0.3271282749842048, time 736.0, rides 139\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 1241, reward 327.0, memory_length 2000, epsilon 0.32683385953671906, time 733.0, rides 122\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 1242, reward 713.0, memory_length 2000, epsilon 0.326539709063136, time 730.0, rides 135\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 1243, reward 441.0, memory_length 2000, epsilon 0.3262458233249792, time 725.0, rides 132\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 1244, reward 288.0, memory_length 2000, epsilon 0.32595220208398673, time 732.0, rides 109\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 1245, reward 403.0, memory_length 2000, epsilon 0.3256588451021111, time 726.0, rides 127\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 1246, reward 602.0, memory_length 2000, epsilon 0.32536575214151925, time 730.0, rides 141\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 1247, reward 508.0, memory_length 2000, epsilon 0.3250729229645919, time 727.0, rides 145\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 1248, reward 590.0, memory_length 2000, epsilon 0.32478035733392374, time 729.0, rides 129\n",
      "Initial State is  [1, 12, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1249, reward 154.0, memory_length 2000, epsilon 0.3244880550123232, time 730.0, rides 136\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1250, reward 629.0, memory_length 2000, epsilon 0.3241960157628121, time 730.0, rides 135\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 1251, reward 244.0, memory_length 2000, epsilon 0.32390423934862556, time 725.0, rides 133\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 1252, reward 545.0, memory_length 2000, epsilon 0.3236127255332118, time 730.0, rides 129\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 1253, reward 404.0, memory_length 2000, epsilon 0.32332147408023193, time 721.0, rides 132\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1254, reward 254.0, memory_length 2000, epsilon 0.3230304847535597, time 732.0, rides 125\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1255, reward 727.0, memory_length 2000, epsilon 0.3227397573172815, time 724.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 1256, reward 573.0, memory_length 2000, epsilon 0.32244929153569596, time 728.0, rides 129\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 1257, reward 326.0, memory_length 2000, epsilon 0.3221590871733138, time 724.0, rides 140\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 1258, reward 615.0, memory_length 2000, epsilon 0.32186914399485783, time 738.0, rides 122\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 1259, reward 616.0, memory_length 2000, epsilon 0.3215794617652625, time 728.0, rides 130\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1260, reward 577.0, memory_length 2000, epsilon 0.3212900402496737, time 735.0, rides 134\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 1261, reward 503.0, memory_length 2000, epsilon 0.321000879213449, time 741.0, rides 125\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 1262, reward 541.0, memory_length 2000, epsilon 0.3207119784221569, time 725.0, rides 133\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 1263, reward 710.0, memory_length 2000, epsilon 0.32042333764157693, time 732.0, rides 130\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 1264, reward 564.0, memory_length 2000, epsilon 0.32013495663769953, time 735.0, rides 124\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 1265, reward 407.0, memory_length 2000, epsilon 0.3198468351767256, time 726.0, rides 130\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1266, reward 545.0, memory_length 2000, epsilon 0.31955897302506653, time 738.0, rides 120\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 1267, reward 586.0, memory_length 2000, epsilon 0.31927136994934396, time 723.0, rides 134\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 1268, reward 412.0, memory_length 2000, epsilon 0.31898402571638956, time 729.0, rides 123\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 1269, reward 436.0, memory_length 2000, epsilon 0.3186969400932448, time 733.0, rides 123\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 1270, reward 472.0, memory_length 2000, epsilon 0.31841011284716086, time 740.0, rides 132\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 1271, reward 256.0, memory_length 2000, epsilon 0.3181235437455984, time 732.0, rides 141\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 1272, reward 339.0, memory_length 2000, epsilon 0.31783723255622737, time 727.0, rides 136\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 1273, reward 252.0, memory_length 2000, epsilon 0.31755117904692676, time 722.0, rides 122\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 1274, reward 489.0, memory_length 2000, epsilon 0.3172653829857845, time 731.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1275, reward 386.0, memory_length 2000, epsilon 0.3169798441410973, time 724.0, rides 123\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 1276, reward 139.0, memory_length 2000, epsilon 0.31669456228137033, time 736.0, rides 128\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 1277, reward 568.0, memory_length 2000, epsilon 0.3164095371753171, time 735.0, rides 141\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 1278, reward 215.0, memory_length 2000, epsilon 0.31612476859185934, time 724.0, rides 129\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 1279, reward 662.0, memory_length 2000, epsilon 0.3158402563001267, time 735.0, rides 124\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 1280, reward 395.0, memory_length 2000, epsilon 0.31555600006945655, time 739.0, rides 129\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 1281, reward 555.0, memory_length 2000, epsilon 0.31527199966939407, time 727.0, rides 134\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 1282, reward 495.0, memory_length 2000, epsilon 0.3149882548696916, time 729.0, rides 136\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1283, reward 368.0, memory_length 2000, epsilon 0.3147047654403089, time 735.0, rides 137\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1284, reward 704.0, memory_length 2000, epsilon 0.31442153115141264, time 724.0, rides 146\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 1285, reward 532.0, memory_length 2000, epsilon 0.31413855177337635, time 722.0, rides 142\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 1286, reward 576.0, memory_length 2000, epsilon 0.31385582707678034, time 739.0, rides 132\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 1287, reward 352.0, memory_length 2000, epsilon 0.3135733568324112, time 725.0, rides 131\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 1288, reward 665.0, memory_length 2000, epsilon 0.313291140811262, time 727.0, rides 146\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 1289, reward 667.0, memory_length 2000, epsilon 0.3130091787845319, time 723.0, rides 133\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 1290, reward 455.0, memory_length 2000, epsilon 0.3127274705236258, time 732.0, rides 135\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 1291, reward 687.0, memory_length 2000, epsilon 0.3124460158001546, time 726.0, rides 124\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 1292, reward 654.0, memory_length 2000, epsilon 0.3121648143859344, time 733.0, rides 127\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 1293, reward 412.0, memory_length 2000, epsilon 0.31188386605298707, time 735.0, rides 130\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1294, reward 298.0, memory_length 2000, epsilon 0.31160317057353937, time 726.0, rides 124\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 1295, reward 251.0, memory_length 2000, epsilon 0.3113227277200232, time 736.0, rides 135\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 1296, reward 422.0, memory_length 2000, epsilon 0.31104253726507514, time 727.0, rides 123\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 1297, reward -4.0, memory_length 2000, epsilon 0.3107625989815366, time 726.0, rides 125\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1298, reward 655.0, memory_length 2000, epsilon 0.3104829126424532, time 729.0, rides 137\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 1299, reward 447.0, memory_length 2000, epsilon 0.310203478021075, time 728.0, rides 137\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 1300, reward 672.0, memory_length 2000, epsilon 0.30992429489085604, time 740.0, rides 128\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 1301, reward 598.0, memory_length 2000, epsilon 0.30964536302545426, time 729.0, rides 124\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 1302, reward 455.0, memory_length 2000, epsilon 0.30936668219873137, time 736.0, rides 137\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 1303, reward 430.0, memory_length 2000, epsilon 0.3090882521847525, time 727.0, rides 123\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1304, reward 474.0, memory_length 2000, epsilon 0.3088100727577862, time 726.0, rides 131\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1305, reward 504.0, memory_length 2000, epsilon 0.3085321436923042, time 725.0, rides 134\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 1306, reward 554.0, memory_length 2000, epsilon 0.30825446476298113, time 731.0, rides 123\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 1307, reward 419.0, memory_length 2000, epsilon 0.3079770357446944, time 735.0, rides 120\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1308, reward 801.0, memory_length 2000, epsilon 0.3076998564125242, time 725.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1309, reward 474.0, memory_length 2000, epsilon 0.3074229265417529, time 731.0, rides 121\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 1310, reward 490.0, memory_length 2000, epsilon 0.3071462459078653, time 729.0, rides 119\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 1311, reward 350.0, memory_length 2000, epsilon 0.30686981428654825, time 731.0, rides 140\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 1312, reward 620.0, memory_length 2000, epsilon 0.30659363145369034, time 728.0, rides 133\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 1313, reward 687.0, memory_length 2000, epsilon 0.30631769718538204, time 733.0, rides 134\n",
      "Initial State is  [4, 13, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1314, reward 422.0, memory_length 2000, epsilon 0.3060420112579152, time 727.0, rides 125\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 1315, reward 486.0, memory_length 2000, epsilon 0.3057665734477831, time 731.0, rides 144\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 1316, reward 451.0, memory_length 2000, epsilon 0.30549138353168004, time 723.0, rides 110\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 1317, reward 596.0, memory_length 2000, epsilon 0.30521644128650155, time 729.0, rides 133\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 1318, reward 410.0, memory_length 2000, epsilon 0.3049417464893437, time 726.0, rides 118\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 1319, reward 343.0, memory_length 2000, epsilon 0.30466729891750327, time 739.0, rides 128\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 1320, reward 428.0, memory_length 2000, epsilon 0.3043930983484775, time 731.0, rides 114\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 1321, reward 503.0, memory_length 2000, epsilon 0.30411914455996386, time 727.0, rides 117\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 1322, reward 531.0, memory_length 2000, epsilon 0.3038454373298599, time 726.0, rides 112\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 1323, reward 562.0, memory_length 2000, epsilon 0.30357197643626305, time 729.0, rides 122\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 1324, reward 611.0, memory_length 2000, epsilon 0.3032987616574704, time 727.0, rides 135\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 1325, reward 592.0, memory_length 2000, epsilon 0.30302579277197866, time 726.0, rides 125\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 1326, reward 585.0, memory_length 2000, epsilon 0.30275306955848386, time 727.0, rides 128\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 1327, reward 489.0, memory_length 2000, epsilon 0.3024805917958812, time 729.0, rides 141\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 1328, reward 603.0, memory_length 2000, epsilon 0.3022083592632649, time 725.0, rides 134\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 1329, reward 387.0, memory_length 2000, epsilon 0.30193637173992793, time 733.0, rides 128\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 1330, reward 397.0, memory_length 2000, epsilon 0.301664629005362, time 725.0, rides 133\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1331, reward 781.0, memory_length 2000, epsilon 0.3013931308392572, time 725.0, rides 127\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 1332, reward 478.0, memory_length 2000, epsilon 0.30112187702150184, time 728.0, rides 115\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 1333, reward 466.0, memory_length 2000, epsilon 0.30085086733218247, time 724.0, rides 129\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 1334, reward 449.0, memory_length 2000, epsilon 0.3005801015515835, time 729.0, rides 121\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 1335, reward 625.0, memory_length 2000, epsilon 0.30030957946018705, time 730.0, rides 128\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 1336, reward 536.0, memory_length 2000, epsilon 0.30003930083867286, time 727.0, rides 131\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 1337, reward 386.0, memory_length 2000, epsilon 0.29976926546791804, time 729.0, rides 119\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 1338, reward 879.0, memory_length 2000, epsilon 0.29949947312899694, time 733.0, rides 130\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1339, reward 564.0, memory_length 2000, epsilon 0.29922992360318085, time 732.0, rides 123\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 1340, reward 575.0, memory_length 2000, epsilon 0.29896061667193796, time 727.0, rides 130\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 1341, reward 251.0, memory_length 2000, epsilon 0.2986915521169332, time 727.0, rides 138\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1342, reward 400.0, memory_length 2000, epsilon 0.298422729720028, time 723.0, rides 139\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 1343, reward 500.0, memory_length 2000, epsilon 0.29815414926327993, time 723.0, rides 128\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 1344, reward 507.0, memory_length 2000, epsilon 0.297885810528943, time 722.0, rides 127\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 1345, reward 604.0, memory_length 2000, epsilon 0.2976177132994669, time 721.0, rides 122\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 1346, reward 510.0, memory_length 2000, epsilon 0.29734985735749736, time 731.0, rides 118\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 1347, reward 514.0, memory_length 2000, epsilon 0.2970822424858756, time 732.0, rides 127\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1348, reward 532.0, memory_length 2000, epsilon 0.2968148684676383, time 726.0, rides 122\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 1349, reward 440.0, memory_length 2000, epsilon 0.29654773508601745, time 728.0, rides 130\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 1350, reward 508.0, memory_length 2000, epsilon 0.29628084212444006, time 720.0, rides 125\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1351, reward 465.0, memory_length 2000, epsilon 0.29601418936652807, time 733.0, rides 127\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 1352, reward 685.0, memory_length 2000, epsilon 0.2957477765960982, time 728.0, rides 136\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 1353, reward 454.0, memory_length 2000, epsilon 0.2954816035971617, time 732.0, rides 121\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 1354, reward 399.0, memory_length 2000, epsilon 0.29521567015392425, time 728.0, rides 131\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 1355, reward 455.0, memory_length 2000, epsilon 0.2949499760507857, time 727.0, rides 110\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 1356, reward 518.0, memory_length 2000, epsilon 0.29468452107234, time 730.0, rides 126\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 1357, reward 477.0, memory_length 2000, epsilon 0.2944193050033749, time 729.0, rides 114\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 1358, reward 495.0, memory_length 2000, epsilon 0.29415432762887184, time 727.0, rides 123\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1359, reward 357.0, memory_length 2000, epsilon 0.29388958873400584, time 726.0, rides 129\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 1360, reward 295.0, memory_length 2000, epsilon 0.2936250881041452, time 722.0, rides 129\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 1361, reward 197.0, memory_length 2000, epsilon 0.2933608255248515, time 729.0, rides 145\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 1362, reward 196.0, memory_length 2000, epsilon 0.2930968007818791, time 738.0, rides 123\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 1363, reward 431.0, memory_length 2000, epsilon 0.2928330136611754, time 727.0, rides 134\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 1364, reward 585.0, memory_length 2000, epsilon 0.29256946394888034, time 733.0, rides 130\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1365, reward 279.0, memory_length 2000, epsilon 0.2923061514313263, time 725.0, rides 137\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 1366, reward 230.0, memory_length 2000, epsilon 0.29204307589503814, time 732.0, rides 111\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 1367, reward 578.0, memory_length 2000, epsilon 0.2917802371267326, time 738.0, rides 116\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 1368, reward 356.0, memory_length 2000, epsilon 0.29151763491331856, time 734.0, rides 144\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 1369, reward 374.0, memory_length 2000, epsilon 0.2912552690418966, time 732.0, rides 133\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 1370, reward 418.0, memory_length 2000, epsilon 0.2909931392997589, time 733.0, rides 117\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 1371, reward 649.0, memory_length 2000, epsilon 0.2907312454743891, time 726.0, rides 118\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 1372, reward 387.0, memory_length 2000, epsilon 0.2904695873534622, time 728.0, rides 148\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 1373, reward 385.0, memory_length 2000, epsilon 0.29020816472484406, time 731.0, rides 115\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1374, reward 634.0, memory_length 2000, epsilon 0.2899469773765917, time 726.0, rides 128\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1375, reward 412.0, memory_length 2000, epsilon 0.28968602509695274, time 726.0, rides 130\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 1376, reward 526.0, memory_length 2000, epsilon 0.2894253076743655, time 734.0, rides 134\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 1377, reward 743.0, memory_length 2000, epsilon 0.28916482489745854, time 739.0, rides 133\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1378, reward 333.0, memory_length 2000, epsilon 0.2889045765550508, time 729.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1379, reward 380.0, memory_length 2000, epsilon 0.2886445624361513, time 732.0, rides 107\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 1380, reward 292.0, memory_length 2000, epsilon 0.28838478232995873, time 726.0, rides 131\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1381, reward 460.0, memory_length 2000, epsilon 0.28812523602586176, time 734.0, rides 125\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 1382, reward 341.0, memory_length 2000, epsilon 0.28786592331343847, time 723.0, rides 134\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1383, reward 426.0, memory_length 2000, epsilon 0.2876068439824564, time 722.0, rides 126\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 1384, reward 504.0, memory_length 2000, epsilon 0.2873479978228722, time 730.0, rides 134\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 1385, reward 384.0, memory_length 2000, epsilon 0.2870893846248316, time 746.0, rides 124\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1386, reward 542.0, memory_length 2000, epsilon 0.28683100417866925, time 729.0, rides 127\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 1387, reward 571.0, memory_length 2000, epsilon 0.2865728562749084, time 731.0, rides 127\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 1388, reward 509.0, memory_length 2000, epsilon 0.286314940704261, time 729.0, rides 132\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 1389, reward 1018.0, memory_length 2000, epsilon 0.28605725725762715, time 730.0, rides 131\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 1390, reward 458.0, memory_length 2000, epsilon 0.28579980572609526, time 733.0, rides 127\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1391, reward 227.0, memory_length 2000, epsilon 0.2855425859009418, time 729.0, rides 124\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 1392, reward 560.0, memory_length 2000, epsilon 0.2852855975736309, time 731.0, rides 132\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 1393, reward 477.0, memory_length 2000, epsilon 0.2850288405358147, time 734.0, rides 139\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 1394, reward 558.0, memory_length 2000, epsilon 0.28477231457933244, time 733.0, rides 136\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1395, reward 310.0, memory_length 2000, epsilon 0.284516019496211, time 733.0, rides 145\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 1396, reward 329.0, memory_length 2000, epsilon 0.2842599550786644, time 726.0, rides 127\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 1397, reward 559.0, memory_length 2000, epsilon 0.2840041211190936, time 726.0, rides 127\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 1398, reward 548.0, memory_length 2000, epsilon 0.28374851741008644, time 727.0, rides 131\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 1399, reward 489.0, memory_length 2000, epsilon 0.28349314374441736, time 738.0, rides 126\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 1400, reward 310.0, memory_length 2000, epsilon 0.2832379999150474, time 721.0, rides 133\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1401, reward 228.0, memory_length 2000, epsilon 0.2829830857151238, time 728.0, rides 130\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 1402, reward 225.0, memory_length 2000, epsilon 0.2827284009379802, time 739.0, rides 122\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 1403, reward 502.0, memory_length 2000, epsilon 0.282473945377136, time 726.0, rides 136\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 1404, reward 446.0, memory_length 2000, epsilon 0.2822197188262966, time 734.0, rides 131\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 1405, reward 482.0, memory_length 2000, epsilon 0.2819657210793529, time 729.0, rides 133\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 1406, reward 240.0, memory_length 2000, epsilon 0.2817119519303815, time 730.0, rides 131\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 1407, reward 671.0, memory_length 2000, epsilon 0.2814584111736442, time 729.0, rides 125\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 1408, reward 635.0, memory_length 2000, epsilon 0.2812050986035879, time 726.0, rides 119\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 1409, reward 444.0, memory_length 2000, epsilon 0.28095201401484465, time 723.0, rides 125\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1410, reward 430.0, memory_length 2000, epsilon 0.28069915720223126, time 732.0, rides 125\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1411, reward 140.0, memory_length 2000, epsilon 0.28044652796074926, time 729.0, rides 128\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 1412, reward 157.0, memory_length 2000, epsilon 0.2801941260855846, time 724.0, rides 127\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1413, reward 574.0, memory_length 2000, epsilon 0.27994195137210753, time 723.0, rides 136\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 1414, reward 496.0, memory_length 2000, epsilon 0.27969000361587265, time 729.0, rides 119\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 1415, reward 727.0, memory_length 2000, epsilon 0.2794382826126184, time 736.0, rides 122\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1416, reward 638.0, memory_length 2000, epsilon 0.27918678815826703, time 732.0, rides 128\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 1417, reward 314.0, memory_length 2000, epsilon 0.2789355200489246, time 729.0, rides 131\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 1418, reward 551.0, memory_length 2000, epsilon 0.27868447808088054, time 731.0, rides 121\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 1419, reward 452.0, memory_length 2000, epsilon 0.27843366205060777, time 721.0, rides 125\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 1420, reward 824.0, memory_length 2000, epsilon 0.2781830717547622, time 729.0, rides 136\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 1421, reward 259.0, memory_length 2000, epsilon 0.2779327069901829, time 736.0, rides 134\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 1422, reward 390.0, memory_length 2000, epsilon 0.27768256755389176, time 729.0, rides 144\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 1423, reward 651.0, memory_length 2000, epsilon 0.27743265324309324, time 731.0, rides 126\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 1424, reward 419.0, memory_length 2000, epsilon 0.27718296385517444, time 735.0, rides 116\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 1425, reward 435.0, memory_length 2000, epsilon 0.27693349918770477, time 727.0, rides 126\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 1426, reward 664.0, memory_length 2000, epsilon 0.27668425903843585, time 736.0, rides 134\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1427, reward 522.0, memory_length 2000, epsilon 0.2764352432053013, time 731.0, rides 127\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 1428, reward 574.0, memory_length 2000, epsilon 0.2761864514864165, time 727.0, rides 141\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 1429, reward 476.0, memory_length 2000, epsilon 0.27593788368007877, time 725.0, rides 133\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 1430, reward 211.0, memory_length 2000, epsilon 0.2756895395847667, time 734.0, rides 132\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 1431, reward 650.0, memory_length 2000, epsilon 0.27544141899914043, time 728.0, rides 118\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 1432, reward 476.0, memory_length 2000, epsilon 0.2751935217220412, time 727.0, rides 136\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 1433, reward 510.0, memory_length 2000, epsilon 0.27494584755249135, time 733.0, rides 125\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1434, reward 541.0, memory_length 2000, epsilon 0.2746983962896941, time 726.0, rides 112\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 1435, reward 589.0, memory_length 2000, epsilon 0.2744511677330334, time 724.0, rides 122\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 1436, reward 507.0, memory_length 2000, epsilon 0.2742041616820737, time 727.0, rides 121\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 1437, reward 495.0, memory_length 2000, epsilon 0.27395737793655983, time 725.0, rides 117\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 1438, reward 455.0, memory_length 2000, epsilon 0.2737108162964169, time 728.0, rides 123\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 1439, reward 623.0, memory_length 2000, epsilon 0.27346447656175016, time 731.0, rides 119\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 1440, reward 383.0, memory_length 2000, epsilon 0.2732183585328446, time 724.0, rides 132\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 1441, reward 614.0, memory_length 2000, epsilon 0.272972462010165, time 726.0, rides 137\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1442, reward 358.0, memory_length 2000, epsilon 0.27272678679435586, time 727.0, rides 130\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 1443, reward 666.0, memory_length 2000, epsilon 0.2724813326862409, time 722.0, rides 122\n",
      "Initial State is  [3, 22, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1444, reward 728.0, memory_length 2000, epsilon 0.2722360994868233, time 729.0, rides 134\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 1445, reward 703.0, memory_length 2000, epsilon 0.2719910869972852, time 725.0, rides 119\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 1446, reward 658.0, memory_length 2000, epsilon 0.2717462950189876, time 730.0, rides 128\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 1447, reward 715.0, memory_length 2000, epsilon 0.2715017233534705, time 733.0, rides 117\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 1448, reward 425.0, memory_length 2000, epsilon 0.27125737180245235, time 727.0, rides 126\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 1449, reward 596.0, memory_length 2000, epsilon 0.2710132401678301, time 730.0, rides 124\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 1450, reward 807.0, memory_length 2000, epsilon 0.2707693282516791, time 723.0, rides 118\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 1451, reward 420.0, memory_length 2000, epsilon 0.2705256358562526, time 737.0, rides 141\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 1452, reward 298.0, memory_length 2000, epsilon 0.270282162783982, time 730.0, rides 121\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 1453, reward 314.0, memory_length 2000, epsilon 0.2700389088374764, time 728.0, rides 115\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 1454, reward 416.0, memory_length 2000, epsilon 0.26979587381952264, time 733.0, rides 127\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 1455, reward 1022.0, memory_length 2000, epsilon 0.26955305753308506, time 733.0, rides 128\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1456, reward 300.0, memory_length 2000, epsilon 0.2693104597813053, time 727.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 1457, reward 614.0, memory_length 2000, epsilon 0.2690680803675021, time 734.0, rides 126\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 1458, reward 787.0, memory_length 2000, epsilon 0.2688259190951714, time 727.0, rides 135\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 1459, reward 425.0, memory_length 2000, epsilon 0.26858397576798576, time 725.0, rides 117\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 1460, reward 345.0, memory_length 2000, epsilon 0.2683422501897946, time 725.0, rides 118\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 1461, reward 449.0, memory_length 2000, epsilon 0.26810074216462376, time 734.0, rides 125\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 1462, reward 490.0, memory_length 2000, epsilon 0.2678594514966756, time 736.0, rides 120\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 1463, reward 364.0, memory_length 2000, epsilon 0.2676183779903286, time 734.0, rides 114\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 1464, reward 379.0, memory_length 2000, epsilon 0.2673775214501373, time 726.0, rides 125\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 1465, reward 332.0, memory_length 2000, epsilon 0.2671368816808322, time 727.0, rides 135\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 1466, reward 523.0, memory_length 2000, epsilon 0.26689645848731947, time 726.0, rides 130\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 1467, reward 596.0, memory_length 2000, epsilon 0.2666562516746809, time 733.0, rides 130\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 1468, reward 721.0, memory_length 2000, epsilon 0.2664162610481737, time 728.0, rides 124\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 1469, reward 431.0, memory_length 2000, epsilon 0.26617648641323033, time 727.0, rides 111\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 1470, reward 543.0, memory_length 2000, epsilon 0.2659369275754584, time 733.0, rides 124\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 1471, reward 548.0, memory_length 2000, epsilon 0.2656975843406405, time 727.0, rides 125\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1472, reward 672.0, memory_length 2000, epsilon 0.26545845651473393, time 732.0, rides 122\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 1473, reward 534.0, memory_length 2000, epsilon 0.26521954390387065, time 734.0, rides 110\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1474, reward 459.0, memory_length 2000, epsilon 0.26498084631435714, time 734.0, rides 122\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 1475, reward 376.0, memory_length 2000, epsilon 0.2647423635526742, time 726.0, rides 127\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 1476, reward 530.0, memory_length 2000, epsilon 0.2645040954254768, time 729.0, rides 137\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 1477, reward 577.0, memory_length 2000, epsilon 0.2642660417395939, time 730.0, rides 117\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 1478, reward 401.0, memory_length 2000, epsilon 0.2640282023020283, time 730.0, rides 126\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 1479, reward 545.0, memory_length 2000, epsilon 0.26379057691995644, time 726.0, rides 139\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 1480, reward 457.0, memory_length 2000, epsilon 0.2635531654007285, time 737.0, rides 134\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1481, reward 783.0, memory_length 2000, epsilon 0.2633159675518678, time 738.0, rides 131\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1482, reward 587.0, memory_length 2000, epsilon 0.26307898318107115, time 732.0, rides 128\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 1483, reward 594.0, memory_length 2000, epsilon 0.26284221209620817, time 734.0, rides 130\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1484, reward 791.0, memory_length 2000, epsilon 0.2626056541053216, time 725.0, rides 127\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 1485, reward 641.0, memory_length 2000, epsilon 0.2623693090166268, time 726.0, rides 126\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 1486, reward 586.0, memory_length 2000, epsilon 0.2621331766385118, time 726.0, rides 133\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 1487, reward 249.0, memory_length 2000, epsilon 0.2618972567795372, time 726.0, rides 124\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 1488, reward 371.0, memory_length 2000, epsilon 0.2616615492484356, time 723.0, rides 117\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 1489, reward 475.0, memory_length 2000, epsilon 0.261426053854112, time 728.0, rides 125\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 1490, reward 659.0, memory_length 2000, epsilon 0.2611907704056433, time 732.0, rides 129\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 1491, reward 828.0, memory_length 2000, epsilon 0.26095569871227825, time 727.0, rides 134\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 1492, reward 524.0, memory_length 2000, epsilon 0.2607208385834372, time 734.0, rides 122\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1493, reward 592.0, memory_length 2000, epsilon 0.2604861898287121, time 724.0, rides 127\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 1494, reward 578.0, memory_length 2000, epsilon 0.26025175225786623, time 738.0, rides 123\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 1495, reward 183.0, memory_length 2000, epsilon 0.26001752568083414, time 724.0, rides 123\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 1496, reward 549.0, memory_length 2000, epsilon 0.25978350990772137, time 731.0, rides 147\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1497, reward 544.0, memory_length 2000, epsilon 0.2595497047488044, time 728.0, rides 122\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 1498, reward 594.0, memory_length 2000, epsilon 0.2593161100145305, time 726.0, rides 124\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 1499, reward 276.0, memory_length 2000, epsilon 0.2590827255155174, time 725.0, rides 120\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 1500, reward 724.0, memory_length 2000, epsilon 0.2588495510625535, time 725.0, rides 117\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 1501, reward 548.0, memory_length 2000, epsilon 0.2586165864665972, time 728.0, rides 132\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 1502, reward 876.0, memory_length 2000, epsilon 0.25838383153877725, time 729.0, rides 121\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 1503, reward 552.0, memory_length 2000, epsilon 0.25815128609039234, time 730.0, rides 123\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 1504, reward 749.0, memory_length 2000, epsilon 0.257918949932911, time 731.0, rides 125\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 1505, reward 312.0, memory_length 2000, epsilon 0.25768682287797134, time 731.0, rides 131\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 1506, reward 142.0, memory_length 2000, epsilon 0.25745490473738114, time 727.0, rides 123\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 1507, reward 537.0, memory_length 2000, epsilon 0.2572231953231175, time 728.0, rides 121\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 1508, reward 353.0, memory_length 2000, epsilon 0.25699169444732667, time 725.0, rides 134\n",
      "Initial State is  [3, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1509, reward 604.0, memory_length 2000, epsilon 0.2567604019223241, time 731.0, rides 137\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 1510, reward 498.0, memory_length 2000, epsilon 0.256529317560594, time 732.0, rides 114\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 1511, reward 320.0, memory_length 2000, epsilon 0.25629844117478945, time 732.0, rides 128\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1512, reward 723.0, memory_length 2000, epsilon 0.2560677725777321, time 726.0, rides 119\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1513, reward 724.0, memory_length 2000, epsilon 0.25583731158241213, time 726.0, rides 131\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 1514, reward 572.0, memory_length 2000, epsilon 0.25560705800198796, time 722.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 1515, reward 452.0, memory_length 2000, epsilon 0.25537701164978616, time 729.0, rides 130\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1516, reward 543.0, memory_length 2000, epsilon 0.25514717233930134, time 733.0, rides 124\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 1517, reward 764.0, memory_length 2000, epsilon 0.25491753988419596, time 726.0, rides 120\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1518, reward 432.0, memory_length 2000, epsilon 0.25468811409830017, time 724.0, rides 128\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 1519, reward 425.0, memory_length 2000, epsilon 0.2544588947956117, time 725.0, rides 131\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 1520, reward 533.0, memory_length 2000, epsilon 0.2542298817902956, time 723.0, rides 136\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1521, reward 626.0, memory_length 2000, epsilon 0.25400107489668433, time 725.0, rides 126\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 1522, reward 617.0, memory_length 2000, epsilon 0.2537724739292773, time 728.0, rides 131\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 1523, reward 565.0, memory_length 2000, epsilon 0.253544078702741, time 725.0, rides 138\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 1524, reward 731.0, memory_length 2000, epsilon 0.2533158890319085, time 735.0, rides 138\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 1525, reward 532.0, memory_length 2000, epsilon 0.2530879047317798, time 724.0, rides 140\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 1526, reward 610.0, memory_length 2000, epsilon 0.2528601256175212, time 727.0, rides 112\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 1527, reward 631.0, memory_length 2000, epsilon 0.2526325515044654, time 725.0, rides 134\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1528, reward 931.0, memory_length 2000, epsilon 0.25240518220811137, time 731.0, rides 130\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 1529, reward 762.0, memory_length 2000, epsilon 0.25217801754412406, time 732.0, rides 138\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 1530, reward 619.0, memory_length 2000, epsilon 0.25195105732833434, time 728.0, rides 137\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1531, reward 617.0, memory_length 2000, epsilon 0.25172430137673885, time 724.0, rides 126\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 1532, reward 383.0, memory_length 2000, epsilon 0.2514977495054998, time 734.0, rides 129\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 1533, reward 819.0, memory_length 2000, epsilon 0.25127140153094485, time 728.0, rides 128\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 1534, reward 616.0, memory_length 2000, epsilon 0.251045257269567, time 725.0, rides 125\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 1535, reward 575.0, memory_length 2000, epsilon 0.25081931653802436, time 730.0, rides 128\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 1536, reward 548.0, memory_length 2000, epsilon 0.2505935791531401, time 727.0, rides 133\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 1537, reward 235.0, memory_length 2000, epsilon 0.2503680449319023, time 723.0, rides 125\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 1538, reward 803.0, memory_length 2000, epsilon 0.25014271369146357, time 726.0, rides 146\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 1539, reward 463.0, memory_length 2000, epsilon 0.24991758524914126, time 733.0, rides 128\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 1540, reward 705.0, memory_length 2000, epsilon 0.24969265942241703, time 732.0, rides 140\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 1541, reward 636.0, memory_length 2000, epsilon 0.24946793602893685, time 726.0, rides 125\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 1542, reward 485.0, memory_length 2000, epsilon 0.2492434148865108, time 724.0, rides 123\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 1543, reward 575.0, memory_length 2000, epsilon 0.24901909581311293, time 728.0, rides 141\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 1544, reward 809.0, memory_length 2000, epsilon 0.24879497862688113, time 736.0, rides 131\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 1545, reward 858.0, memory_length 2000, epsilon 0.24857106314611693, time 729.0, rides 137\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 1546, reward 653.0, memory_length 2000, epsilon 0.24834734918928542, time 724.0, rides 127\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 1547, reward 447.0, memory_length 2000, epsilon 0.24812383657501505, time 727.0, rides 119\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 1548, reward 491.0, memory_length 2000, epsilon 0.24790052512209754, time 736.0, rides 127\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 1549, reward 555.0, memory_length 2000, epsilon 0.24767741464948764, time 726.0, rides 137\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 1550, reward 817.0, memory_length 2000, epsilon 0.2474545049763031, time 724.0, rides 139\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 1551, reward 455.0, memory_length 2000, epsilon 0.24723179592182443, time 737.0, rides 139\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 1552, reward 390.0, memory_length 2000, epsilon 0.2470092873054948, time 732.0, rides 135\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 1553, reward 753.0, memory_length 2000, epsilon 0.24678697894691984, time 730.0, rides 119\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 1554, reward 282.0, memory_length 2000, epsilon 0.2465648706658676, time 728.0, rides 143\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 1555, reward 424.0, memory_length 2000, epsilon 0.24634296228226832, time 729.0, rides 127\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1556, reward 660.0, memory_length 2000, epsilon 0.24612125361621429, time 730.0, rides 118\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1557, reward 615.0, memory_length 2000, epsilon 0.2458997444879597, time 730.0, rides 124\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 1558, reward 456.0, memory_length 2000, epsilon 0.24567843471792053, time 724.0, rides 129\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 1559, reward 816.0, memory_length 2000, epsilon 0.2454573241266744, time 726.0, rides 136\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 1560, reward 496.0, memory_length 2000, epsilon 0.2452364125349604, time 726.0, rides 126\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 1561, reward 220.0, memory_length 2000, epsilon 0.24501569976367893, time 728.0, rides 120\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 1562, reward 729.0, memory_length 2000, epsilon 0.2447951856338916, time 727.0, rides 126\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 1563, reward 369.0, memory_length 2000, epsilon 0.2445748699668211, time 729.0, rides 121\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 1564, reward 442.0, memory_length 2000, epsilon 0.24435475258385095, time 730.0, rides 126\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 1565, reward 656.0, memory_length 2000, epsilon 0.24413483330652547, time 735.0, rides 126\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 1566, reward 530.0, memory_length 2000, epsilon 0.24391511195654958, time 728.0, rides 147\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 1567, reward 678.0, memory_length 2000, epsilon 0.2436955883557887, time 720.0, rides 122\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1568, reward 542.0, memory_length 2000, epsilon 0.24347626232626848, time 736.0, rides 134\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1569, reward 911.0, memory_length 2000, epsilon 0.24325713369017485, time 731.0, rides 128\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 1570, reward 199.0, memory_length 2000, epsilon 0.24303820226985368, time 729.0, rides 128\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 1571, reward 655.0, memory_length 2000, epsilon 0.2428194678878108, time 735.0, rides 130\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 1572, reward 336.0, memory_length 2000, epsilon 0.24260093036671176, time 726.0, rides 134\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 1573, reward 659.0, memory_length 2000, epsilon 0.24238258952938171, time 732.0, rides 131\n",
      "Initial State is  [3, 23, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1574, reward 609.0, memory_length 2000, epsilon 0.24216444519880526, time 729.0, rides 130\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 1575, reward 620.0, memory_length 2000, epsilon 0.24194649719812633, time 735.0, rides 142\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 1576, reward 640.0, memory_length 2000, epsilon 0.241728745350648, time 732.0, rides 135\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 1577, reward 617.0, memory_length 2000, epsilon 0.2415111894798324, time 727.0, rides 130\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 1578, reward 621.0, memory_length 2000, epsilon 0.24129382940930055, time 723.0, rides 123\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 1579, reward 360.0, memory_length 2000, epsilon 0.24107666496283217, time 739.0, rides 121\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 1580, reward 361.0, memory_length 2000, epsilon 0.24085969596436563, time 735.0, rides 144\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 1581, reward 639.0, memory_length 2000, epsilon 0.2406429222379977, time 727.0, rides 125\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 1582, reward 420.0, memory_length 2000, epsilon 0.24042634360798348, time 732.0, rides 137\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1583, reward 796.0, memory_length 2000, epsilon 0.2402099598987363, time 733.0, rides 144\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 1584, reward 192.0, memory_length 2000, epsilon 0.23999377093482743, time 729.0, rides 130\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 1585, reward 795.0, memory_length 2000, epsilon 0.2397777765409861, time 735.0, rides 150\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1586, reward 426.0, memory_length 2000, epsilon 0.2395619765420992, time 727.0, rides 128\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 1587, reward 776.0, memory_length 2000, epsilon 0.23934637076321133, time 726.0, rides 140\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 1588, reward 399.0, memory_length 2000, epsilon 0.23913095902952444, time 736.0, rides 128\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1589, reward 716.0, memory_length 2000, epsilon 0.23891574116639785, time 731.0, rides 128\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 1590, reward 553.0, memory_length 2000, epsilon 0.23870071699934808, time 729.0, rides 128\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 1591, reward 632.0, memory_length 2000, epsilon 0.23848588635404866, time 722.0, rides 125\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 1592, reward 410.0, memory_length 2000, epsilon 0.23827124905633001, time 725.0, rides 144\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 1593, reward 813.0, memory_length 2000, epsilon 0.23805680493217932, time 734.0, rides 126\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 1594, reward 424.0, memory_length 2000, epsilon 0.23784255380774036, time 732.0, rides 123\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 1595, reward 568.0, memory_length 2000, epsilon 0.2376284955093134, time 726.0, rides 116\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 1596, reward 287.0, memory_length 2000, epsilon 0.23741462986335501, time 730.0, rides 127\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 1597, reward 815.0, memory_length 2000, epsilon 0.237200956696478, time 739.0, rides 143\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 1598, reward 532.0, memory_length 2000, epsilon 0.23698747583545118, time 733.0, rides 126\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 1599, reward 565.0, memory_length 2000, epsilon 0.23677418710719927, time 721.0, rides 133\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 1600, reward 538.0, memory_length 2000, epsilon 0.2365610903388028, time 723.0, rides 121\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 1601, reward 400.0, memory_length 2000, epsilon 0.23634818535749788, time 734.0, rides 141\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 1602, reward 584.0, memory_length 2000, epsilon 0.23613547199067614, time 733.0, rides 122\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 1603, reward 597.0, memory_length 2000, epsilon 0.23592295006588454, time 729.0, rides 121\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 1604, reward 502.0, memory_length 2000, epsilon 0.23571061941082525, time 732.0, rides 136\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 1605, reward 274.0, memory_length 2000, epsilon 0.2354984798533555, time 731.0, rides 130\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1606, reward 751.0, memory_length 2000, epsilon 0.2352865312214875, time 736.0, rides 128\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 1607, reward 579.0, memory_length 2000, epsilon 0.23507477334338814, time 730.0, rides 125\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 1608, reward 859.0, memory_length 2000, epsilon 0.2348632060473791, time 724.0, rides 132\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1609, reward 602.0, memory_length 2000, epsilon 0.23465182916193644, time 740.0, rides 132\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 1610, reward 614.0, memory_length 2000, epsilon 0.2344406425156907, time 728.0, rides 130\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 1611, reward 374.0, memory_length 2000, epsilon 0.23422964593742657, time 731.0, rides 130\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 1612, reward 603.0, memory_length 2000, epsilon 0.23401883925608288, time 721.0, rides 144\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 1613, reward 887.0, memory_length 2000, epsilon 0.2338082223007524, time 728.0, rides 121\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 1614, reward 873.0, memory_length 2000, epsilon 0.23359779490068172, time 724.0, rides 128\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1615, reward 372.0, memory_length 2000, epsilon 0.2333875568852711, time 730.0, rides 125\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1616, reward 360.0, memory_length 2000, epsilon 0.23317750808407436, time 721.0, rides 148\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 1617, reward 610.0, memory_length 2000, epsilon 0.2329676483267987, time 733.0, rides 129\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 1618, reward 847.0, memory_length 2000, epsilon 0.23275797744330456, time 729.0, rides 132\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 1619, reward 405.0, memory_length 2000, epsilon 0.23254849526360558, time 744.0, rides 129\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 1620, reward 479.0, memory_length 2000, epsilon 0.23233920161786834, time 729.0, rides 125\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 1621, reward 891.0, memory_length 2000, epsilon 0.23213009633641224, time 726.0, rides 133\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 1622, reward 491.0, memory_length 2000, epsilon 0.23192117924970945, time 728.0, rides 120\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 1623, reward 445.0, memory_length 2000, epsilon 0.2317124501883847, time 726.0, rides 128\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 1624, reward 798.0, memory_length 2000, epsilon 0.23150390898321516, time 731.0, rides 131\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 1625, reward 562.0, memory_length 2000, epsilon 0.23129555546513025, time 725.0, rides 119\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 1626, reward 450.0, memory_length 2000, epsilon 0.23108738946521162, time 727.0, rides 125\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1627, reward 807.0, memory_length 2000, epsilon 0.23087941081469293, time 725.0, rides 120\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 1628, reward 811.0, memory_length 2000, epsilon 0.2306716193449597, time 735.0, rides 131\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 1629, reward 706.0, memory_length 2000, epsilon 0.23046401488754922, time 723.0, rides 127\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 1630, reward 519.0, memory_length 2000, epsilon 0.23025659727415043, time 731.0, rides 141\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 1631, reward 759.0, memory_length 2000, epsilon 0.2300493663366037, time 721.0, rides 121\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 1632, reward 204.0, memory_length 2000, epsilon 0.22984232190690074, time 730.0, rides 129\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 1633, reward 803.0, memory_length 2000, epsilon 0.22963546381718453, time 737.0, rides 147\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1634, reward 374.0, memory_length 2000, epsilon 0.22942879189974905, time 729.0, rides 136\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 1635, reward 41.0, memory_length 2000, epsilon 0.22922230598703927, time 737.0, rides 124\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 1636, reward 614.0, memory_length 2000, epsilon 0.22901600591165094, time 733.0, rides 138\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 1637, reward 583.0, memory_length 2000, epsilon 0.22880989150633047, time 729.0, rides 138\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1638, reward 457.0, memory_length 2000, epsilon 0.22860396260397475, time 728.0, rides 120\n",
      "Initial State is  [2, 8, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1639, reward 279.0, memory_length 2000, epsilon 0.22839821903763116, time 723.0, rides 127\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 1640, reward 734.0, memory_length 2000, epsilon 0.22819266064049729, time 728.0, rides 117\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1641, reward 655.0, memory_length 2000, epsilon 0.22798728724592082, time 727.0, rides 133\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1642, reward 814.0, memory_length 2000, epsilon 0.2277820986873995, time 723.0, rides 133\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 1643, reward 577.0, memory_length 2000, epsilon 0.22757709479858082, time 724.0, rides 118\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 1644, reward 540.0, memory_length 2000, epsilon 0.2273722754132621, time 729.0, rides 128\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 1645, reward 678.0, memory_length 2000, epsilon 0.22716764036539017, time 731.0, rides 133\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 1646, reward 282.0, memory_length 2000, epsilon 0.2269631894890613, time 727.0, rides 135\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 1647, reward 504.0, memory_length 2000, epsilon 0.22675892261852115, time 734.0, rides 141\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 1648, reward 331.0, memory_length 2000, epsilon 0.22655483958816447, time 728.0, rides 114\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 1649, reward 624.0, memory_length 2000, epsilon 0.22635094023253513, time 735.0, rides 133\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 1650, reward 630.0, memory_length 2000, epsilon 0.22614722438632584, time 731.0, rides 146\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 1651, reward 855.0, memory_length 2000, epsilon 0.22594369188437816, time 730.0, rides 130\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1652, reward 494.0, memory_length 2000, epsilon 0.2257403425616822, time 721.0, rides 131\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1653, reward 502.0, memory_length 2000, epsilon 0.2255371762533767, time 739.0, rides 122\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 1654, reward 625.0, memory_length 2000, epsilon 0.22533419279474864, time 723.0, rides 128\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 1655, reward 888.0, memory_length 2000, epsilon 0.22513139202123336, time 732.0, rides 125\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 1656, reward 741.0, memory_length 2000, epsilon 0.22492877376841425, time 725.0, rides 127\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 1657, reward 808.0, memory_length 2000, epsilon 0.22472633787202267, time 727.0, rides 134\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 1658, reward 654.0, memory_length 2000, epsilon 0.22452408416793784, time 728.0, rides 128\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1659, reward 461.0, memory_length 2000, epsilon 0.2243220124921867, time 726.0, rides 124\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 1660, reward 751.0, memory_length 2000, epsilon 0.22412012268094372, time 726.0, rides 124\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 1661, reward 439.0, memory_length 2000, epsilon 0.22391841457053088, time 731.0, rides 117\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 1662, reward 546.0, memory_length 2000, epsilon 0.2237168879974174, time 729.0, rides 124\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 1663, reward 654.0, memory_length 2000, epsilon 0.22351554279821972, time 727.0, rides 131\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1664, reward 637.0, memory_length 2000, epsilon 0.2233143788097013, time 732.0, rides 124\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1665, reward 816.0, memory_length 2000, epsilon 0.22311339586877257, time 740.0, rides 131\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 1666, reward 581.0, memory_length 2000, epsilon 0.22291259381249068, time 726.0, rides 129\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 1667, reward 835.0, memory_length 2000, epsilon 0.22271197247805943, time 724.0, rides 131\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1668, reward 564.0, memory_length 2000, epsilon 0.22251153170282917, time 729.0, rides 128\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 1669, reward 563.0, memory_length 2000, epsilon 0.22231127132429662, time 730.0, rides 118\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 1670, reward 984.0, memory_length 2000, epsilon 0.22211119118010475, time 724.0, rides 134\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 1671, reward 856.0, memory_length 2000, epsilon 0.22191129110804264, time 722.0, rides 130\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 1672, reward 532.0, memory_length 2000, epsilon 0.2217115709460454, time 730.0, rides 125\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 1673, reward 366.0, memory_length 2000, epsilon 0.22151203053219395, time 735.0, rides 130\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 1674, reward 750.0, memory_length 2000, epsilon 0.22131266970471497, time 732.0, rides 123\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 1675, reward 367.0, memory_length 2000, epsilon 0.22111348830198072, time 724.0, rides 127\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1676, reward 509.0, memory_length 2000, epsilon 0.22091448616250892, time 735.0, rides 131\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 1677, reward 591.0, memory_length 2000, epsilon 0.22071566312496266, time 735.0, rides 137\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 1678, reward 737.0, memory_length 2000, epsilon 0.22051701902815019, time 733.0, rides 136\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 1679, reward 539.0, memory_length 2000, epsilon 0.22031855371102485, time 741.0, rides 122\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 1680, reward 431.0, memory_length 2000, epsilon 0.22012026701268492, time 731.0, rides 120\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 1681, reward 610.0, memory_length 2000, epsilon 0.2199221587723735, time 724.0, rides 139\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 1682, reward 804.0, memory_length 2000, epsilon 0.21972422882947837, time 723.0, rides 138\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1683, reward 786.0, memory_length 2000, epsilon 0.21952647702353184, time 724.0, rides 136\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 1684, reward 678.0, memory_length 2000, epsilon 0.21932890319421067, time 733.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 1685, reward 439.0, memory_length 2000, epsilon 0.21913150718133587, time 729.0, rides 152\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 1686, reward 527.0, memory_length 2000, epsilon 0.21893428882487267, time 725.0, rides 130\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 1687, reward 558.0, memory_length 2000, epsilon 0.2187372479649303, time 725.0, rides 121\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 1688, reward 596.0, memory_length 2000, epsilon 0.21854038444176185, time 728.0, rides 137\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1689, reward 300.0, memory_length 2000, epsilon 0.21834369809576426, time 732.0, rides 129\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 1690, reward 228.0, memory_length 2000, epsilon 0.21814718876747807, time 731.0, rides 137\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 1691, reward 704.0, memory_length 2000, epsilon 0.21795085629758734, time 726.0, rides 127\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1692, reward 524.0, memory_length 2000, epsilon 0.2177547005269195, time 728.0, rides 132\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 1693, reward 578.0, memory_length 2000, epsilon 0.21755872129644527, time 724.0, rides 122\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 1694, reward 723.0, memory_length 2000, epsilon 0.21736291844727845, time 726.0, rides 131\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1695, reward 399.0, memory_length 2000, epsilon 0.2171672918206759, time 729.0, rides 132\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 1696, reward 386.0, memory_length 2000, epsilon 0.21697184125803728, time 728.0, rides 131\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 1697, reward 656.0, memory_length 2000, epsilon 0.21677656660090505, time 727.0, rides 139\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 1698, reward 721.0, memory_length 2000, epsilon 0.21658146769096423, time 728.0, rides 118\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1699, reward 454.0, memory_length 2000, epsilon 0.21638654437004237, time 725.0, rides 139\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 1700, reward 590.0, memory_length 2000, epsilon 0.21619179648010933, time 733.0, rides 142\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 1701, reward 414.0, memory_length 2000, epsilon 0.21599722386327724, time 728.0, rides 126\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 1702, reward 457.0, memory_length 2000, epsilon 0.2158028263618003, time 735.0, rides 119\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 1703, reward 749.0, memory_length 2000, epsilon 0.21560860381807467, time 730.0, rides 137\n",
      "Initial State is  [2, 8, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1704, reward 739.0, memory_length 2000, epsilon 0.2154145560746384, time 738.0, rides 123\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 1705, reward 859.0, memory_length 2000, epsilon 0.21522068297417124, time 736.0, rides 124\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 1706, reward 953.0, memory_length 2000, epsilon 0.2150269843594945, time 725.0, rides 138\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 1707, reward 890.0, memory_length 2000, epsilon 0.21483346007357096, time 734.0, rides 130\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 1708, reward 333.0, memory_length 2000, epsilon 0.21464010995950475, time 724.0, rides 128\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 1709, reward 410.0, memory_length 2000, epsilon 0.2144469338605412, time 733.0, rides 134\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 1710, reward 525.0, memory_length 2000, epsilon 0.2142539316200667, time 729.0, rides 135\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 1711, reward 731.0, memory_length 2000, epsilon 0.21406110308160864, time 733.0, rides 131\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 1712, reward 448.0, memory_length 2000, epsilon 0.21386844808883518, time 730.0, rides 133\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 1713, reward 398.0, memory_length 2000, epsilon 0.21367596648555523, time 730.0, rides 139\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 1714, reward 566.0, memory_length 2000, epsilon 0.21348365811571823, time 730.0, rides 128\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1715, reward 454.0, memory_length 2000, epsilon 0.2132915228234141, time 733.0, rides 136\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 1716, reward 606.0, memory_length 2000, epsilon 0.213099560452873, time 727.0, rides 134\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 1717, reward 593.0, memory_length 2000, epsilon 0.21290777084846543, time 737.0, rides 127\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 1718, reward 617.0, memory_length 2000, epsilon 0.2127161538547018, time 725.0, rides 119\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 1719, reward 248.0, memory_length 2000, epsilon 0.21252470931623257, time 723.0, rides 126\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 1720, reward 810.0, memory_length 2000, epsilon 0.21233343707784796, time 731.0, rides 140\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 1721, reward 617.0, memory_length 2000, epsilon 0.2121423369844779, time 733.0, rides 120\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 1722, reward 711.0, memory_length 2000, epsilon 0.21195140888119188, time 731.0, rides 134\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 1723, reward 244.0, memory_length 2000, epsilon 0.2117606526131988, time 730.0, rides 133\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 1724, reward 533.0, memory_length 2000, epsilon 0.2115700680258469, time 728.0, rides 135\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 1725, reward 617.0, memory_length 2000, epsilon 0.21137965496462363, time 723.0, rides 124\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1726, reward 745.0, memory_length 2000, epsilon 0.21118941327515547, time 735.0, rides 124\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 1727, reward 788.0, memory_length 2000, epsilon 0.21099934280320784, time 724.0, rides 127\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 1728, reward 707.0, memory_length 2000, epsilon 0.21080944339468494, time 723.0, rides 128\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 1729, reward 660.0, memory_length 2000, epsilon 0.21061971489562972, time 732.0, rides 147\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 1730, reward 531.0, memory_length 2000, epsilon 0.21043015715222366, time 731.0, rides 121\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 1731, reward 658.0, memory_length 2000, epsilon 0.21024077001078664, time 729.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 1732, reward 674.0, memory_length 2000, epsilon 0.21005155331777695, time 733.0, rides 132\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1733, reward 760.0, memory_length 2000, epsilon 0.20986250691979094, time 726.0, rides 130\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 1734, reward 582.0, memory_length 2000, epsilon 0.20967363066356312, time 728.0, rides 138\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 1735, reward 927.0, memory_length 2000, epsilon 0.20948492439596592, time 732.0, rides 153\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 1736, reward 795.0, memory_length 2000, epsilon 0.20929638796400954, time 721.0, rides 132\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 1737, reward 552.0, memory_length 2000, epsilon 0.20910802121484193, time 732.0, rides 139\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 1738, reward 549.0, memory_length 2000, epsilon 0.20891982399574857, time 727.0, rides 124\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 1739, reward 571.0, memory_length 2000, epsilon 0.20873179615415238, time 737.0, rides 130\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1740, reward 639.0, memory_length 2000, epsilon 0.20854393753761363, time 726.0, rides 131\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 1741, reward 653.0, memory_length 2000, epsilon 0.2083562479938298, time 730.0, rides 137\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 1742, reward 886.0, memory_length 2000, epsilon 0.20816872737063535, time 724.0, rides 124\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 1743, reward 578.0, memory_length 2000, epsilon 0.2079813755160018, time 726.0, rides 126\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 1744, reward 892.0, memory_length 2000, epsilon 0.2077941922780374, time 729.0, rides 127\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 1745, reward 831.0, memory_length 2000, epsilon 0.20760717750498714, time 725.0, rides 146\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 1746, reward 419.0, memory_length 2000, epsilon 0.20742033104523264, time 733.0, rides 130\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 1747, reward 575.0, memory_length 2000, epsilon 0.2072336527472919, time 730.0, rides 135\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 1748, reward 510.0, memory_length 2000, epsilon 0.20704714245981934, time 724.0, rides 134\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 1749, reward 630.0, memory_length 2000, epsilon 0.2068608000316055, time 725.0, rides 138\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 1750, reward 403.0, memory_length 2000, epsilon 0.20667462531157707, time 728.0, rides 147\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 1751, reward 710.0, memory_length 2000, epsilon 0.20648861814879665, time 727.0, rides 122\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1752, reward 774.0, memory_length 2000, epsilon 0.20630277839246272, time 734.0, rides 134\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 1753, reward 760.0, memory_length 2000, epsilon 0.2061171058919095, time 730.0, rides 134\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 1754, reward 946.0, memory_length 2000, epsilon 0.2059316004966068, time 724.0, rides 132\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1755, reward 509.0, memory_length 2000, epsilon 0.20574626205615987, time 729.0, rides 130\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 1756, reward 736.0, memory_length 2000, epsilon 0.20556109042030932, time 728.0, rides 128\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 1757, reward 754.0, memory_length 2000, epsilon 0.20537608543893104, time 729.0, rides 145\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 1758, reward 970.0, memory_length 2000, epsilon 0.205191246962036, time 725.0, rides 143\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 1759, reward 535.0, memory_length 2000, epsilon 0.20500657483977017, time 724.0, rides 134\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 1760, reward 514.0, memory_length 2000, epsilon 0.20482206892241436, time 729.0, rides 138\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 1761, reward 1037.0, memory_length 2000, epsilon 0.2046377290603842, time 731.0, rides 130\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 1762, reward 716.0, memory_length 2000, epsilon 0.20445355510422983, time 727.0, rides 133\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 1763, reward 397.0, memory_length 2000, epsilon 0.20426954690463603, time 732.0, rides 121\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 1764, reward 491.0, memory_length 2000, epsilon 0.20408570431242185, time 730.0, rides 134\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 1765, reward 621.0, memory_length 2000, epsilon 0.20390202717854067, time 734.0, rides 127\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 1766, reward 590.0, memory_length 2000, epsilon 0.20371851535407998, time 727.0, rides 130\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 1767, reward 551.0, memory_length 2000, epsilon 0.2035351686902613, time 726.0, rides 127\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 1768, reward 707.0, memory_length 2000, epsilon 0.20335198703844007, time 735.0, rides 126\n",
      "Initial State is  [1, 12, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1769, reward 629.0, memory_length 2000, epsilon 0.20316897025010547, time 726.0, rides 121\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 1770, reward 752.0, memory_length 2000, epsilon 0.20298611817688036, time 726.0, rides 135\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 1771, reward 295.0, memory_length 2000, epsilon 0.20280343067052117, time 725.0, rides 125\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 1772, reward 421.0, memory_length 2000, epsilon 0.2026209075829177, time 728.0, rides 133\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 1773, reward 496.0, memory_length 2000, epsilon 0.20243854876609307, time 731.0, rides 123\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 1774, reward 475.0, memory_length 2000, epsilon 0.20225635407220358, time 740.0, rides 134\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 1775, reward 954.0, memory_length 2000, epsilon 0.2020743233535386, time 727.0, rides 130\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1776, reward 675.0, memory_length 2000, epsilon 0.2018924564625204, time 732.0, rides 134\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 1777, reward 653.0, memory_length 2000, epsilon 0.20171075325170415, time 729.0, rides 130\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 1778, reward 548.0, memory_length 2000, epsilon 0.20152921357377762, time 727.0, rides 138\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 1779, reward 777.0, memory_length 2000, epsilon 0.20134783728156122, time 731.0, rides 143\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1780, reward 637.0, memory_length 2000, epsilon 0.20116662422800782, time 730.0, rides 129\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1781, reward 744.0, memory_length 2000, epsilon 0.20098557426620262, time 733.0, rides 137\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 1782, reward 282.0, memory_length 2000, epsilon 0.20080468724936304, time 728.0, rides 143\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1783, reward 672.0, memory_length 2000, epsilon 0.2006239630308386, time 735.0, rides 125\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 1784, reward 728.0, memory_length 2000, epsilon 0.20044340146411085, time 729.0, rides 127\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1785, reward 594.0, memory_length 2000, epsilon 0.20026300240279316, time 732.0, rides 132\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 1786, reward 726.0, memory_length 2000, epsilon 0.20008276570063063, time 726.0, rides 130\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 1787, reward 488.0, memory_length 2000, epsilon 0.19990269121150006, time 723.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 1788, reward 446.0, memory_length 2000, epsilon 0.19972277878940972, time 730.0, rides 127\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 1789, reward 919.0, memory_length 2000, epsilon 0.19954302828849926, time 731.0, rides 147\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 1790, reward 582.0, memory_length 2000, epsilon 0.19936343956303962, time 726.0, rides 131\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 1791, reward 761.0, memory_length 2000, epsilon 0.1991840124674329, time 727.0, rides 138\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 1792, reward 962.0, memory_length 2000, epsilon 0.1990047468562122, time 726.0, rides 129\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 1793, reward 701.0, memory_length 2000, epsilon 0.1988256425840416, time 725.0, rides 124\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 1794, reward 449.0, memory_length 2000, epsilon 0.19864669950571595, time 730.0, rides 145\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1795, reward 871.0, memory_length 2000, epsilon 0.1984679174761608, time 728.0, rides 122\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 1796, reward 631.0, memory_length 2000, epsilon 0.19828929635043224, time 728.0, rides 137\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 1797, reward 481.0, memory_length 2000, epsilon 0.19811083598371684, time 727.0, rides 125\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 1798, reward 436.0, memory_length 2000, epsilon 0.1979325362313315, time 725.0, rides 134\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 1799, reward 685.0, memory_length 2000, epsilon 0.1977543969487233, time 732.0, rides 128\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 1800, reward 444.0, memory_length 2000, epsilon 0.19757641799146944, time 722.0, rides 136\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 1801, reward 791.0, memory_length 2000, epsilon 0.1973985992152771, time 730.0, rides 130\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 1802, reward 752.0, memory_length 2000, epsilon 0.19722094047598335, time 729.0, rides 133\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 1803, reward 327.0, memory_length 2000, epsilon 0.19704344162955495, time 725.0, rides 138\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 1804, reward 831.0, memory_length 2000, epsilon 0.19686610253208836, time 729.0, rides 129\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 1805, reward 431.0, memory_length 2000, epsilon 0.19668892303980948, time 733.0, rides 122\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 1806, reward 986.0, memory_length 2000, epsilon 0.19651190300907365, time 733.0, rides 138\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 1807, reward 801.0, memory_length 2000, epsilon 0.19633504229636548, time 728.0, rides 137\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 1808, reward 712.0, memory_length 2000, epsilon 0.19615834075829874, time 726.0, rides 121\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 1809, reward 214.0, memory_length 2000, epsilon 0.19598179825161627, time 735.0, rides 143\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 1810, reward 429.0, memory_length 2000, epsilon 0.19580541463318982, time 725.0, rides 130\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 1811, reward 350.0, memory_length 2000, epsilon 0.19562918976001994, time 724.0, rides 125\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 1812, reward 873.0, memory_length 2000, epsilon 0.19545312348923594, time 725.0, rides 120\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 1813, reward 728.0, memory_length 2000, epsilon 0.1952772156780956, time 731.0, rides 131\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 1814, reward 662.0, memory_length 2000, epsilon 0.19510146618398533, time 730.0, rides 140\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 1815, reward 682.0, memory_length 2000, epsilon 0.19492587486441973, time 736.0, rides 125\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 1816, reward 274.0, memory_length 2000, epsilon 0.19475044157704174, time 724.0, rides 127\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1817, reward 559.0, memory_length 2000, epsilon 0.1945751661796224, time 726.0, rides 126\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 1818, reward 467.0, memory_length 2000, epsilon 0.19440004853006074, time 731.0, rides 141\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 1819, reward 643.0, memory_length 2000, epsilon 0.19422508848638367, time 728.0, rides 126\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 1820, reward 620.0, memory_length 2000, epsilon 0.19405028590674592, time 729.0, rides 129\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 1821, reward 370.0, memory_length 2000, epsilon 0.19387564064942983, time 739.0, rides 124\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1822, reward 581.0, memory_length 2000, epsilon 0.19370115257284534, time 729.0, rides 130\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 1823, reward 999.0, memory_length 2000, epsilon 0.19352682153552977, time 731.0, rides 140\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 1824, reward 510.0, memory_length 2000, epsilon 0.1933526473961478, time 722.0, rides 146\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 1825, reward 677.0, memory_length 2000, epsilon 0.19317863001349125, time 740.0, rides 137\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 1826, reward 527.0, memory_length 2000, epsilon 0.1930047692464791, time 725.0, rides 147\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 1827, reward 772.0, memory_length 2000, epsilon 0.19283106495415728, time 733.0, rides 131\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 1828, reward 710.0, memory_length 2000, epsilon 0.19265751699569852, time 728.0, rides 142\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 1829, reward 616.0, memory_length 2000, epsilon 0.1924841252304024, time 735.0, rides 132\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 1830, reward 551.0, memory_length 2000, epsilon 0.19231088951769504, time 721.0, rides 137\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 1831, reward 720.0, memory_length 2000, epsilon 0.1921378097171291, time 729.0, rides 145\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 1832, reward 367.0, memory_length 2000, epsilon 0.19196488568838369, time 732.0, rides 138\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 1833, reward 516.0, memory_length 2000, epsilon 0.19179211729126414, time 727.0, rides 142\n",
      "Initial State is  [0, 0, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1834, reward 709.0, memory_length 2000, epsilon 0.191619504385702, time 738.0, rides 130\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 1835, reward 716.0, memory_length 2000, epsilon 0.19144704683175487, time 724.0, rides 130\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 1836, reward 849.0, memory_length 2000, epsilon 0.1912747444896063, time 724.0, rides 141\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 1837, reward 368.0, memory_length 2000, epsilon 0.19110259721956566, time 735.0, rides 126\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 1838, reward 589.0, memory_length 2000, epsilon 0.19093060488206803, time 722.0, rides 132\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 1839, reward 586.0, memory_length 2000, epsilon 0.19075876733767416, time 730.0, rides 114\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 1840, reward 607.0, memory_length 2000, epsilon 0.19058708444707026, time 724.0, rides 125\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 1841, reward 793.0, memory_length 2000, epsilon 0.1904155560710679, time 743.0, rides 131\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 1842, reward 908.0, memory_length 2000, epsilon 0.19024418207060392, time 727.0, rides 125\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 1843, reward 615.0, memory_length 2000, epsilon 0.19007296230674037, time 731.0, rides 128\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 1844, reward 435.0, memory_length 2000, epsilon 0.18990189664066429, time 731.0, rides 125\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 1845, reward 817.0, memory_length 2000, epsilon 0.18973098493368767, time 734.0, rides 132\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1846, reward 318.0, memory_length 2000, epsilon 0.18956022704724734, time 727.0, rides 137\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 1847, reward 890.0, memory_length 2000, epsilon 0.1893896228429048, time 727.0, rides 141\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 1848, reward 576.0, memory_length 2000, epsilon 0.18921917218234618, time 731.0, rides 134\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 1849, reward 681.0, memory_length 2000, epsilon 0.18904887492738207, time 734.0, rides 135\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 1850, reward 519.0, memory_length 2000, epsilon 0.18887873093994742, time 730.0, rides 141\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1851, reward 285.0, memory_length 2000, epsilon 0.18870874008210148, time 726.0, rides 134\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 1852, reward 530.0, memory_length 2000, epsilon 0.1885389022160276, time 724.0, rides 135\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 1853, reward 888.0, memory_length 2000, epsilon 0.18836921720403316, time 728.0, rides 134\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 1854, reward 811.0, memory_length 2000, epsilon 0.18819968490854952, time 729.0, rides 130\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1855, reward 501.0, memory_length 2000, epsilon 0.18803030519213182, time 742.0, rides 133\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 1856, reward 323.0, memory_length 2000, epsilon 0.1878610779174589, time 730.0, rides 127\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 1857, reward 839.0, memory_length 2000, epsilon 0.18769200294733318, time 723.0, rides 138\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 1858, reward 835.0, memory_length 2000, epsilon 0.18752308014468058, time 729.0, rides 116\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 1859, reward 349.0, memory_length 2000, epsilon 0.18735430937255038, time 723.0, rides 132\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 1860, reward 562.0, memory_length 2000, epsilon 0.18718569049411507, time 730.0, rides 141\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 1861, reward 772.0, memory_length 2000, epsilon 0.18701722337267038, time 727.0, rides 122\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 1862, reward 482.0, memory_length 2000, epsilon 0.18684890787163497, time 730.0, rides 133\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 1863, reward 591.0, memory_length 2000, epsilon 0.1866807438545505, time 738.0, rides 114\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 1864, reward 704.0, memory_length 2000, epsilon 0.1865127311850814, time 728.0, rides 143\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 1865, reward 628.0, memory_length 2000, epsilon 0.18634486972701483, time 728.0, rides 129\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 1866, reward 754.0, memory_length 2000, epsilon 0.18617715934426052, time 731.0, rides 135\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 1867, reward 243.0, memory_length 2000, epsilon 0.18600959990085067, time 727.0, rides 133\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 1868, reward 646.0, memory_length 2000, epsilon 0.1858421912609399, time 722.0, rides 121\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 1869, reward 873.0, memory_length 2000, epsilon 0.18567493328880505, time 731.0, rides 134\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 1870, reward 568.0, memory_length 2000, epsilon 0.18550782584884512, time 732.0, rides 144\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 1871, reward 380.0, memory_length 2000, epsilon 0.18534086880558115, time 728.0, rides 131\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 1872, reward 738.0, memory_length 2000, epsilon 0.18517406202365613, time 727.0, rides 134\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 1873, reward 689.0, memory_length 2000, epsilon 0.18500740536783483, time 727.0, rides 134\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 1874, reward 477.0, memory_length 2000, epsilon 0.18484089870300377, time 732.0, rides 135\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 1875, reward 477.0, memory_length 2000, epsilon 0.18467454189417107, time 732.0, rides 135\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 1876, reward 639.0, memory_length 2000, epsilon 0.1845083348064663, time 728.0, rides 116\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1877, reward 790.0, memory_length 2000, epsilon 0.1843422773051405, time 725.0, rides 130\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 1878, reward 483.0, memory_length 2000, epsilon 0.18417636925556585, time 721.0, rides 135\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 1879, reward 720.0, memory_length 2000, epsilon 0.18401061052323583, time 733.0, rides 147\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 1880, reward 704.0, memory_length 2000, epsilon 0.1838450009737649, time 734.0, rides 114\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 1881, reward 656.0, memory_length 2000, epsilon 0.1836795404728885, time 727.0, rides 124\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 1882, reward 806.0, memory_length 2000, epsilon 0.1835142288864629, time 724.0, rides 117\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1883, reward 561.0, memory_length 2000, epsilon 0.18334906608046508, time 739.0, rides 123\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 1884, reward 428.0, memory_length 2000, epsilon 0.18318405192099266, time 733.0, rides 126\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 1885, reward 723.0, memory_length 2000, epsilon 0.18301918627426375, time 725.0, rides 138\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 1886, reward 556.0, memory_length 2000, epsilon 0.18285446900661692, time 730.0, rides 142\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 1887, reward 681.0, memory_length 2000, epsilon 0.18268989998451096, time 726.0, rides 123\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 1888, reward 896.0, memory_length 2000, epsilon 0.1825254790745249, time 732.0, rides 121\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 1889, reward 1011.0, memory_length 2000, epsilon 0.18236120614335782, time 730.0, rides 135\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 1890, reward 1039.0, memory_length 2000, epsilon 0.1821970810578288, time 729.0, rides 141\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 1891, reward 1020.0, memory_length 2000, epsilon 0.18203310368487677, time 730.0, rides 133\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 1892, reward 980.0, memory_length 2000, epsilon 0.18186927389156038, time 729.0, rides 135\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 1893, reward 650.0, memory_length 2000, epsilon 0.18170559154505797, time 731.0, rides 130\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 1894, reward 881.0, memory_length 2000, epsilon 0.18154205651266742, time 732.0, rides 125\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 1895, reward 510.0, memory_length 2000, epsilon 0.18137866866180602, time 732.0, rides 125\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 1896, reward 723.0, memory_length 2000, epsilon 0.18121542786001038, time 724.0, rides 135\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 1897, reward 557.0, memory_length 2000, epsilon 0.18105233397493636, time 729.0, rides 124\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 1898, reward 875.0, memory_length 2000, epsilon 0.18088938687435893, time 722.0, rides 145\n",
      "Initial State is  [1, 20, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1899, reward 755.0, memory_length 2000, epsilon 0.180726586426172, time 729.0, rides 131\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 1900, reward 616.0, memory_length 2000, epsilon 0.18056393249838845, time 730.0, rides 120\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 1901, reward 418.0, memory_length 2000, epsilon 0.1804014249591399, time 732.0, rides 122\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 1902, reward 510.0, memory_length 2000, epsilon 0.1802390636766767, time 724.0, rides 146\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 1903, reward 375.0, memory_length 2000, epsilon 0.18007684851936767, time 736.0, rides 128\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 1904, reward 765.0, memory_length 2000, epsilon 0.17991477935570024, time 727.0, rides 128\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 1905, reward 958.0, memory_length 2000, epsilon 0.17975285605428012, time 725.0, rides 130\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 1906, reward 776.0, memory_length 2000, epsilon 0.17959107848383127, time 738.0, rides 134\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 1907, reward 796.0, memory_length 2000, epsilon 0.1794294465131958, time 724.0, rides 124\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 1908, reward 574.0, memory_length 2000, epsilon 0.17926796001133394, time 722.0, rides 134\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 1909, reward 895.0, memory_length 2000, epsilon 0.17910661884732373, time 748.0, rides 132\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 1910, reward 559.0, memory_length 2000, epsilon 0.17894542289036114, time 733.0, rides 130\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 1911, reward 529.0, memory_length 2000, epsilon 0.1787843720097598, time 724.0, rides 127\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 1912, reward 778.0, memory_length 2000, epsilon 0.17862346607495103, time 726.0, rides 139\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 1913, reward 549.0, memory_length 2000, epsilon 0.17846270495548358, time 735.0, rides 139\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 1914, reward 826.0, memory_length 2000, epsilon 0.17830208852102364, time 732.0, rides 141\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 1915, reward 827.0, memory_length 2000, epsilon 0.17814161664135472, time 727.0, rides 149\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 1916, reward 463.0, memory_length 2000, epsilon 0.1779812891863775, time 725.0, rides 139\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 1917, reward 888.0, memory_length 2000, epsilon 0.17782110602610976, time 727.0, rides 134\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 1918, reward 716.0, memory_length 2000, epsilon 0.17766106703068626, time 731.0, rides 136\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 1919, reward 812.0, memory_length 2000, epsilon 0.17750117207035865, time 725.0, rides 142\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 1920, reward 523.0, memory_length 2000, epsilon 0.17734142101549533, time 724.0, rides 117\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 1921, reward 776.0, memory_length 2000, epsilon 0.17718181373658137, time 727.0, rides 136\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 1922, reward 468.0, memory_length 2000, epsilon 0.17702235010421843, time 729.0, rides 141\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 1923, reward 809.0, memory_length 2000, epsilon 0.17686302998912465, time 733.0, rides 137\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 1924, reward 738.0, memory_length 2000, epsilon 0.17670385326213445, time 732.0, rides 128\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 1925, reward 711.0, memory_length 2000, epsilon 0.17654481979419853, time 729.0, rides 141\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 1926, reward 680.0, memory_length 2000, epsilon 0.17638592945638376, time 727.0, rides 130\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 1927, reward 533.0, memory_length 2000, epsilon 0.176227182119873, time 724.0, rides 138\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 1928, reward 814.0, memory_length 2000, epsilon 0.17606857765596512, time 726.0, rides 130\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 1929, reward 630.0, memory_length 2000, epsilon 0.17591011593607475, time 727.0, rides 123\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 1930, reward 590.0, memory_length 2000, epsilon 0.17575179683173228, time 735.0, rides 138\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 1931, reward 491.0, memory_length 2000, epsilon 0.17559362021458372, time 741.0, rides 120\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 1932, reward 813.0, memory_length 2000, epsilon 0.17543558595639058, time 730.0, rides 133\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 1933, reward 929.0, memory_length 2000, epsilon 0.17527769392902984, time 726.0, rides 139\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 1934, reward 324.0, memory_length 2000, epsilon 0.1751199440044937, time 731.0, rides 133\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 1935, reward 737.0, memory_length 2000, epsilon 0.17496233605488967, time 725.0, rides 144\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 1936, reward 693.0, memory_length 2000, epsilon 0.17480486995244027, time 728.0, rides 125\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 1937, reward 667.0, memory_length 2000, epsilon 0.17464754556948306, time 727.0, rides 137\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 1938, reward 859.0, memory_length 2000, epsilon 0.17449036277847052, time 730.0, rides 135\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 1939, reward 557.0, memory_length 2000, epsilon 0.1743333214519699, time 724.0, rides 130\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 1940, reward 969.0, memory_length 2000, epsilon 0.17417642146266313, time 727.0, rides 134\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 1941, reward 933.0, memory_length 2000, epsilon 0.17401966268334673, time 724.0, rides 128\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 1942, reward 931.0, memory_length 2000, epsilon 0.17386304498693173, time 729.0, rides 126\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 1943, reward 528.0, memory_length 2000, epsilon 0.17370656824644348, time 736.0, rides 121\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 1944, reward 610.0, memory_length 2000, epsilon 0.17355023233502168, time 732.0, rides 146\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 1945, reward 516.0, memory_length 2000, epsilon 0.17339403712592016, time 730.0, rides 125\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 1946, reward 587.0, memory_length 2000, epsilon 0.17323798249250683, time 722.0, rides 132\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 1947, reward 705.0, memory_length 2000, epsilon 0.17308206830826356, time 729.0, rides 138\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 1948, reward 256.0, memory_length 2000, epsilon 0.17292629444678612, time 733.0, rides 132\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 1949, reward 638.0, memory_length 2000, epsilon 0.17277066078178402, time 733.0, rides 125\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 1950, reward 715.0, memory_length 2000, epsilon 0.17261516718708042, time 733.0, rides 136\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 1951, reward 712.0, memory_length 2000, epsilon 0.17245981353661205, time 724.0, rides 139\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 1952, reward 796.0, memory_length 2000, epsilon 0.1723045997044291, time 737.0, rides 136\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 1953, reward 688.0, memory_length 2000, epsilon 0.17214952556469512, time 734.0, rides 127\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 1954, reward 871.0, memory_length 2000, epsilon 0.1719945909916869, time 725.0, rides 124\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 1955, reward 664.0, memory_length 2000, epsilon 0.1718397958597944, time 737.0, rides 128\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 1956, reward 865.0, memory_length 2000, epsilon 0.17168514004352056, time 730.0, rides 135\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 1957, reward 958.0, memory_length 2000, epsilon 0.1715306234174814, time 729.0, rides 126\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 1958, reward 678.0, memory_length 2000, epsilon 0.17137624585640568, time 720.0, rides 133\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1959, reward 640.0, memory_length 2000, epsilon 0.17122200723513492, time 726.0, rides 125\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 1960, reward 591.0, memory_length 2000, epsilon 0.1710679074286233, time 726.0, rides 124\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 1961, reward 374.0, memory_length 2000, epsilon 0.17091394631193754, time 729.0, rides 135\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 1962, reward 997.0, memory_length 2000, epsilon 0.1707601237602568, time 730.0, rides 141\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 1963, reward 844.0, memory_length 2000, epsilon 0.17060643964887257, time 734.0, rides 125\n",
      "Initial State is  [1, 10, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1964, reward 655.0, memory_length 2000, epsilon 0.17045289385318857, time 726.0, rides 143\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 1965, reward 840.0, memory_length 2000, epsilon 0.1702994862487207, time 737.0, rides 139\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 1966, reward 723.0, memory_length 2000, epsilon 0.17014621671109686, time 733.0, rides 128\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1967, reward 754.0, memory_length 2000, epsilon 0.16999308511605687, time 725.0, rides 125\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 1968, reward 803.0, memory_length 2000, epsilon 0.1698400913394524, time 728.0, rides 129\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 1969, reward 774.0, memory_length 2000, epsilon 0.1696872352572469, time 722.0, rides 134\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 1970, reward 452.0, memory_length 2000, epsilon 0.1695345167455154, time 731.0, rides 143\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 1971, reward 693.0, memory_length 2000, epsilon 0.16938193568044443, time 735.0, rides 140\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 1972, reward 490.0, memory_length 2000, epsilon 0.16922949193833203, time 728.0, rides 131\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 1973, reward 341.0, memory_length 2000, epsilon 0.16907718539558753, time 732.0, rides 146\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 1974, reward 722.0, memory_length 2000, epsilon 0.1689250159287315, time 735.0, rides 136\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 1975, reward 640.0, memory_length 2000, epsilon 0.16877298341439564, time 727.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 1976, reward 816.0, memory_length 2000, epsilon 0.1686210877293227, time 728.0, rides 146\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 1977, reward 809.0, memory_length 2000, epsilon 0.1684693287503663, time 728.0, rides 129\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 1978, reward 766.0, memory_length 2000, epsilon 0.16831770635449098, time 736.0, rides 125\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 1979, reward 452.0, memory_length 2000, epsilon 0.16816622041877194, time 721.0, rides 128\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 1980, reward 479.0, memory_length 2000, epsilon 0.16801487082039504, time 728.0, rides 137\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 1981, reward 440.0, memory_length 2000, epsilon 0.16786365743665668, time 734.0, rides 125\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 1982, reward 755.0, memory_length 2000, epsilon 0.16771258014496368, time 726.0, rides 137\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 1983, reward 644.0, memory_length 2000, epsilon 0.1675616388228332, time 730.0, rides 131\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 1984, reward 701.0, memory_length 2000, epsilon 0.16741083334789264, time 727.0, rides 125\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 1985, reward 580.0, memory_length 2000, epsilon 0.16726016359787954, time 723.0, rides 138\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 1986, reward 1180.0, memory_length 2000, epsilon 0.16710962945064145, time 728.0, rides 138\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 1987, reward 678.0, memory_length 2000, epsilon 0.16695923078413588, time 730.0, rides 138\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 1988, reward 428.0, memory_length 2000, epsilon 0.16680896747643015, time 725.0, rides 127\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 1989, reward 1098.0, memory_length 2000, epsilon 0.16665883940570136, time 724.0, rides 143\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 1990, reward 808.0, memory_length 2000, epsilon 0.16650884645023623, time 725.0, rides 126\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 1991, reward 584.0, memory_length 2000, epsilon 0.166358988488431, time 741.0, rides 123\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 1992, reward 654.0, memory_length 2000, epsilon 0.1662092653987914, time 731.0, rides 122\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 1993, reward 554.0, memory_length 2000, epsilon 0.1660596770599325, time 735.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 1994, reward 872.0, memory_length 2000, epsilon 0.16591022335057856, time 727.0, rides 132\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 1995, reward 709.0, memory_length 2000, epsilon 0.16576090414956304, time 730.0, rides 135\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 1996, reward 565.0, memory_length 2000, epsilon 0.16561171933582844, time 728.0, rides 129\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 1997, reward 395.0, memory_length 2000, epsilon 0.1654626687884262, time 737.0, rides 119\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 1998, reward 647.0, memory_length 2000, epsilon 0.1653137523865166, time 729.0, rides 124\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 1999, reward 615.0, memory_length 2000, epsilon 0.16516497000936875, time 729.0, rides 120\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2000, reward 931.0, memory_length 2000, epsilon 0.1650163215363603, time 736.0, rides 126\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 2001, reward 808.0, memory_length 2000, epsilon 0.16486780684697758, time 734.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 2002, reward 765.0, memory_length 2000, epsilon 0.1647194258208153, time 741.0, rides 134\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 2003, reward 659.0, memory_length 2000, epsilon 0.16457117833757656, time 737.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2004, reward 839.0, memory_length 2000, epsilon 0.16442306427707273, time 724.0, rides 122\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2005, reward 653.0, memory_length 2000, epsilon 0.16427508351922337, time 723.0, rides 126\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 2006, reward 619.0, memory_length 2000, epsilon 0.16412723594405607, time 731.0, rides 131\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2007, reward 689.0, memory_length 2000, epsilon 0.1639795214317064, time 732.0, rides 130\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 2008, reward 707.0, memory_length 2000, epsilon 0.16383193986241787, time 725.0, rides 122\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2009, reward 557.0, memory_length 2000, epsilon 0.16368449111654168, time 733.0, rides 123\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 2010, reward 419.0, memory_length 2000, epsilon 0.1635371750745368, time 730.0, rides 136\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 2011, reward 619.0, memory_length 2000, epsilon 0.1633899916169697, time 726.0, rides 133\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 2012, reward 727.0, memory_length 2000, epsilon 0.16324294062451444, time 741.0, rides 134\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2013, reward 611.0, memory_length 2000, epsilon 0.16309602197795237, time 732.0, rides 129\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 2014, reward 867.0, memory_length 2000, epsilon 0.1629492355581722, time 731.0, rides 139\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 2015, reward 661.0, memory_length 2000, epsilon 0.16280258124616984, time 726.0, rides 127\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 2016, reward 716.0, memory_length 2000, epsilon 0.16265605892304827, time 728.0, rides 127\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 2017, reward 628.0, memory_length 2000, epsilon 0.16250966847001752, time 740.0, rides 124\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 2018, reward 532.0, memory_length 2000, epsilon 0.1623634097683945, time 727.0, rides 131\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 2019, reward 645.0, memory_length 2000, epsilon 0.16221728269960295, time 737.0, rides 135\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 2020, reward 565.0, memory_length 2000, epsilon 0.1620712871451733, time 721.0, rides 132\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 2021, reward 742.0, memory_length 2000, epsilon 0.16192542298674265, time 730.0, rides 125\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2022, reward 771.0, memory_length 2000, epsilon 0.16177969010605459, time 722.0, rides 130\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2023, reward 718.0, memory_length 2000, epsilon 0.16163408838495913, time 725.0, rides 128\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 2024, reward 683.0, memory_length 2000, epsilon 0.16148861770541267, time 721.0, rides 127\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 2025, reward 585.0, memory_length 2000, epsilon 0.1613432779494778, time 732.0, rides 128\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 2026, reward 801.0, memory_length 2000, epsilon 0.1611980689993233, time 729.0, rides 126\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 2027, reward 486.0, memory_length 2000, epsilon 0.1610529907372239, time 724.0, rides 132\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 2028, reward 1028.0, memory_length 2000, epsilon 0.1609080430455604, time 730.0, rides 125\n",
      "Initial State is  [3, 19, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2029, reward 813.0, memory_length 2000, epsilon 0.16076322580681937, time 734.0, rides 129\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2030, reward 766.0, memory_length 2000, epsilon 0.16061853890359323, time 730.0, rides 132\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 2031, reward 749.0, memory_length 2000, epsilon 0.16047398221858, time 742.0, rides 116\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 2032, reward 695.0, memory_length 2000, epsilon 0.1603295556345833, time 726.0, rides 121\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 2033, reward 425.0, memory_length 2000, epsilon 0.16018525903451217, time 722.0, rides 131\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 2034, reward 563.0, memory_length 2000, epsilon 0.1600410923013811, time 724.0, rides 131\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 2035, reward 444.0, memory_length 2000, epsilon 0.15989705531830986, time 730.0, rides 124\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2036, reward 586.0, memory_length 2000, epsilon 0.15975314796852338, time 731.0, rides 129\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 2037, reward 692.0, memory_length 2000, epsilon 0.1596093701353517, time 732.0, rides 126\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 2038, reward 620.0, memory_length 2000, epsilon 0.1594657217022299, time 735.0, rides 124\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 2039, reward 603.0, memory_length 2000, epsilon 0.15932220255269788, time 735.0, rides 120\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2040, reward 516.0, memory_length 2000, epsilon 0.15917881257040045, time 725.0, rides 118\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 2041, reward 717.0, memory_length 2000, epsilon 0.15903555163908709, time 729.0, rides 137\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 2042, reward 651.0, memory_length 2000, epsilon 0.15889241964261192, time 734.0, rides 126\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 2043, reward 780.0, memory_length 2000, epsilon 0.15874941646493357, time 725.0, rides 123\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 2044, reward 820.0, memory_length 2000, epsilon 0.15860654199011512, time 720.0, rides 131\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 2045, reward 796.0, memory_length 2000, epsilon 0.158463796102324, time 731.0, rides 127\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 2046, reward 730.0, memory_length 2000, epsilon 0.1583211786858319, time 728.0, rides 139\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 2047, reward 789.0, memory_length 2000, epsilon 0.15817868962501463, time 730.0, rides 123\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2048, reward 394.0, memory_length 2000, epsilon 0.15803632880435212, time 731.0, rides 120\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 2049, reward 763.0, memory_length 2000, epsilon 0.1578940961084282, time 734.0, rides 132\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 2050, reward 966.0, memory_length 2000, epsilon 0.1577519914219306, time 733.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 2051, reward 604.0, memory_length 2000, epsilon 0.15761001462965088, time 723.0, rides 122\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 2052, reward 714.0, memory_length 2000, epsilon 0.1574681656164842, time 725.0, rides 134\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 2053, reward 792.0, memory_length 2000, epsilon 0.15732644426742937, time 735.0, rides 124\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 2054, reward 898.0, memory_length 2000, epsilon 0.15718485046758868, time 725.0, rides 130\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 2055, reward 1130.0, memory_length 2000, epsilon 0.15704338410216784, time 724.0, rides 128\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 2056, reward 573.0, memory_length 2000, epsilon 0.1569020450564759, time 724.0, rides 124\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 2057, reward 634.0, memory_length 2000, epsilon 0.15676083321592507, time 722.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2058, reward 304.0, memory_length 2000, epsilon 0.15661974846603074, time 728.0, rides 120\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 2059, reward 728.0, memory_length 2000, epsilon 0.1564787906924113, time 724.0, rides 117\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 2060, reward 606.0, memory_length 2000, epsilon 0.15633795978078813, time 726.0, rides 125\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 2061, reward 775.0, memory_length 2000, epsilon 0.15619725561698541, time 723.0, rides 123\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2062, reward 837.0, memory_length 2000, epsilon 0.15605667808693013, time 727.0, rides 128\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 2063, reward 607.0, memory_length 2000, epsilon 0.1559162270766519, time 730.0, rides 118\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 2064, reward 582.0, memory_length 2000, epsilon 0.1557759024722829, time 727.0, rides 127\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 2065, reward 842.0, memory_length 2000, epsilon 0.15563570416005784, time 726.0, rides 126\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 2066, reward 382.0, memory_length 2000, epsilon 0.15549563202631378, time 728.0, rides 132\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 2067, reward 576.0, memory_length 2000, epsilon 0.1553556859574901, time 731.0, rides 131\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 2068, reward 712.0, memory_length 2000, epsilon 0.15521586584012836, time 732.0, rides 120\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 2069, reward 744.0, memory_length 2000, epsilon 0.15507617156087225, time 730.0, rides 124\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 2070, reward 665.0, memory_length 2000, epsilon 0.15493660300646747, time 724.0, rides 123\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2071, reward 526.0, memory_length 2000, epsilon 0.15479716006376165, time 735.0, rides 109\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 2072, reward 684.0, memory_length 2000, epsilon 0.15465784261970428, time 735.0, rides 133\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2073, reward 539.0, memory_length 2000, epsilon 0.15451865056134653, time 732.0, rides 122\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2074, reward 657.0, memory_length 2000, epsilon 0.15437958377584132, time 729.0, rides 132\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2075, reward 712.0, memory_length 2000, epsilon 0.15424064215044306, time 725.0, rides 121\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 2076, reward 393.0, memory_length 2000, epsilon 0.15410182557250765, time 730.0, rides 119\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 2077, reward 534.0, memory_length 2000, epsilon 0.1539631339294924, time 743.0, rides 126\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 2078, reward 535.0, memory_length 2000, epsilon 0.15382456710895587, time 726.0, rides 123\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2079, reward 585.0, memory_length 2000, epsilon 0.1536861249985578, time 727.0, rides 125\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 2080, reward 765.0, memory_length 2000, epsilon 0.1535478074860591, time 727.0, rides 124\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 2081, reward 546.0, memory_length 2000, epsilon 0.15340961445932164, time 725.0, rides 136\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2082, reward 1220.0, memory_length 2000, epsilon 0.15327154580630825, time 727.0, rides 125\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 2083, reward 445.0, memory_length 2000, epsilon 0.15313360141508256, time 733.0, rides 121\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 2084, reward 945.0, memory_length 2000, epsilon 0.152995781173809, time 731.0, rides 121\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2085, reward 777.0, memory_length 2000, epsilon 0.15285808497075257, time 726.0, rides 122\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 2086, reward 666.0, memory_length 2000, epsilon 0.1527205126942789, time 729.0, rides 127\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 2087, reward 1069.0, memory_length 2000, epsilon 0.15258306423285403, time 734.0, rides 129\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 2088, reward 1016.0, memory_length 2000, epsilon 0.15244573947504447, time 724.0, rides 113\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2089, reward 307.0, memory_length 2000, epsilon 0.15230853830951693, time 729.0, rides 126\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2090, reward 492.0, memory_length 2000, epsilon 0.15217146062503836, time 727.0, rides 117\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 2091, reward 532.0, memory_length 2000, epsilon 0.15203450631047583, time 725.0, rides 128\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2092, reward 349.0, memory_length 2000, epsilon 0.1518976752547964, time 724.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 2093, reward 881.0, memory_length 2000, epsilon 0.15176096734706707, time 731.0, rides 125\n",
      "Initial State is  [0, 22, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2094, reward 997.0, memory_length 2000, epsilon 0.1516243824764547, time 730.0, rides 136\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 2095, reward 639.0, memory_length 2000, epsilon 0.1514879205322259, time 726.0, rides 125\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 2096, reward 827.0, memory_length 2000, epsilon 0.15135158140374688, time 732.0, rides 115\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2097, reward 490.0, memory_length 2000, epsilon 0.15121536498048352, time 738.0, rides 118\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 2098, reward 769.0, memory_length 2000, epsilon 0.1510792711520011, time 724.0, rides 128\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 2099, reward 654.0, memory_length 2000, epsilon 0.15094329980796428, time 722.0, rides 119\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 2100, reward 601.0, memory_length 2000, epsilon 0.15080745083813712, time 732.0, rides 129\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 2101, reward 635.0, memory_length 2000, epsilon 0.1506717241323828, time 731.0, rides 126\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 2102, reward 593.0, memory_length 2000, epsilon 0.15053611958066365, time 726.0, rides 151\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 2103, reward 710.0, memory_length 2000, epsilon 0.15040063707304105, time 725.0, rides 126\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 2104, reward 680.0, memory_length 2000, epsilon 0.1502652764996753, time 729.0, rides 115\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 2105, reward 571.0, memory_length 2000, epsilon 0.1501300377508256, time 727.0, rides 132\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 2106, reward 472.0, memory_length 2000, epsilon 0.14999492071684983, time 737.0, rides 109\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 2107, reward 795.0, memory_length 2000, epsilon 0.14985992528820466, time 722.0, rides 127\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 2108, reward 574.0, memory_length 2000, epsilon 0.14972505135544528, time 730.0, rides 113\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 2109, reward 517.0, memory_length 2000, epsilon 0.1495902988092254, time 725.0, rides 131\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 2110, reward 799.0, memory_length 2000, epsilon 0.1494556675402971, time 733.0, rides 129\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 2111, reward 862.0, memory_length 2000, epsilon 0.14932115743951083, time 724.0, rides 121\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 2112, reward 481.0, memory_length 2000, epsilon 0.14918676839781528, time 723.0, rides 128\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 2113, reward 715.0, memory_length 2000, epsilon 0.14905250030625725, time 731.0, rides 120\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 2114, reward 892.0, memory_length 2000, epsilon 0.1489183530559816, time 730.0, rides 112\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 2115, reward 410.0, memory_length 2000, epsilon 0.14878432653823123, time 735.0, rides 134\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 2116, reward 601.0, memory_length 2000, epsilon 0.14865042064434683, time 726.0, rides 130\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 2117, reward 689.0, memory_length 2000, epsilon 0.14851663526576692, time 735.0, rides 120\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 2118, reward 514.0, memory_length 2000, epsilon 0.14838297029402772, time 732.0, rides 132\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 2119, reward 772.0, memory_length 2000, epsilon 0.1482494256207631, time 723.0, rides 122\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 2120, reward 765.0, memory_length 2000, epsilon 0.1481160011377044, time 732.0, rides 129\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 2121, reward 946.0, memory_length 2000, epsilon 0.14798269673668046, time 728.0, rides 123\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 2122, reward 691.0, memory_length 2000, epsilon 0.14784951230961746, time 730.0, rides 145\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 2123, reward 409.0, memory_length 2000, epsilon 0.14771644774853881, time 730.0, rides 144\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 2124, reward 833.0, memory_length 2000, epsilon 0.14758350294556513, time 737.0, rides 126\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 2125, reward 732.0, memory_length 2000, epsilon 0.14745067779291413, time 723.0, rides 130\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 2126, reward 1012.0, memory_length 2000, epsilon 0.1473179721829005, time 736.0, rides 134\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 2127, reward 425.0, memory_length 2000, epsilon 0.14718538600793588, time 733.0, rides 141\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 2128, reward 746.0, memory_length 2000, epsilon 0.14705291916052873, time 726.0, rides 135\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 2129, reward 659.0, memory_length 2000, epsilon 0.14692057153328425, time 722.0, rides 141\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 2130, reward 815.0, memory_length 2000, epsilon 0.14678834301890428, time 734.0, rides 144\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 2131, reward 512.0, memory_length 2000, epsilon 0.14665623351018728, time 724.0, rides 137\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 2132, reward 653.0, memory_length 2000, epsilon 0.1465242429000281, time 731.0, rides 142\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 2133, reward 594.0, memory_length 2000, epsilon 0.1463923710814181, time 740.0, rides 130\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2134, reward 691.0, memory_length 2000, epsilon 0.1462606179474448, time 731.0, rides 131\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2135, reward 804.0, memory_length 2000, epsilon 0.1461289833912921, time 722.0, rides 148\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2136, reward 843.0, memory_length 2000, epsilon 0.14599746730623994, time 729.0, rides 128\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 2137, reward 723.0, memory_length 2000, epsilon 0.14586606958566434, time 730.0, rides 128\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 2138, reward 713.0, memory_length 2000, epsilon 0.14573479012303725, time 734.0, rides 128\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 2139, reward 822.0, memory_length 2000, epsilon 0.1456036288119265, time 732.0, rides 134\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 2140, reward 818.0, memory_length 2000, epsilon 0.14547258554599576, time 726.0, rides 129\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 2141, reward 608.0, memory_length 2000, epsilon 0.14534166021900435, time 739.0, rides 132\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 2142, reward 760.0, memory_length 2000, epsilon 0.14521085272480724, time 728.0, rides 137\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 2143, reward 682.0, memory_length 2000, epsilon 0.1450801629573549, time 724.0, rides 133\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2144, reward 667.0, memory_length 2000, epsilon 0.14494959081069328, time 730.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 2145, reward 742.0, memory_length 2000, epsilon 0.14481913617896366, time 735.0, rides 132\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 2146, reward 319.0, memory_length 2000, epsilon 0.1446887989564026, time 729.0, rides 138\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2147, reward 663.0, memory_length 2000, epsilon 0.14455857903734184, time 735.0, rides 131\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 2148, reward 736.0, memory_length 2000, epsilon 0.14442847631620823, time 727.0, rides 136\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 2149, reward 430.0, memory_length 2000, epsilon 0.14429849068752365, time 733.0, rides 112\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 2150, reward 1027.0, memory_length 2000, epsilon 0.1441686220459049, time 728.0, rides 122\n",
      "Initial State is  [4, 1, 3]\n",
      "episode 2151, reward 1009.0, memory_length 2000, epsilon 0.14403887028606358, time 720.0, rides 134\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 2152, reward 640.0, memory_length 2000, epsilon 0.1439092353028061, time 729.0, rides 129\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2153, reward 606.0, memory_length 2000, epsilon 0.1437797169910336, time 727.0, rides 133\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2154, reward 847.0, memory_length 2000, epsilon 0.14365031524574165, time 736.0, rides 123\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 2155, reward 710.0, memory_length 2000, epsilon 0.14352102996202049, time 725.0, rides 132\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 2156, reward 527.0, memory_length 2000, epsilon 0.14339186103505466, time 727.0, rides 128\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2157, reward 961.0, memory_length 2000, epsilon 0.14326280836012312, time 723.0, rides 128\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 2158, reward 998.0, memory_length 2000, epsilon 0.143133871832599, time 726.0, rides 131\n",
      "Initial State is  [1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2159, reward 965.0, memory_length 2000, epsilon 0.14300505134794966, time 723.0, rides 130\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 2160, reward 749.0, memory_length 2000, epsilon 0.1428763468017365, time 728.0, rides 133\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2161, reward 848.0, memory_length 2000, epsilon 0.14274775808961493, time 731.0, rides 121\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 2162, reward 576.0, memory_length 2000, epsilon 0.14261928510733426, time 733.0, rides 118\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 2163, reward 1170.0, memory_length 2000, epsilon 0.14249092775073766, time 729.0, rides 130\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 2164, reward 786.0, memory_length 2000, epsilon 0.14236268591576198, time 735.0, rides 119\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2165, reward 943.0, memory_length 2000, epsilon 0.1422345594984378, time 737.0, rides 133\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2166, reward 853.0, memory_length 2000, epsilon 0.1421065483948892, time 731.0, rides 132\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2167, reward 790.0, memory_length 2000, epsilon 0.1419786525013338, time 734.0, rides 128\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 2168, reward 990.0, memory_length 2000, epsilon 0.1418508717140826, time 728.0, rides 143\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 2169, reward 966.0, memory_length 2000, epsilon 0.1417232059295399, time 731.0, rides 141\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 2170, reward 784.0, memory_length 2000, epsilon 0.14159565504420332, time 727.0, rides 132\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2171, reward 884.0, memory_length 2000, epsilon 0.14146821895466355, time 737.0, rides 129\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2172, reward 696.0, memory_length 2000, epsilon 0.14134089755760434, time 727.0, rides 135\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 2173, reward 777.0, memory_length 2000, epsilon 0.1412136907498025, time 725.0, rides 118\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 2174, reward 510.0, memory_length 2000, epsilon 0.14108659842812768, time 730.0, rides 139\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 2175, reward 813.0, memory_length 2000, epsilon 0.14095962048954236, time 730.0, rides 126\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 2176, reward 256.0, memory_length 2000, epsilon 0.14083275683110177, time 726.0, rides 127\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2177, reward 749.0, memory_length 2000, epsilon 0.14070600734995378, time 731.0, rides 133\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 2178, reward 786.0, memory_length 2000, epsilon 0.14057937194333883, time 731.0, rides 140\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2179, reward 767.0, memory_length 2000, epsilon 0.14045285050858983, time 736.0, rides 114\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 2180, reward 952.0, memory_length 2000, epsilon 0.1403264429431321, time 734.0, rides 131\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 2181, reward 622.0, memory_length 2000, epsilon 0.14020014914448328, time 730.0, rides 139\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2182, reward 856.0, memory_length 2000, epsilon 0.14007396901025324, time 733.0, rides 128\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2183, reward 503.0, memory_length 2000, epsilon 0.139947902438144, time 726.0, rides 136\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 2184, reward 798.0, memory_length 2000, epsilon 0.13982194932594968, time 723.0, rides 133\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 2185, reward 713.0, memory_length 2000, epsilon 0.13969610957155632, time 734.0, rides 131\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2186, reward 818.0, memory_length 2000, epsilon 0.13957038307294192, time 723.0, rides 141\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 2187, reward 848.0, memory_length 2000, epsilon 0.13944476972817627, time 730.0, rides 135\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 2188, reward 972.0, memory_length 2000, epsilon 0.13931926943542092, time 732.0, rides 125\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 2189, reward 845.0, memory_length 2000, epsilon 0.13919388209292904, time 724.0, rides 126\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 2190, reward 509.0, memory_length 2000, epsilon 0.1390686075990454, time 728.0, rides 148\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 2191, reward 618.0, memory_length 2000, epsilon 0.13894344585220628, time 731.0, rides 129\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 2192, reward 847.0, memory_length 2000, epsilon 0.1388183967509393, time 727.0, rides 143\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 2193, reward 639.0, memory_length 2000, epsilon 0.13869346019386344, time 729.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 2194, reward 406.0, memory_length 2000, epsilon 0.13856863607968897, time 726.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 2195, reward 674.0, memory_length 2000, epsilon 0.13844392430721725, time 724.0, rides 141\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 2196, reward 930.0, memory_length 2000, epsilon 0.13831932477534076, time 733.0, rides 118\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 2197, reward 967.0, memory_length 2000, epsilon 0.13819483738304295, time 727.0, rides 153\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2198, reward 750.0, memory_length 2000, epsilon 0.1380704620293982, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 2199, reward 627.0, memory_length 2000, epsilon 0.13794619861357174, time 724.0, rides 125\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 2200, reward 763.0, memory_length 2000, epsilon 0.1378220470348195, time 726.0, rides 111\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 2201, reward 611.0, memory_length 2000, epsilon 0.13769800719248818, time 732.0, rides 111\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 2202, reward 605.0, memory_length 2000, epsilon 0.13757407898601492, time 725.0, rides 131\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 2203, reward 670.0, memory_length 2000, epsilon 0.13745026231492752, time 726.0, rides 141\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 2204, reward 559.0, memory_length 2000, epsilon 0.13732655707884409, time 722.0, rides 136\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 2205, reward 1037.0, memory_length 2000, epsilon 0.13720296317747313, time 725.0, rides 120\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2206, reward 724.0, memory_length 2000, epsilon 0.13707948051061342, time 729.0, rides 126\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 2207, reward 871.0, memory_length 2000, epsilon 0.13695610897815386, time 728.0, rides 136\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 2208, reward 799.0, memory_length 2000, epsilon 0.13683284848007352, time 737.0, rides 151\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 2209, reward 844.0, memory_length 2000, epsilon 0.13670969891644144, time 728.0, rides 123\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 2210, reward 654.0, memory_length 2000, epsilon 0.13658666018741664, time 724.0, rides 131\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2211, reward 833.0, memory_length 2000, epsilon 0.13646373219324795, time 728.0, rides 133\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2212, reward 592.0, memory_length 2000, epsilon 0.13634091483427402, time 728.0, rides 132\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 2213, reward 605.0, memory_length 2000, epsilon 0.13621820801092316, time 737.0, rides 148\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 2214, reward 902.0, memory_length 2000, epsilon 0.13609561162371334, time 728.0, rides 128\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 2215, reward 1168.0, memory_length 2000, epsilon 0.135973125573252, time 724.0, rides 132\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 2216, reward 807.0, memory_length 2000, epsilon 0.13585074976023606, time 732.0, rides 128\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 2217, reward 442.0, memory_length 2000, epsilon 0.13572848408545185, time 729.0, rides 125\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2218, reward 759.0, memory_length 2000, epsilon 0.13560632844977494, time 727.0, rides 133\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 2219, reward 680.0, memory_length 2000, epsilon 0.13548428275417013, time 732.0, rides 118\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 2220, reward 864.0, memory_length 2000, epsilon 0.13536234689969137, time 734.0, rides 148\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2221, reward 810.0, memory_length 2000, epsilon 0.13524052078748164, time 731.0, rides 140\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 2222, reward 725.0, memory_length 2000, epsilon 0.1351188043187729, time 730.0, rides 132\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2223, reward 696.0, memory_length 2000, epsilon 0.134997197394886, time 728.0, rides 132\n",
      "Initial State is  [4, 23, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2224, reward 1151.0, memory_length 2000, epsilon 0.1348756999172306, time 729.0, rides 131\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 2225, reward 662.0, memory_length 2000, epsilon 0.1347543117873051, time 725.0, rides 127\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 2226, reward 1013.0, memory_length 2000, epsilon 0.1346330329066965, time 727.0, rides 130\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 2227, reward 704.0, memory_length 2000, epsilon 0.13451186317708047, time 730.0, rides 124\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 2228, reward 986.0, memory_length 2000, epsilon 0.1343908025002211, time 727.0, rides 148\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 2229, reward 595.0, memory_length 2000, epsilon 0.13426985077797088, time 732.0, rides 132\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 2230, reward 790.0, memory_length 2000, epsilon 0.1341490079122707, time 728.0, rides 129\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2231, reward 569.0, memory_length 2000, epsilon 0.13402827380514964, time 731.0, rides 127\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 2232, reward 742.0, memory_length 2000, epsilon 0.133907648358725, time 735.0, rides 127\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 2233, reward 1099.0, memory_length 2000, epsilon 0.13378713147520216, time 724.0, rides 135\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 2234, reward 876.0, memory_length 2000, epsilon 0.13366672305687446, time 727.0, rides 139\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2235, reward 563.0, memory_length 2000, epsilon 0.13354642300612327, time 734.0, rides 134\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 2236, reward 876.0, memory_length 2000, epsilon 0.13342623122541775, time 724.0, rides 129\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 2237, reward 704.0, memory_length 2000, epsilon 0.13330614761731488, time 730.0, rides 144\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 2238, reward 693.0, memory_length 2000, epsilon 0.1331861720844593, time 728.0, rides 137\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 2239, reward 684.0, memory_length 2000, epsilon 0.1330663045295833, time 727.0, rides 123\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 2240, reward 807.0, memory_length 2000, epsilon 0.13294654485550667, time 725.0, rides 134\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 2241, reward 772.0, memory_length 2000, epsilon 0.1328268929651367, time 727.0, rides 144\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 2242, reward 883.0, memory_length 2000, epsilon 0.13270734876146806, time 730.0, rides 145\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2243, reward 704.0, memory_length 2000, epsilon 0.13258791214758273, time 737.0, rides 136\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 2244, reward 839.0, memory_length 2000, epsilon 0.1324685830266499, time 733.0, rides 131\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 2245, reward 681.0, memory_length 2000, epsilon 0.13234936130192593, time 735.0, rides 123\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 2246, reward 756.0, memory_length 2000, epsilon 0.1322302468767542, time 729.0, rides 134\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2247, reward 637.0, memory_length 2000, epsilon 0.13211123965456512, time 728.0, rides 133\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 2248, reward 700.0, memory_length 2000, epsilon 0.131992339538876, time 730.0, rides 142\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 2249, reward 1049.0, memory_length 2000, epsilon 0.13187354643329102, time 738.0, rides 142\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 2250, reward 635.0, memory_length 2000, epsilon 0.13175486024150107, time 726.0, rides 136\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 2251, reward 868.0, memory_length 2000, epsilon 0.1316362808672837, time 722.0, rides 146\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 2252, reward 373.0, memory_length 2000, epsilon 0.13151780821450315, time 727.0, rides 121\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2253, reward 673.0, memory_length 2000, epsilon 0.1313994421871101, time 733.0, rides 137\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 2254, reward 550.0, memory_length 2000, epsilon 0.1312811826891417, time 726.0, rides 136\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 2255, reward 201.0, memory_length 2000, epsilon 0.13116302962472148, time 728.0, rides 143\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 2256, reward 1315.0, memory_length 2000, epsilon 0.13104498289805924, time 726.0, rides 115\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 2257, reward 902.0, memory_length 2000, epsilon 0.130927042413451, time 728.0, rides 126\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 2258, reward 931.0, memory_length 2000, epsilon 0.13080920807527888, time 727.0, rides 120\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 2259, reward 386.0, memory_length 2000, epsilon 0.13069147978801113, time 728.0, rides 135\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2260, reward 760.0, memory_length 2000, epsilon 0.13057385745620192, time 741.0, rides 142\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 2261, reward 962.0, memory_length 2000, epsilon 0.13045634098449135, time 733.0, rides 131\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 2262, reward 497.0, memory_length 2000, epsilon 0.13033893027760532, time 726.0, rides 133\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 2263, reward 608.0, memory_length 2000, epsilon 0.13022162524035547, time 732.0, rides 142\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 2264, reward 726.0, memory_length 2000, epsilon 0.13010442577763914, time 733.0, rides 148\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 2265, reward 671.0, memory_length 2000, epsilon 0.12998733179443928, time 723.0, rides 136\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 2266, reward 956.0, memory_length 2000, epsilon 0.12987034319582427, time 728.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 2267, reward 658.0, memory_length 2000, epsilon 0.12975345988694803, time 726.0, rides 124\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 2268, reward 419.0, memory_length 2000, epsilon 0.12963668177304977, time 728.0, rides 125\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2269, reward 920.0, memory_length 2000, epsilon 0.12952000875945402, time 729.0, rides 121\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 2270, reward 619.0, memory_length 2000, epsilon 0.1294034407515705, time 729.0, rides 138\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 2271, reward 913.0, memory_length 2000, epsilon 0.12928697765489408, time 724.0, rides 121\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 2272, reward 935.0, memory_length 2000, epsilon 0.12917061937500468, time 730.0, rides 138\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 2273, reward 815.0, memory_length 2000, epsilon 0.12905436581756718, time 725.0, rides 126\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 2274, reward 668.0, memory_length 2000, epsilon 0.12893821688833138, time 725.0, rides 125\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2275, reward 661.0, memory_length 2000, epsilon 0.12882217249313188, time 736.0, rides 135\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 2276, reward 524.0, memory_length 2000, epsilon 0.12870623253788807, time 725.0, rides 128\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 2277, reward 767.0, memory_length 2000, epsilon 0.12859039692860397, time 723.0, rides 126\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 2278, reward 527.0, memory_length 2000, epsilon 0.12847466557136822, time 723.0, rides 143\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 2279, reward 569.0, memory_length 2000, epsilon 0.128359038372354, time 726.0, rides 125\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 2280, reward 658.0, memory_length 2000, epsilon 0.12824351523781888, time 730.0, rides 135\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 2281, reward 580.0, memory_length 2000, epsilon 0.12812809607410483, time 729.0, rides 132\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2282, reward 730.0, memory_length 2000, epsilon 0.12801278078763814, time 726.0, rides 129\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 2283, reward 719.0, memory_length 2000, epsilon 0.12789756928492926, time 740.0, rides 139\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 2284, reward 705.0, memory_length 2000, epsilon 0.12778246147257283, time 728.0, rides 135\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 2285, reward 913.0, memory_length 2000, epsilon 0.1276674572572475, time 736.0, rides 127\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 2286, reward 765.0, memory_length 2000, epsilon 0.12755255654571598, time 734.0, rides 135\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 2287, reward 770.0, memory_length 2000, epsilon 0.12743775924482484, time 724.0, rides 139\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 2288, reward 824.0, memory_length 2000, epsilon 0.1273230652615045, time 729.0, rides 135\n",
      "Initial State is  [4, 6, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2289, reward 651.0, memory_length 2000, epsilon 0.12720847450276915, time 728.0, rides 134\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 2290, reward 686.0, memory_length 2000, epsilon 0.12709398687571666, time 730.0, rides 130\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 2291, reward 946.0, memory_length 2000, epsilon 0.1269796022875285, time 732.0, rides 113\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 2292, reward 646.0, memory_length 2000, epsilon 0.1268653206454697, time 738.0, rides 125\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 2293, reward 990.0, memory_length 2000, epsilon 0.1267511418568888, time 729.0, rides 134\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 2294, reward 781.0, memory_length 2000, epsilon 0.1266370658292176, time 733.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 2295, reward 534.0, memory_length 2000, epsilon 0.12652309246997132, time 726.0, rides 137\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 2296, reward 890.0, memory_length 2000, epsilon 0.12640922168674834, time 725.0, rides 139\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 2297, reward 672.0, memory_length 2000, epsilon 0.12629545338723028, time 731.0, rides 121\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2298, reward 933.0, memory_length 2000, epsilon 0.12618178747918177, time 726.0, rides 147\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 2299, reward 599.0, memory_length 2000, epsilon 0.1260682238704505, time 738.0, rides 117\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 2300, reward 1076.0, memory_length 2000, epsilon 0.12595476246896709, time 727.0, rides 134\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2301, reward 870.0, memory_length 2000, epsilon 0.125841403182745, time 725.0, rides 161\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 2302, reward 753.0, memory_length 2000, epsilon 0.12572814591988052, time 730.0, rides 135\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2303, reward 827.0, memory_length 2000, epsilon 0.12561499058855263, time 729.0, rides 127\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 2304, reward 545.0, memory_length 2000, epsilon 0.12550193709702293, time 726.0, rides 126\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 2305, reward 988.0, memory_length 2000, epsilon 0.1253889853536356, time 731.0, rides 139\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 2306, reward 1034.0, memory_length 2000, epsilon 0.12527613526681733, time 734.0, rides 144\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 2307, reward 808.0, memory_length 2000, epsilon 0.12516338674507718, time 746.0, rides 127\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 2308, reward 545.0, memory_length 2000, epsilon 0.1250507396970066, time 732.0, rides 137\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2309, reward 862.0, memory_length 2000, epsilon 0.1249381940312793, time 736.0, rides 141\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 2310, reward 712.0, memory_length 2000, epsilon 0.12482574965665115, time 732.0, rides 129\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2311, reward 809.0, memory_length 2000, epsilon 0.12471340648196017, time 730.0, rides 149\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 2312, reward 633.0, memory_length 2000, epsilon 0.1246011644161264, time 729.0, rides 136\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2313, reward 659.0, memory_length 2000, epsilon 0.12448902336815189, time 733.0, rides 129\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 2314, reward 770.0, memory_length 2000, epsilon 0.12437698324712056, time 736.0, rides 153\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2315, reward 596.0, memory_length 2000, epsilon 0.12426504396219815, time 728.0, rides 128\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 2316, reward 891.0, memory_length 2000, epsilon 0.12415320542263217, time 734.0, rides 139\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 2317, reward 498.0, memory_length 2000, epsilon 0.1240414675377518, time 727.0, rides 130\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 2318, reward 580.0, memory_length 2000, epsilon 0.12392983021696782, time 723.0, rides 130\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 2319, reward 702.0, memory_length 2000, epsilon 0.12381829336977256, time 735.0, rides 139\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 2320, reward 803.0, memory_length 2000, epsilon 0.12370685690573976, time 733.0, rides 141\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 2321, reward 744.0, memory_length 2000, epsilon 0.1235955207345246, time 726.0, rides 137\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 2322, reward 715.0, memory_length 2000, epsilon 0.12348428476586353, time 730.0, rides 134\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 2323, reward 822.0, memory_length 2000, epsilon 0.12337314890957425, time 723.0, rides 127\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 2324, reward 605.0, memory_length 2000, epsilon 0.12326211307555564, time 729.0, rides 141\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 2325, reward 470.0, memory_length 2000, epsilon 0.12315117717378764, time 729.0, rides 143\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 2326, reward 1024.0, memory_length 2000, epsilon 0.12304034111433122, time 732.0, rides 129\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 2327, reward 753.0, memory_length 2000, epsilon 0.12292960480732833, time 733.0, rides 126\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 2328, reward 1041.0, memory_length 2000, epsilon 0.12281896816300172, time 724.0, rides 133\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 2329, reward 726.0, memory_length 2000, epsilon 0.12270843109165502, time 728.0, rides 140\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 2330, reward 739.0, memory_length 2000, epsilon 0.12259799350367254, time 724.0, rides 128\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 2331, reward 669.0, memory_length 2000, epsilon 0.12248765530951923, time 728.0, rides 124\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2332, reward 920.0, memory_length 2000, epsilon 0.12237741641974066, time 731.0, rides 125\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 2333, reward 820.0, memory_length 2000, epsilon 0.12226727674496289, time 732.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2334, reward 983.0, memory_length 2000, epsilon 0.12215723619589243, time 733.0, rides 127\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2335, reward 915.0, memory_length 2000, epsilon 0.12204729468331613, time 727.0, rides 137\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 2336, reward 577.0, memory_length 2000, epsilon 0.12193745211810114, time 727.0, rides 143\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 2337, reward 793.0, memory_length 2000, epsilon 0.12182770841119485, time 737.0, rides 141\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 2338, reward 856.0, memory_length 2000, epsilon 0.12171806347362477, time 728.0, rides 141\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2339, reward 647.0, memory_length 2000, epsilon 0.1216085172164985, time 727.0, rides 144\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 2340, reward 596.0, memory_length 2000, epsilon 0.12149906955100365, time 727.0, rides 132\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 2341, reward 645.0, memory_length 2000, epsilon 0.12138972038840774, time 731.0, rides 127\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 2342, reward 1034.0, memory_length 2000, epsilon 0.12128046964005817, time 726.0, rides 137\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2343, reward 943.0, memory_length 2000, epsilon 0.12117131721738213, time 723.0, rides 126\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 2344, reward 937.0, memory_length 2000, epsilon 0.12106226303188648, time 735.0, rides 131\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 2345, reward 816.0, memory_length 2000, epsilon 0.12095330699515779, time 726.0, rides 123\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 2346, reward 945.0, memory_length 2000, epsilon 0.12084444901886214, time 732.0, rides 147\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2347, reward 597.0, memory_length 2000, epsilon 0.12073568901474516, time 724.0, rides 141\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 2348, reward 920.0, memory_length 2000, epsilon 0.12062702689463188, time 728.0, rides 121\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2349, reward 995.0, memory_length 2000, epsilon 0.12051846257042671, time 739.0, rides 138\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 2350, reward 943.0, memory_length 2000, epsilon 0.12040999595411332, time 723.0, rides 133\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 2351, reward 415.0, memory_length 2000, epsilon 0.12030162695775462, time 726.0, rides 127\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 2352, reward 663.0, memory_length 2000, epsilon 0.12019335549349264, time 729.0, rides 148\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 2353, reward 759.0, memory_length 2000, epsilon 0.12008518147354849, time 731.0, rides 131\n",
      "Initial State is  [2, 8, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2354, reward 1049.0, memory_length 2000, epsilon 0.1199771048102223, time 732.0, rides 129\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2355, reward 782.0, memory_length 2000, epsilon 0.11986912541589309, time 731.0, rides 129\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 2356, reward 671.0, memory_length 2000, epsilon 0.11976124320301879, time 734.0, rides 135\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 2357, reward 731.0, memory_length 2000, epsilon 0.11965345808413606, time 722.0, rides 121\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 2358, reward 794.0, memory_length 2000, epsilon 0.11954576997186034, time 727.0, rides 129\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 2359, reward 629.0, memory_length 2000, epsilon 0.11943817877888566, time 725.0, rides 128\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 2360, reward 1072.0, memory_length 2000, epsilon 0.11933068441798465, time 731.0, rides 131\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 2361, reward 548.0, memory_length 2000, epsilon 0.11922328680200847, time 733.0, rides 128\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 2362, reward 637.0, memory_length 2000, epsilon 0.11911598584388666, time 725.0, rides 141\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 2363, reward 571.0, memory_length 2000, epsilon 0.11900878145662716, time 726.0, rides 132\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 2364, reward 945.0, memory_length 2000, epsilon 0.1189016735533162, time 732.0, rides 148\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2365, reward 645.0, memory_length 2000, epsilon 0.11879466204711821, time 723.0, rides 135\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 2366, reward 658.0, memory_length 2000, epsilon 0.1186877468512758, time 731.0, rides 136\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 2367, reward 652.0, memory_length 2000, epsilon 0.11858092787910965, time 733.0, rides 128\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 2368, reward 795.0, memory_length 2000, epsilon 0.11847420504401845, time 725.0, rides 140\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 2369, reward 1044.0, memory_length 2000, epsilon 0.11836757825947884, time 731.0, rides 145\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 2370, reward 941.0, memory_length 2000, epsilon 0.11826104743904531, time 725.0, rides 127\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 2371, reward 958.0, memory_length 2000, epsilon 0.11815461249635016, time 730.0, rides 139\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 2372, reward 987.0, memory_length 2000, epsilon 0.11804827334510344, time 732.0, rides 136\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 2373, reward 837.0, memory_length 2000, epsilon 0.11794202989909285, time 725.0, rides 128\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 2374, reward 316.0, memory_length 2000, epsilon 0.11783588207218366, time 730.0, rides 115\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 2375, reward 755.0, memory_length 2000, epsilon 0.1177298297783187, time 728.0, rides 146\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 2376, reward 764.0, memory_length 2000, epsilon 0.1176238729315182, time 726.0, rides 136\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 2377, reward 1030.0, memory_length 2000, epsilon 0.11751801144587984, time 733.0, rides 142\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 2378, reward 695.0, memory_length 2000, epsilon 0.11741224523557854, time 721.0, rides 130\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 2379, reward 711.0, memory_length 2000, epsilon 0.11730657421486652, time 725.0, rides 132\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 2380, reward 634.0, memory_length 2000, epsilon 0.11720099829807314, time 731.0, rides 155\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 2381, reward 1010.0, memory_length 2000, epsilon 0.11709551739960487, time 722.0, rides 133\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 2382, reward 677.0, memory_length 2000, epsilon 0.11699013143394522, time 730.0, rides 129\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 2383, reward 782.0, memory_length 2000, epsilon 0.11688484031565467, time 731.0, rides 112\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 2384, reward 760.0, memory_length 2000, epsilon 0.11677964395937059, time 727.0, rides 130\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 2385, reward 605.0, memory_length 2000, epsilon 0.11667454227980716, time 729.0, rides 124\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 2386, reward 882.0, memory_length 2000, epsilon 0.11656953519175532, time 735.0, rides 130\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2387, reward 914.0, memory_length 2000, epsilon 0.11646462261008274, time 727.0, rides 132\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2388, reward 658.0, memory_length 2000, epsilon 0.11635980444973366, time 725.0, rides 141\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 2389, reward 933.0, memory_length 2000, epsilon 0.1162550806257289, time 724.0, rides 156\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 2390, reward 819.0, memory_length 2000, epsilon 0.11615045105316574, time 737.0, rides 120\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2391, reward 454.0, memory_length 2000, epsilon 0.11604591564721789, time 736.0, rides 133\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 2392, reward 546.0, memory_length 2000, epsilon 0.1159414743231354, time 735.0, rides 125\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 2393, reward 784.0, memory_length 2000, epsilon 0.11583712699624457, time 726.0, rides 137\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 2394, reward 371.0, memory_length 2000, epsilon 0.11573287358194795, time 730.0, rides 121\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2395, reward 738.0, memory_length 2000, epsilon 0.11562871399572419, time 725.0, rides 127\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 2396, reward 750.0, memory_length 2000, epsilon 0.11552464815312803, time 725.0, rides 136\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 2397, reward 416.0, memory_length 2000, epsilon 0.11542067596979022, time 723.0, rides 129\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 2398, reward 756.0, memory_length 2000, epsilon 0.11531679736141741, time 735.0, rides 133\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2399, reward 431.0, memory_length 2000, epsilon 0.11521301224379213, time 724.0, rides 148\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 2400, reward 614.0, memory_length 2000, epsilon 0.11510932053277272, time 739.0, rides 131\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 2401, reward 435.0, memory_length 2000, epsilon 0.11500572214429322, time 734.0, rides 130\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 2402, reward 904.0, memory_length 2000, epsilon 0.11490221699436336, time 722.0, rides 130\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 2403, reward 871.0, memory_length 2000, epsilon 0.11479880499906843, time 726.0, rides 128\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 2404, reward 883.0, memory_length 2000, epsilon 0.11469548607456927, time 738.0, rides 126\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2405, reward 493.0, memory_length 2000, epsilon 0.11459226013710215, time 732.0, rides 125\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 2406, reward 743.0, memory_length 2000, epsilon 0.11448912710297876, time 735.0, rides 132\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 2407, reward 1025.0, memory_length 2000, epsilon 0.11438608688858608, time 727.0, rides 122\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 2408, reward 480.0, memory_length 2000, epsilon 0.11428313941038636, time 725.0, rides 137\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2409, reward 852.0, memory_length 2000, epsilon 0.11418028458491701, time 730.0, rides 134\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 2410, reward 555.0, memory_length 2000, epsilon 0.11407752232879058, time 730.0, rides 145\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 2411, reward 348.0, memory_length 2000, epsilon 0.11397485255869466, time 730.0, rides 144\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2412, reward 991.0, memory_length 2000, epsilon 0.11387227519139184, time 725.0, rides 122\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2413, reward 910.0, memory_length 2000, epsilon 0.11376979014371959, time 730.0, rides 133\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 2414, reward 811.0, memory_length 2000, epsilon 0.11366739733259024, time 725.0, rides 136\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2415, reward 902.0, memory_length 2000, epsilon 0.1135650966749909, time 732.0, rides 116\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 2416, reward 904.0, memory_length 2000, epsilon 0.11346288808798341, time 730.0, rides 135\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2417, reward 1074.0, memory_length 2000, epsilon 0.11336077148870423, time 733.0, rides 129\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 2418, reward 852.0, memory_length 2000, epsilon 0.11325874679436439, time 727.0, rides 140\n",
      "Initial State is  [2, 14, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2419, reward 777.0, memory_length 2000, epsilon 0.11315681392224945, time 727.0, rides 134\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 2420, reward 644.0, memory_length 2000, epsilon 0.11305497278971943, time 729.0, rides 136\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 2421, reward 684.0, memory_length 2000, epsilon 0.11295322331420868, time 741.0, rides 129\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2422, reward 832.0, memory_length 2000, epsilon 0.11285156541322588, time 724.0, rides 127\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 2423, reward 855.0, memory_length 2000, epsilon 0.11274999900435398, time 721.0, rides 134\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 2424, reward 963.0, memory_length 2000, epsilon 0.11264852400525006, time 728.0, rides 134\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 2425, reward 431.0, memory_length 2000, epsilon 0.11254714033364534, time 736.0, rides 126\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2426, reward 1019.0, memory_length 2000, epsilon 0.11244584790734506, time 727.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 2427, reward 1125.0, memory_length 2000, epsilon 0.11234464664422845, time 733.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2428, reward 631.0, memory_length 2000, epsilon 0.11224353646224865, time 726.0, rides 135\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 2429, reward 606.0, memory_length 2000, epsilon 0.11214251727943263, time 729.0, rides 121\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 2430, reward 698.0, memory_length 2000, epsilon 0.11204158901388113, time 724.0, rides 149\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 2431, reward 1041.0, memory_length 2000, epsilon 0.11194075158376864, time 724.0, rides 129\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 2432, reward 725.0, memory_length 2000, epsilon 0.11184000490734325, time 725.0, rides 129\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 2433, reward 841.0, memory_length 2000, epsilon 0.11173934890292664, time 737.0, rides 132\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 2434, reward 787.0, memory_length 2000, epsilon 0.111638783488914, time 723.0, rides 140\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 2435, reward 848.0, memory_length 2000, epsilon 0.11153830858377398, time 731.0, rides 130\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2436, reward 680.0, memory_length 2000, epsilon 0.11143792410604858, time 729.0, rides 134\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2437, reward 460.0, memory_length 2000, epsilon 0.11133762997435313, time 727.0, rides 126\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 2438, reward 798.0, memory_length 2000, epsilon 0.11123742610737622, time 725.0, rides 148\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 2439, reward 1221.0, memory_length 2000, epsilon 0.11113731242387959, time 728.0, rides 136\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 2440, reward 521.0, memory_length 2000, epsilon 0.11103728884269809, time 724.0, rides 128\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2441, reward 671.0, memory_length 2000, epsilon 0.11093735528273967, time 734.0, rides 125\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 2442, reward 816.0, memory_length 2000, epsilon 0.1108375116629852, time 726.0, rides 134\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2443, reward 972.0, memory_length 2000, epsilon 0.1107377579024885, time 724.0, rides 136\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 2444, reward 831.0, memory_length 2000, epsilon 0.11063809392037627, time 726.0, rides 140\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 2445, reward 850.0, memory_length 2000, epsilon 0.11053851963584793, time 730.0, rides 123\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 2446, reward 801.0, memory_length 2000, epsilon 0.11043903496817567, time 731.0, rides 138\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 2447, reward 672.0, memory_length 2000, epsilon 0.1103396398367043, time 733.0, rides 138\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 2448, reward 973.0, memory_length 2000, epsilon 0.11024033416085127, time 726.0, rides 143\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 2449, reward 804.0, memory_length 2000, epsilon 0.11014111786010651, time 724.0, rides 128\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 2450, reward 1032.0, memory_length 2000, epsilon 0.1100419908540324, time 734.0, rides 138\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 2451, reward 522.0, memory_length 2000, epsilon 0.10994295306226377, time 733.0, rides 136\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 2452, reward 791.0, memory_length 2000, epsilon 0.10984400440450773, time 729.0, rides 127\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 2453, reward 827.0, memory_length 2000, epsilon 0.10974514480054368, time 740.0, rides 124\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 2454, reward 578.0, memory_length 2000, epsilon 0.10964637417022319, time 739.0, rides 127\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 2455, reward 907.0, memory_length 2000, epsilon 0.10954769243346998, time 727.0, rides 120\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 2456, reward 880.0, memory_length 2000, epsilon 0.10944909951027985, time 724.0, rides 137\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 2457, reward 825.0, memory_length 2000, epsilon 0.1093505953207206, time 729.0, rides 131\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 2458, reward 539.0, memory_length 2000, epsilon 0.10925217978493194, time 724.0, rides 142\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 2459, reward 732.0, memory_length 2000, epsilon 0.10915385282312551, time 727.0, rides 136\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 2460, reward 845.0, memory_length 2000, epsilon 0.1090556143555847, time 732.0, rides 133\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2461, reward 562.0, memory_length 2000, epsilon 0.10895746430266467, time 735.0, rides 118\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 2462, reward 589.0, memory_length 2000, epsilon 0.10885940258479228, time 721.0, rides 130\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2463, reward 699.0, memory_length 2000, epsilon 0.10876142912246596, time 725.0, rides 127\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 2464, reward 830.0, memory_length 2000, epsilon 0.10866354383625575, time 732.0, rides 133\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 2465, reward 446.0, memory_length 2000, epsilon 0.10856574664680312, time 733.0, rides 120\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 2466, reward 482.0, memory_length 2000, epsilon 0.10846803747482099, time 730.0, rides 125\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2467, reward 804.0, memory_length 2000, epsilon 0.10837041624109366, time 727.0, rides 131\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 2468, reward 682.0, memory_length 2000, epsilon 0.10827288286647667, time 728.0, rides 139\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 2469, reward 771.0, memory_length 2000, epsilon 0.10817543727189684, time 729.0, rides 128\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 2470, reward 571.0, memory_length 2000, epsilon 0.10807807937835213, time 735.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 2471, reward 799.0, memory_length 2000, epsilon 0.10798080910691162, time 732.0, rides 126\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 2472, reward 687.0, memory_length 2000, epsilon 0.10788362637871539, time 736.0, rides 129\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2473, reward 947.0, memory_length 2000, epsilon 0.10778653111497455, time 734.0, rides 134\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 2474, reward 612.0, memory_length 2000, epsilon 0.10768952323697108, time 724.0, rides 122\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 2475, reward 810.0, memory_length 2000, epsilon 0.1075926026660578, time 725.0, rides 132\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 2476, reward 936.0, memory_length 2000, epsilon 0.10749576932365836, time 724.0, rides 129\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 2477, reward 782.0, memory_length 2000, epsilon 0.10739902313126706, time 726.0, rides 132\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2478, reward 681.0, memory_length 2000, epsilon 0.10730236401044892, time 726.0, rides 124\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 2479, reward 752.0, memory_length 2000, epsilon 0.10720579188283952, time 728.0, rides 121\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2480, reward 588.0, memory_length 2000, epsilon 0.10710930667014495, time 731.0, rides 117\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 2481, reward 466.0, memory_length 2000, epsilon 0.10701290829414183, time 735.0, rides 126\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 2482, reward 747.0, memory_length 2000, epsilon 0.10691659667667709, time 720.0, rides 136\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 2483, reward 668.0, memory_length 2000, epsilon 0.10682037173966809, time 723.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2484, reward 748.0, memory_length 2000, epsilon 0.10672423340510238, time 724.0, rides 135\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 2485, reward 1023.0, memory_length 2000, epsilon 0.10662818159503779, time 726.0, rides 141\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 2486, reward 679.0, memory_length 2000, epsilon 0.10653221623160225, time 730.0, rides 139\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 2487, reward 885.0, memory_length 2000, epsilon 0.1064363372369938, time 727.0, rides 137\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 2488, reward 641.0, memory_length 2000, epsilon 0.1063405445334805, time 736.0, rides 132\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 2489, reward 753.0, memory_length 2000, epsilon 0.10624483804340037, time 733.0, rides 127\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2490, reward 618.0, memory_length 2000, epsilon 0.10614921768916132, time 731.0, rides 124\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 2491, reward 507.0, memory_length 2000, epsilon 0.10605368339324107, time 728.0, rides 132\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 2492, reward 303.0, memory_length 2000, epsilon 0.10595823507818716, time 727.0, rides 135\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 2493, reward 802.0, memory_length 2000, epsilon 0.10586287266661679, time 725.0, rides 137\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 2494, reward 1010.0, memory_length 2000, epsilon 0.10576759608121683, time 726.0, rides 138\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 2495, reward 909.0, memory_length 2000, epsilon 0.10567240524474374, time 724.0, rides 139\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 2496, reward 702.0, memory_length 2000, epsilon 0.10557730008002346, time 727.0, rides 128\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 2497, reward 1244.0, memory_length 2000, epsilon 0.10548228050995144, time 735.0, rides 134\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 2498, reward 977.0, memory_length 2000, epsilon 0.10538734645749248, time 727.0, rides 132\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 2499, reward 1029.0, memory_length 2000, epsilon 0.10529249784568073, time 724.0, rides 112\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 2500, reward 803.0, memory_length 2000, epsilon 0.10519773459761962, time 726.0, rides 133\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 2501, reward 747.0, memory_length 2000, epsilon 0.10510305663648176, time 723.0, rides 126\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 2502, reward 685.0, memory_length 2000, epsilon 0.10500846388550893, time 727.0, rides 133\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 2503, reward 519.0, memory_length 2000, epsilon 0.10491395626801196, time 742.0, rides 141\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 2504, reward 664.0, memory_length 2000, epsilon 0.10481953370737075, time 724.0, rides 142\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 2505, reward 910.0, memory_length 2000, epsilon 0.10472519612703411, time 723.0, rides 129\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 2506, reward 708.0, memory_length 2000, epsilon 0.10463094345051978, time 727.0, rides 129\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 2507, reward 858.0, memory_length 2000, epsilon 0.1045367756014143, time 723.0, rides 128\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 2508, reward 716.0, memory_length 2000, epsilon 0.10444269250337303, time 725.0, rides 148\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 2509, reward 842.0, memory_length 2000, epsilon 0.10434869408011999, time 736.0, rides 126\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 2510, reward 770.0, memory_length 2000, epsilon 0.10425478025544788, time 730.0, rides 129\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 2511, reward 756.0, memory_length 2000, epsilon 0.10416095095321798, time 730.0, rides 138\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 2512, reward 652.0, memory_length 2000, epsilon 0.10406720609736009, time 724.0, rides 120\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 2513, reward 967.0, memory_length 2000, epsilon 0.10397354561187246, time 735.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 2514, reward 814.0, memory_length 2000, epsilon 0.10387996942082177, time 728.0, rides 121\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 2515, reward 452.0, memory_length 2000, epsilon 0.10378647744834303, time 733.0, rides 121\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 2516, reward 679.0, memory_length 2000, epsilon 0.10369306961863953, time 732.0, rides 139\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 2517, reward 752.0, memory_length 2000, epsilon 0.10359974585598275, time 739.0, rides 126\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 2518, reward 443.0, memory_length 2000, epsilon 0.10350650608471236, time 731.0, rides 124\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2519, reward 745.0, memory_length 2000, epsilon 0.10341335022923612, time 728.0, rides 121\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 2520, reward 646.0, memory_length 2000, epsilon 0.10332027821402981, time 728.0, rides 131\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 2521, reward 882.0, memory_length 2000, epsilon 0.10322728996363718, time 725.0, rides 122\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 2522, reward 701.0, memory_length 2000, epsilon 0.1031343854026699, time 725.0, rides 136\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2523, reward 867.0, memory_length 2000, epsilon 0.1030415644558075, time 727.0, rides 118\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 2524, reward 753.0, memory_length 2000, epsilon 0.10294882704779727, time 725.0, rides 127\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2525, reward 658.0, memory_length 2000, epsilon 0.10285617310345425, time 731.0, rides 135\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 2526, reward 644.0, memory_length 2000, epsilon 0.10276360254766115, time 736.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 2527, reward 742.0, memory_length 2000, epsilon 0.10267111530536825, time 727.0, rides 130\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 2528, reward 750.0, memory_length 2000, epsilon 0.10257871130159342, time 730.0, rides 119\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 2529, reward 672.0, memory_length 2000, epsilon 0.10248639046142198, time 730.0, rides 123\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 2530, reward 693.0, memory_length 2000, epsilon 0.1023941527100067, time 724.0, rides 121\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2531, reward 699.0, memory_length 2000, epsilon 0.10230199797256768, time 726.0, rides 136\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 2532, reward 440.0, memory_length 2000, epsilon 0.10220992617439237, time 737.0, rides 121\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 2533, reward 1006.0, memory_length 2000, epsilon 0.10211793724083541, time 726.0, rides 141\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 2534, reward 843.0, memory_length 2000, epsilon 0.10202603109731866, time 726.0, rides 143\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 2535, reward 951.0, memory_length 2000, epsilon 0.10193420766933106, time 732.0, rides 137\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 2536, reward 476.0, memory_length 2000, epsilon 0.10184246688242866, time 730.0, rides 133\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2537, reward 979.0, memory_length 2000, epsilon 0.10175080866223447, time 736.0, rides 133\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 2538, reward 630.0, memory_length 2000, epsilon 0.10165923293443846, time 725.0, rides 142\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 2539, reward 1053.0, memory_length 2000, epsilon 0.10156773962479747, time 723.0, rides 136\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2540, reward 530.0, memory_length 2000, epsilon 0.10147632865913515, time 737.0, rides 131\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 2541, reward 817.0, memory_length 2000, epsilon 0.10138499996334194, time 737.0, rides 143\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 2542, reward 724.0, memory_length 2000, epsilon 0.10129375346337492, time 730.0, rides 137\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 2543, reward 876.0, memory_length 2000, epsilon 0.10120258908525788, time 726.0, rides 138\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 2544, reward 619.0, memory_length 2000, epsilon 0.10111150675508114, time 735.0, rides 132\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 2545, reward 861.0, memory_length 2000, epsilon 0.10102050639900156, time 728.0, rides 123\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 2546, reward 430.0, memory_length 2000, epsilon 0.10092958794324246, time 723.0, rides 130\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 2547, reward 862.0, memory_length 2000, epsilon 0.10083875131409353, time 725.0, rides 131\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2548, reward 823.0, memory_length 2000, epsilon 0.10074799643791085, time 734.0, rides 127\n",
      "Initial State is  [1, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2549, reward 1188.0, memory_length 2000, epsilon 0.10065732324111673, time 732.0, rides 154\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 2550, reward 928.0, memory_length 2000, epsilon 0.10056673165019972, time 724.0, rides 134\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 2551, reward 933.0, memory_length 2000, epsilon 0.10047622159171454, time 733.0, rides 139\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 2552, reward 994.0, memory_length 2000, epsilon 0.100385792992282, time 729.0, rides 138\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 2553, reward 1009.0, memory_length 2000, epsilon 0.10029544577858894, time 728.0, rides 136\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 2554, reward 930.0, memory_length 2000, epsilon 0.10020517987738821, time 722.0, rides 136\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 2555, reward 802.0, memory_length 2000, epsilon 0.10011499521549856, time 722.0, rides 141\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 2556, reward 1087.0, memory_length 2000, epsilon 0.10002489171980461, time 729.0, rides 128\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 2557, reward 456.0, memory_length 2000, epsilon 0.09993486931725679, time 727.0, rides 123\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 2558, reward 547.0, memory_length 2000, epsilon 0.09984492793487125, time 732.0, rides 138\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2559, reward 1125.0, memory_length 2000, epsilon 0.09975506749972987, time 725.0, rides 126\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 2560, reward 734.0, memory_length 2000, epsilon 0.09966528793898011, time 728.0, rides 118\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 2561, reward 732.0, memory_length 2000, epsilon 0.09957558917983503, time 727.0, rides 124\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 2562, reward 873.0, memory_length 2000, epsilon 0.09948597114957318, time 734.0, rides 127\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2563, reward 714.0, memory_length 2000, epsilon 0.09939643377553856, time 734.0, rides 140\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 2564, reward 530.0, memory_length 2000, epsilon 0.09930697698514057, time 734.0, rides 132\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 2565, reward 848.0, memory_length 2000, epsilon 0.09921760070585395, time 726.0, rides 136\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 2566, reward 425.0, memory_length 2000, epsilon 0.09912830486521867, time 725.0, rides 137\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 2567, reward 624.0, memory_length 2000, epsilon 0.09903908939083998, time 735.0, rides 134\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 2568, reward 637.0, memory_length 2000, epsilon 0.09894995421038823, time 728.0, rides 117\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 2569, reward 820.0, memory_length 2000, epsilon 0.09886089925159888, time 732.0, rides 130\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 2570, reward 1069.0, memory_length 2000, epsilon 0.09877192444227244, time 727.0, rides 150\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2571, reward 657.0, memory_length 2000, epsilon 0.09868302971027439, time 729.0, rides 133\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 2572, reward 830.0, memory_length 2000, epsilon 0.09859421498353514, time 727.0, rides 133\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 2573, reward 376.0, memory_length 2000, epsilon 0.09850548019004995, time 724.0, rides 128\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 2574, reward 645.0, memory_length 2000, epsilon 0.09841682525787891, time 731.0, rides 126\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 2575, reward 582.0, memory_length 2000, epsilon 0.09832825011514681, time 731.0, rides 127\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 2576, reward 846.0, memory_length 2000, epsilon 0.09823975469004319, time 728.0, rides 133\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 2577, reward 972.0, memory_length 2000, epsilon 0.09815133891082214, time 727.0, rides 124\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 2578, reward 673.0, memory_length 2000, epsilon 0.0980630027058024, time 728.0, rides 120\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 2579, reward 729.0, memory_length 2000, epsilon 0.09797474600336717, time 732.0, rides 127\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 2580, reward 699.0, memory_length 2000, epsilon 0.09788656873196414, time 727.0, rides 121\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2581, reward 855.0, memory_length 2000, epsilon 0.09779847082010537, time 734.0, rides 120\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 2582, reward 709.0, memory_length 2000, epsilon 0.09771045219636727, time 726.0, rides 122\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 2583, reward 711.0, memory_length 2000, epsilon 0.09762251278939055, time 738.0, rides 137\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 2584, reward 936.0, memory_length 2000, epsilon 0.0975346525278801, time 728.0, rides 134\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 2585, reward 740.0, memory_length 2000, epsilon 0.097446871340605, time 727.0, rides 137\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 2586, reward 814.0, memory_length 2000, epsilon 0.09735916915639846, time 731.0, rides 130\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 2587, reward 815.0, memory_length 2000, epsilon 0.0972715459041577, time 730.0, rides 130\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 2588, reward 824.0, memory_length 2000, epsilon 0.09718400151284395, time 731.0, rides 130\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 2589, reward 394.0, memory_length 2000, epsilon 0.09709653591148239, time 723.0, rides 129\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 2590, reward 780.0, memory_length 2000, epsilon 0.09700914902916205, time 730.0, rides 124\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2591, reward 839.0, memory_length 2000, epsilon 0.09692184079503581, time 733.0, rides 127\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 2592, reward 853.0, memory_length 2000, epsilon 0.09683461113832027, time 724.0, rides 136\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 2593, reward 1072.0, memory_length 2000, epsilon 0.09674745998829579, time 728.0, rides 127\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 2594, reward 911.0, memory_length 2000, epsilon 0.09666038727430631, time 738.0, rides 131\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2595, reward 887.0, memory_length 2000, epsilon 0.09657339292575944, time 722.0, rides 130\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 2596, reward 724.0, memory_length 2000, epsilon 0.09648647687212625, time 737.0, rides 128\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 2597, reward 587.0, memory_length 2000, epsilon 0.09639963904294133, time 726.0, rides 131\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 2598, reward 604.0, memory_length 2000, epsilon 0.09631287936780268, time 729.0, rides 132\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 2599, reward 711.0, memory_length 2000, epsilon 0.09622619777637166, time 729.0, rides 132\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 2600, reward 1015.0, memory_length 2000, epsilon 0.09613959419837292, time 721.0, rides 131\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 2601, reward 804.0, memory_length 2000, epsilon 0.09605306856359438, time 727.0, rides 125\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 2602, reward 1124.0, memory_length 2000, epsilon 0.09596662080188714, time 723.0, rides 137\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 2603, reward 436.0, memory_length 2000, epsilon 0.09588025084316544, time 724.0, rides 131\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 2604, reward 743.0, memory_length 2000, epsilon 0.0957939586174066, time 732.0, rides 135\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 2605, reward 784.0, memory_length 2000, epsilon 0.09570774405465093, time 722.0, rides 143\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 2606, reward 923.0, memory_length 2000, epsilon 0.09562160708500175, time 735.0, rides 146\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 2607, reward 794.0, memory_length 2000, epsilon 0.09553554763862525, time 732.0, rides 144\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 2608, reward 898.0, memory_length 2000, epsilon 0.09544956564575048, time 729.0, rides 135\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 2609, reward 662.0, memory_length 2000, epsilon 0.09536366103666931, time 731.0, rides 133\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 2610, reward 837.0, memory_length 2000, epsilon 0.0952778337417363, time 737.0, rides 157\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 2611, reward 852.0, memory_length 2000, epsilon 0.09519208369136874, time 727.0, rides 124\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 2612, reward 800.0, memory_length 2000, epsilon 0.09510641081604651, time 734.0, rides 134\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 2613, reward 1089.0, memory_length 2000, epsilon 0.09502081504631207, time 735.0, rides 135\n",
      "Initial State is  [2, 16, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2614, reward 796.0, memory_length 2000, epsilon 0.0949352963127704, time 727.0, rides 135\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 2615, reward 1030.0, memory_length 2000, epsilon 0.09484985454608891, time 732.0, rides 139\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 2616, reward 866.0, memory_length 2000, epsilon 0.09476448967699742, time 731.0, rides 147\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 2617, reward 567.0, memory_length 2000, epsilon 0.09467920163628812, time 732.0, rides 146\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2618, reward 1104.0, memory_length 2000, epsilon 0.09459399035481546, time 732.0, rides 143\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 2619, reward 760.0, memory_length 2000, epsilon 0.09450885576349612, time 730.0, rides 132\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 2620, reward 855.0, memory_length 2000, epsilon 0.09442379779330896, time 731.0, rides 145\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 2621, reward 576.0, memory_length 2000, epsilon 0.09433881637529498, time 726.0, rides 136\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 2622, reward 964.0, memory_length 2000, epsilon 0.09425391144055721, time 726.0, rides 138\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2623, reward 806.0, memory_length 2000, epsilon 0.0941690829202607, time 731.0, rides 132\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 2624, reward 625.0, memory_length 2000, epsilon 0.09408433074563247, time 724.0, rides 131\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 2625, reward 742.0, memory_length 2000, epsilon 0.0939996548479614, time 739.0, rides 131\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 2626, reward 722.0, memory_length 2000, epsilon 0.09391505515859823, time 729.0, rides 130\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 2627, reward 661.0, memory_length 2000, epsilon 0.09383053160895549, time 733.0, rides 125\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 2628, reward 688.0, memory_length 2000, epsilon 0.09374608413050743, time 724.0, rides 131\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 2629, reward 912.0, memory_length 2000, epsilon 0.09366171265478998, time 737.0, rides 144\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 2630, reward 876.0, memory_length 2000, epsilon 0.09357741711340067, time 726.0, rides 130\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 2631, reward 586.0, memory_length 2000, epsilon 0.09349319743799861, time 723.0, rides 136\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 2632, reward 581.0, memory_length 2000, epsilon 0.0934090535603044, time 730.0, rides 135\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 2633, reward 805.0, memory_length 2000, epsilon 0.09332498541210013, time 726.0, rides 135\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 2634, reward 441.0, memory_length 2000, epsilon 0.09324099292522924, time 723.0, rides 141\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 2635, reward 856.0, memory_length 2000, epsilon 0.09315707603159652, time 727.0, rides 142\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 2636, reward 761.0, memory_length 2000, epsilon 0.09307323466316808, time 728.0, rides 145\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 2637, reward 991.0, memory_length 2000, epsilon 0.09298946875197123, time 722.0, rides 142\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2638, reward 651.0, memory_length 2000, epsilon 0.09290577823009445, time 737.0, rides 121\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 2639, reward 649.0, memory_length 2000, epsilon 0.09282216302968736, time 725.0, rides 128\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2640, reward 879.0, memory_length 2000, epsilon 0.09273862308296064, time 731.0, rides 129\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 2641, reward 447.0, memory_length 2000, epsilon 0.09265515832218597, time 728.0, rides 120\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 2642, reward 572.0, memory_length 2000, epsilon 0.092571768679696, time 728.0, rides 120\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 2643, reward 592.0, memory_length 2000, epsilon 0.09248845408788428, time 728.0, rides 120\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 2644, reward 873.0, memory_length 2000, epsilon 0.09240521447920519, time 724.0, rides 120\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2645, reward 812.0, memory_length 2000, epsilon 0.09232204978617391, time 730.0, rides 130\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2646, reward 666.0, memory_length 2000, epsilon 0.09223895994136636, time 725.0, rides 123\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 2647, reward 793.0, memory_length 2000, epsilon 0.09215594487741913, time 729.0, rides 130\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 2648, reward 809.0, memory_length 2000, epsilon 0.09207300452702945, time 732.0, rides 131\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 2649, reward 739.0, memory_length 2000, epsilon 0.09199013882295512, time 720.0, rides 122\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 2650, reward 750.0, memory_length 2000, epsilon 0.09190734769801447, time 734.0, rides 110\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 2651, reward 853.0, memory_length 2000, epsilon 0.09182463108508625, time 729.0, rides 121\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 2652, reward 886.0, memory_length 2000, epsilon 0.09174198891710966, time 731.0, rides 134\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 2653, reward 941.0, memory_length 2000, epsilon 0.09165942112708426, time 730.0, rides 134\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 2654, reward 655.0, memory_length 2000, epsilon 0.09157692764806989, time 735.0, rides 130\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 2655, reward 551.0, memory_length 2000, epsilon 0.09149450841318663, time 725.0, rides 138\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 2656, reward 976.0, memory_length 2000, epsilon 0.09141216335561475, time 729.0, rides 139\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 2657, reward 744.0, memory_length 2000, epsilon 0.0913298924085947, time 725.0, rides 127\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 2658, reward 959.0, memory_length 2000, epsilon 0.09124769550542695, time 727.0, rides 126\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 2659, reward 730.0, memory_length 2000, epsilon 0.09116557257947207, time 725.0, rides 127\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2660, reward 672.0, memory_length 2000, epsilon 0.09108352356415055, time 727.0, rides 123\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 2661, reward 1122.0, memory_length 2000, epsilon 0.0910015483929428, time 731.0, rides 135\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 2662, reward 576.0, memory_length 2000, epsilon 0.09091964699938916, time 736.0, rides 131\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 2663, reward 841.0, memory_length 2000, epsilon 0.09083781931708972, time 725.0, rides 135\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 2664, reward 612.0, memory_length 2000, epsilon 0.09075606527970434, time 729.0, rides 142\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 2665, reward 1081.0, memory_length 2000, epsilon 0.09067438482095261, time 732.0, rides 135\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2666, reward 952.0, memory_length 2000, epsilon 0.09059277787461376, time 734.0, rides 132\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 2667, reward 647.0, memory_length 2000, epsilon 0.09051124437452661, time 730.0, rides 130\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 2668, reward 1007.0, memory_length 2000, epsilon 0.09042978425458953, time 733.0, rides 123\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 2669, reward 839.0, memory_length 2000, epsilon 0.0903483974487604, time 723.0, rides 137\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 2670, reward 736.0, memory_length 2000, epsilon 0.09026708389105652, time 727.0, rides 129\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 2671, reward 612.0, memory_length 2000, epsilon 0.09018584351555457, time 724.0, rides 130\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 2672, reward 1090.0, memory_length 2000, epsilon 0.09010467625639057, time 730.0, rides 128\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 2673, reward 665.0, memory_length 2000, epsilon 0.09002358204775981, time 725.0, rides 137\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 2674, reward 760.0, memory_length 2000, epsilon 0.08994256082391683, time 726.0, rides 121\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 2675, reward 751.0, memory_length 2000, epsilon 0.08986161251917531, time 729.0, rides 127\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 2676, reward 857.0, memory_length 2000, epsilon 0.08978073706790805, time 725.0, rides 125\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 2677, reward 1148.0, memory_length 2000, epsilon 0.08969993440454693, time 730.0, rides 127\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 2678, reward 941.0, memory_length 2000, epsilon 0.08961920446358283, time 730.0, rides 123\n",
      "Initial State is  [3, 16, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2679, reward 570.0, memory_length 2000, epsilon 0.08953854717956561, time 724.0, rides 135\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2680, reward 707.0, memory_length 2000, epsilon 0.089457962487104, time 728.0, rides 132\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 2681, reward 407.0, memory_length 2000, epsilon 0.08937745032086561, time 723.0, rides 125\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 2682, reward 1322.0, memory_length 2000, epsilon 0.08929701061557684, time 727.0, rides 132\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 2683, reward 827.0, memory_length 2000, epsilon 0.08921664330602282, time 724.0, rides 121\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 2684, reward 672.0, memory_length 2000, epsilon 0.0891363483270474, time 721.0, rides 124\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 2685, reward 1139.0, memory_length 2000, epsilon 0.08905612561355306, time 730.0, rides 132\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 2686, reward 429.0, memory_length 2000, epsilon 0.08897597510050086, time 723.0, rides 107\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 2687, reward 756.0, memory_length 2000, epsilon 0.0888958967229104, time 722.0, rides 116\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 2688, reward 807.0, memory_length 2000, epsilon 0.08881589041585979, time 727.0, rides 140\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 2689, reward 420.0, memory_length 2000, epsilon 0.08873595611448551, time 728.0, rides 124\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 2690, reward 612.0, memory_length 2000, epsilon 0.08865609375398247, time 731.0, rides 123\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 2691, reward 559.0, memory_length 2000, epsilon 0.08857630326960388, time 724.0, rides 111\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2692, reward 504.0, memory_length 2000, epsilon 0.08849658459666124, time 734.0, rides 128\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 2693, reward 651.0, memory_length 2000, epsilon 0.08841693767052423, time 729.0, rides 132\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 2694, reward 594.0, memory_length 2000, epsilon 0.08833736242662076, time 728.0, rides 141\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 2695, reward 755.0, memory_length 2000, epsilon 0.0882578588004368, time 728.0, rides 143\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 2696, reward 758.0, memory_length 2000, epsilon 0.0881784267275164, time 738.0, rides 132\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2697, reward 714.0, memory_length 2000, epsilon 0.08809906614346164, time 723.0, rides 127\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 2698, reward 815.0, memory_length 2000, epsilon 0.08801977698393251, time 725.0, rides 130\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 2699, reward 757.0, memory_length 2000, epsilon 0.08794055918464697, time 727.0, rides 146\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 2700, reward 645.0, memory_length 2000, epsilon 0.08786141268138078, time 736.0, rides 125\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 2701, reward 564.0, memory_length 2000, epsilon 0.08778233740996755, time 731.0, rides 130\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2702, reward 766.0, memory_length 2000, epsilon 0.08770333330629858, time 733.0, rides 140\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 2703, reward 905.0, memory_length 2000, epsilon 0.0876244003063229, time 727.0, rides 135\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 2704, reward 604.0, memory_length 2000, epsilon 0.08754553834604721, time 733.0, rides 137\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 2705, reward 870.0, memory_length 2000, epsilon 0.08746674736153577, time 731.0, rides 130\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 2706, reward 585.0, memory_length 2000, epsilon 0.08738802728891039, time 733.0, rides 136\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 2707, reward 798.0, memory_length 2000, epsilon 0.08730937806435037, time 727.0, rides 127\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 2708, reward 891.0, memory_length 2000, epsilon 0.08723079962409244, time 730.0, rides 132\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 2709, reward 733.0, memory_length 2000, epsilon 0.08715229190443076, time 723.0, rides 140\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 2710, reward 785.0, memory_length 2000, epsilon 0.08707385484171677, time 727.0, rides 129\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 2711, reward 991.0, memory_length 2000, epsilon 0.08699548837235922, time 734.0, rides 137\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 2712, reward 929.0, memory_length 2000, epsilon 0.0869171924328241, time 728.0, rides 139\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 2713, reward 834.0, memory_length 2000, epsilon 0.08683896695963456, time 731.0, rides 133\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 2714, reward 694.0, memory_length 2000, epsilon 0.08676081188937089, time 725.0, rides 137\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 2715, reward 799.0, memory_length 2000, epsilon 0.08668272715867045, time 729.0, rides 148\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 2716, reward 744.0, memory_length 2000, epsilon 0.08660471270422765, time 731.0, rides 131\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 2717, reward 1121.0, memory_length 2000, epsilon 0.08652676846279385, time 733.0, rides 126\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 2718, reward 1048.0, memory_length 2000, epsilon 0.08644889437117734, time 728.0, rides 126\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 2719, reward 484.0, memory_length 2000, epsilon 0.08637109036624328, time 730.0, rides 126\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 2720, reward 914.0, memory_length 2000, epsilon 0.08629335638491366, time 725.0, rides 118\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 2721, reward 878.0, memory_length 2000, epsilon 0.08621569236416723, time 734.0, rides 139\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 2722, reward 812.0, memory_length 2000, epsilon 0.08613809824103948, time 723.0, rides 137\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 2723, reward 554.0, memory_length 2000, epsilon 0.08606057395262254, time 728.0, rides 126\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 2724, reward 694.0, memory_length 2000, epsilon 0.08598311943606518, time 722.0, rides 130\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 2725, reward 655.0, memory_length 2000, epsilon 0.08590573462857272, time 725.0, rides 137\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 2726, reward 646.0, memory_length 2000, epsilon 0.085828419467407, time 731.0, rides 131\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 2727, reward 876.0, memory_length 2000, epsilon 0.08575117388988633, time 732.0, rides 138\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2728, reward 1234.0, memory_length 2000, epsilon 0.08567399783338543, time 735.0, rides 129\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 2729, reward 819.0, memory_length 2000, epsilon 0.08559689123533538, time 735.0, rides 138\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 2730, reward 1063.0, memory_length 2000, epsilon 0.08551985403322358, time 730.0, rides 128\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 2731, reward 751.0, memory_length 2000, epsilon 0.08544288616459368, time 729.0, rides 131\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 2732, reward 800.0, memory_length 2000, epsilon 0.08536598756704554, time 726.0, rides 126\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 2733, reward 927.0, memory_length 2000, epsilon 0.0852891581782352, time 726.0, rides 122\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 2734, reward 519.0, memory_length 2000, epsilon 0.08521239793587478, time 736.0, rides 122\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 2735, reward 738.0, memory_length 2000, epsilon 0.08513570677773248, time 737.0, rides 139\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2736, reward 726.0, memory_length 2000, epsilon 0.08505908464163252, time 724.0, rides 139\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 2737, reward 675.0, memory_length 2000, epsilon 0.08498253146545505, time 724.0, rides 120\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 2738, reward 815.0, memory_length 2000, epsilon 0.08490604718713614, time 723.0, rides 131\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 2739, reward 890.0, memory_length 2000, epsilon 0.08482963174466772, time 727.0, rides 126\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 2740, reward 832.0, memory_length 2000, epsilon 0.08475328507609751, time 738.0, rides 124\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2741, reward 789.0, memory_length 2000, epsilon 0.08467700711952902, time 736.0, rides 126\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 2742, reward 622.0, memory_length 2000, epsilon 0.08460079781312145, time 739.0, rides 126\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 2743, reward 792.0, memory_length 2000, epsilon 0.08452465709508963, time 729.0, rides 128\n",
      "Initial State is  [2, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2744, reward 595.0, memory_length 2000, epsilon 0.08444858490370405, time 729.0, rides 120\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 2745, reward 723.0, memory_length 2000, epsilon 0.08437258117729071, time 725.0, rides 147\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 2746, reward 708.0, memory_length 2000, epsilon 0.08429664585423115, time 727.0, rides 132\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 2747, reward 830.0, memory_length 2000, epsilon 0.08422077887296234, time 725.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 2748, reward 848.0, memory_length 2000, epsilon 0.08414498017197668, time 730.0, rides 136\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 2749, reward 739.0, memory_length 2000, epsilon 0.08406924968982189, time 722.0, rides 134\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 2750, reward 802.0, memory_length 2000, epsilon 0.08399358736510106, time 747.0, rides 137\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 2751, reward 599.0, memory_length 2000, epsilon 0.08391799313647247, time 728.0, rides 115\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 2752, reward 819.0, memory_length 2000, epsilon 0.08384246694264964, time 721.0, rides 126\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 2753, reward 671.0, memory_length 2000, epsilon 0.08376700872240125, time 726.0, rides 134\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 2754, reward 856.0, memory_length 2000, epsilon 0.0836916184145511, time 726.0, rides 117\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 2755, reward 578.0, memory_length 2000, epsilon 0.083616295957978, time 728.0, rides 130\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 2756, reward 941.0, memory_length 2000, epsilon 0.08354104129161581, time 732.0, rides 126\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 2757, reward 743.0, memory_length 2000, epsilon 0.08346585435445336, time 728.0, rides 135\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 2758, reward 759.0, memory_length 2000, epsilon 0.08339073508553435, time 739.0, rides 126\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 2759, reward 947.0, memory_length 2000, epsilon 0.08331568342395737, time 724.0, rides 130\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 2760, reward 885.0, memory_length 2000, epsilon 0.0832406993088758, time 730.0, rides 147\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 2761, reward 905.0, memory_length 2000, epsilon 0.08316578267949781, time 725.0, rides 142\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 2762, reward 905.0, memory_length 2000, epsilon 0.08309093347508627, time 728.0, rides 135\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 2763, reward 1014.0, memory_length 2000, epsilon 0.0830161516349587, time 735.0, rides 126\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 2764, reward 523.0, memory_length 2000, epsilon 0.08294143709848723, time 726.0, rides 117\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 2765, reward 827.0, memory_length 2000, epsilon 0.08286678980509858, time 733.0, rides 126\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 2766, reward 845.0, memory_length 2000, epsilon 0.08279220969427399, time 726.0, rides 129\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 2767, reward 1148.0, memory_length 2000, epsilon 0.08271769670554914, time 735.0, rides 141\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 2768, reward 613.0, memory_length 2000, epsilon 0.08264325077851414, time 730.0, rides 128\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 2769, reward 1085.0, memory_length 2000, epsilon 0.08256887185281347, time 734.0, rides 117\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 2770, reward 901.0, memory_length 2000, epsilon 0.08249455986814594, time 736.0, rides 131\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 2771, reward 859.0, memory_length 2000, epsilon 0.0824203147642646, time 727.0, rides 129\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 2772, reward 678.0, memory_length 2000, epsilon 0.08234613648097676, time 730.0, rides 125\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 2773, reward 983.0, memory_length 2000, epsilon 0.08227202495814388, time 724.0, rides 139\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 2774, reward 718.0, memory_length 2000, epsilon 0.08219798013568155, time 732.0, rides 133\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 2775, reward 490.0, memory_length 2000, epsilon 0.08212400195355944, time 726.0, rides 137\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2776, reward 678.0, memory_length 2000, epsilon 0.08205009035180123, time 724.0, rides 128\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2777, reward 805.0, memory_length 2000, epsilon 0.08197624527048461, time 724.0, rides 131\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 2778, reward 767.0, memory_length 2000, epsilon 0.08190246664974117, time 726.0, rides 139\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 2779, reward 350.0, memory_length 2000, epsilon 0.0818287544297564, time 726.0, rides 124\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 2780, reward 728.0, memory_length 2000, epsilon 0.08175510855076962, time 730.0, rides 117\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 2781, reward 599.0, memory_length 2000, epsilon 0.08168152895307393, time 727.0, rides 128\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 2782, reward 777.0, memory_length 2000, epsilon 0.08160801557701616, time 734.0, rides 132\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 2783, reward 911.0, memory_length 2000, epsilon 0.08153456836299684, time 727.0, rides 144\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 2784, reward 601.0, memory_length 2000, epsilon 0.08146118725147014, time 738.0, rides 124\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 2785, reward 870.0, memory_length 2000, epsilon 0.08138787218294381, time 731.0, rides 136\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 2786, reward 1020.0, memory_length 2000, epsilon 0.08131462309797917, time 731.0, rides 138\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 2787, reward 678.0, memory_length 2000, epsilon 0.08124143993719099, time 734.0, rides 139\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 2788, reward 828.0, memory_length 2000, epsilon 0.08116832264124751, time 722.0, rides 133\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 2789, reward 687.0, memory_length 2000, epsilon 0.0810952711508704, time 728.0, rides 127\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 2790, reward 682.0, memory_length 2000, epsilon 0.08102228540683461, time 721.0, rides 124\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 2791, reward 713.0, memory_length 2000, epsilon 0.08094936534996845, time 725.0, rides 143\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 2792, reward 994.0, memory_length 2000, epsilon 0.08087651092115349, time 725.0, rides 127\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 2793, reward 952.0, memory_length 2000, epsilon 0.08080372206132444, time 724.0, rides 134\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 2794, reward 568.0, memory_length 2000, epsilon 0.08073099871146924, time 729.0, rides 127\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 2795, reward 936.0, memory_length 2000, epsilon 0.08065834081262892, time 726.0, rides 130\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 2796, reward 817.0, memory_length 2000, epsilon 0.08058574830589756, time 733.0, rides 126\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 2797, reward 780.0, memory_length 2000, epsilon 0.08051322113242225, time 730.0, rides 131\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 2798, reward 982.0, memory_length 2000, epsilon 0.08044075923340308, time 723.0, rides 131\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 2799, reward 965.0, memory_length 2000, epsilon 0.08036836255009301, time 736.0, rides 128\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 2800, reward 595.0, memory_length 2000, epsilon 0.08029603102379793, time 730.0, rides 120\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 2801, reward 713.0, memory_length 2000, epsilon 0.0802237645958765, time 726.0, rides 139\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 2802, reward 764.0, memory_length 2000, epsilon 0.08015156320774021, time 730.0, rides 127\n",
      "Initial State is  [4, 18, 5]\n",
      "episode 2803, reward 637.0, memory_length 2000, epsilon 0.08007942680085324, time 732.0, rides 142\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 2804, reward 776.0, memory_length 2000, epsilon 0.08000735531673248, time 726.0, rides 139\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 2805, reward 820.0, memory_length 2000, epsilon 0.07993534869694742, time 727.0, rides 130\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2806, reward 762.0, memory_length 2000, epsilon 0.07986340688312017, time 728.0, rides 120\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 2807, reward 1216.0, memory_length 2000, epsilon 0.07979152981692536, time 734.0, rides 146\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 2808, reward 627.0, memory_length 2000, epsilon 0.07971971744009013, time 727.0, rides 116\n",
      "Initial State is  [2, 21, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2809, reward 730.0, memory_length 2000, epsilon 0.07964796969439404, time 735.0, rides 128\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 2810, reward 997.0, memory_length 2000, epsilon 0.07957628652166908, time 728.0, rides 131\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 2811, reward 666.0, memory_length 2000, epsilon 0.07950466786379957, time 732.0, rides 129\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 2812, reward 657.0, memory_length 2000, epsilon 0.07943311366272215, time 724.0, rides 119\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 2813, reward 931.0, memory_length 2000, epsilon 0.07936162386042571, time 734.0, rides 126\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 2814, reward 661.0, memory_length 2000, epsilon 0.07929019839895132, time 733.0, rides 127\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 2815, reward 856.0, memory_length 2000, epsilon 0.07921883722039226, time 730.0, rides 134\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 2816, reward 860.0, memory_length 2000, epsilon 0.07914754026689391, time 725.0, rides 132\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 2817, reward 618.0, memory_length 2000, epsilon 0.07907630748065371, time 737.0, rides 124\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 2818, reward 773.0, memory_length 2000, epsilon 0.07900513880392113, time 738.0, rides 141\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 2819, reward 666.0, memory_length 2000, epsilon 0.0789340341789976, time 724.0, rides 135\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 2820, reward 460.0, memory_length 2000, epsilon 0.07886299354823649, time 727.0, rides 118\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 2821, reward 518.0, memory_length 2000, epsilon 0.07879201685404308, time 733.0, rides 135\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 2822, reward 901.0, memory_length 2000, epsilon 0.07872110403887445, time 723.0, rides 137\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 2823, reward 790.0, memory_length 2000, epsilon 0.07865025504523945, time 740.0, rides 135\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 2824, reward 718.0, memory_length 2000, epsilon 0.07857946981569874, time 731.0, rides 131\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 2825, reward 792.0, memory_length 2000, epsilon 0.07850874829286461, time 723.0, rides 121\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 2826, reward 774.0, memory_length 2000, epsilon 0.07843809041940103, time 735.0, rides 132\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2827, reward 809.0, memory_length 2000, epsilon 0.07836749613802357, time 727.0, rides 120\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 2828, reward 841.0, memory_length 2000, epsilon 0.07829696539149936, time 730.0, rides 134\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 2829, reward 858.0, memory_length 2000, epsilon 0.07822649812264701, time 734.0, rides 131\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 2830, reward 840.0, memory_length 2000, epsilon 0.07815609427433663, time 734.0, rides 130\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 2831, reward 900.0, memory_length 2000, epsilon 0.07808575378948973, time 725.0, rides 126\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 2832, reward 1026.0, memory_length 2000, epsilon 0.07801547661107919, time 729.0, rides 138\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 2833, reward 944.0, memory_length 2000, epsilon 0.07794526268212922, time 730.0, rides 141\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 2834, reward 1104.0, memory_length 2000, epsilon 0.0778751119457153, time 733.0, rides 127\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 2835, reward 789.0, memory_length 2000, epsilon 0.07780502434496415, time 731.0, rides 129\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 2836, reward 564.0, memory_length 2000, epsilon 0.07773499982305368, time 732.0, rides 128\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 2837, reward 656.0, memory_length 2000, epsilon 0.07766503832321293, time 730.0, rides 130\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 2838, reward 669.0, memory_length 2000, epsilon 0.07759513978872204, time 725.0, rides 131\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 2839, reward 836.0, memory_length 2000, epsilon 0.07752530416291219, time 726.0, rides 139\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 2840, reward 953.0, memory_length 2000, epsilon 0.07745553138916557, time 726.0, rides 139\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 2841, reward 652.0, memory_length 2000, epsilon 0.07738582141091532, time 736.0, rides 126\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 2842, reward 921.0, memory_length 2000, epsilon 0.0773161741716455, time 723.0, rides 133\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 2843, reward 1128.0, memory_length 2000, epsilon 0.07724658961489102, time 722.0, rides 146\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2844, reward 737.0, memory_length 2000, epsilon 0.07717706768423761, time 728.0, rides 137\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 2845, reward 547.0, memory_length 2000, epsilon 0.0771076083233218, time 732.0, rides 129\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 2846, reward 1008.0, memory_length 2000, epsilon 0.0770382114758308, time 728.0, rides 130\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 2847, reward 828.0, memory_length 2000, epsilon 0.07696887708550255, time 731.0, rides 145\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 2848, reward 925.0, memory_length 2000, epsilon 0.0768996050961256, time 734.0, rides 118\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 2849, reward 809.0, memory_length 2000, epsilon 0.0768303954515391, time 727.0, rides 121\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 2850, reward 607.0, memory_length 2000, epsilon 0.07676124809563271, time 723.0, rides 128\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 2851, reward 825.0, memory_length 2000, epsilon 0.07669216297234664, time 728.0, rides 136\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 2852, reward 949.0, memory_length 2000, epsilon 0.07662314002567153, time 728.0, rides 140\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 2853, reward 661.0, memory_length 2000, epsilon 0.07655417919964842, time 723.0, rides 131\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 2854, reward 1156.0, memory_length 2000, epsilon 0.07648528043836873, time 731.0, rides 144\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 2855, reward 658.0, memory_length 2000, epsilon 0.0764164436859742, time 727.0, rides 130\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 2856, reward 870.0, memory_length 2000, epsilon 0.07634766888665681, time 724.0, rides 133\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 2857, reward 1031.0, memory_length 2000, epsilon 0.07627895598465882, time 737.0, rides 133\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 2858, reward 1161.0, memory_length 2000, epsilon 0.07621030492427262, time 722.0, rides 145\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 2859, reward 738.0, memory_length 2000, epsilon 0.07614171564984078, time 727.0, rides 138\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 2860, reward 1219.0, memory_length 2000, epsilon 0.07607318810575592, time 735.0, rides 136\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 2861, reward 867.0, memory_length 2000, epsilon 0.07600472223646074, time 727.0, rides 139\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 2862, reward 861.0, memory_length 2000, epsilon 0.07593631798644793, time 730.0, rides 141\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 2863, reward 807.0, memory_length 2000, epsilon 0.07586797530026013, time 725.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 2864, reward 1212.0, memory_length 2000, epsilon 0.0757996941224899, time 728.0, rides 142\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 2865, reward 789.0, memory_length 2000, epsilon 0.07573147439777965, time 730.0, rides 118\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 2866, reward 862.0, memory_length 2000, epsilon 0.07566331607082165, time 726.0, rides 120\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 2867, reward 982.0, memory_length 2000, epsilon 0.07559521908635791, time 726.0, rides 138\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 2868, reward 966.0, memory_length 2000, epsilon 0.07552718338918019, time 732.0, rides 125\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 2869, reward 874.0, memory_length 2000, epsilon 0.07545920892412993, time 723.0, rides 125\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 2870, reward 704.0, memory_length 2000, epsilon 0.07539129563609821, time 722.0, rides 125\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 2871, reward 904.0, memory_length 2000, epsilon 0.07532344347002572, time 736.0, rides 128\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 2872, reward 1220.0, memory_length 2000, epsilon 0.07525565237090269, time 725.0, rides 139\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 2873, reward 869.0, memory_length 2000, epsilon 0.07518792228376887, time 725.0, rides 121\n",
      "Initial State is  [3, 9, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2874, reward 927.0, memory_length 2000, epsilon 0.07512025315371348, time 727.0, rides 131\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 2875, reward 659.0, memory_length 2000, epsilon 0.07505264492587514, time 732.0, rides 129\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 2876, reward 754.0, memory_length 2000, epsilon 0.07498509754544186, time 728.0, rides 137\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 2877, reward 896.0, memory_length 2000, epsilon 0.07491761095765095, time 726.0, rides 127\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 2878, reward 1100.0, memory_length 2000, epsilon 0.07485018510778907, time 735.0, rides 132\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 2879, reward 986.0, memory_length 2000, epsilon 0.07478281994119206, time 723.0, rides 130\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 2880, reward 935.0, memory_length 2000, epsilon 0.07471551540324498, time 724.0, rides 131\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 2881, reward 1214.0, memory_length 2000, epsilon 0.07464827143938206, time 729.0, rides 140\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 2882, reward 589.0, memory_length 2000, epsilon 0.07458108799508661, time 721.0, rides 144\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 2883, reward 911.0, memory_length 2000, epsilon 0.07451396501589104, time 728.0, rides 135\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 2884, reward 1163.0, memory_length 2000, epsilon 0.07444690244737674, time 731.0, rides 134\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 2885, reward 1060.0, memory_length 2000, epsilon 0.0743799002351741, time 731.0, rides 142\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 2886, reward 707.0, memory_length 2000, epsilon 0.07431295832496244, time 733.0, rides 126\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 2887, reward 1045.0, memory_length 2000, epsilon 0.07424607666246998, time 732.0, rides 132\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 2888, reward 833.0, memory_length 2000, epsilon 0.07417925519347375, time 734.0, rides 117\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2889, reward 721.0, memory_length 2000, epsilon 0.07411249386379962, time 733.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 2890, reward 952.0, memory_length 2000, epsilon 0.07404579261932219, time 728.0, rides 130\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 2891, reward 910.0, memory_length 2000, epsilon 0.0739791514059648, time 726.0, rides 129\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 2892, reward 1016.0, memory_length 2000, epsilon 0.07391257016969943, time 723.0, rides 122\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 2893, reward 914.0, memory_length 2000, epsilon 0.0738460488565467, time 729.0, rides 135\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 2894, reward 471.0, memory_length 2000, epsilon 0.07377958741257581, time 734.0, rides 116\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 2895, reward 846.0, memory_length 2000, epsilon 0.0737131857839045, time 733.0, rides 125\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 2896, reward 932.0, memory_length 2000, epsilon 0.07364684391669898, time 720.0, rides 117\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 2897, reward 951.0, memory_length 2000, epsilon 0.07358056175717395, time 739.0, rides 131\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 2898, reward 898.0, memory_length 2000, epsilon 0.0735143392515925, time 725.0, rides 129\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 2899, reward 576.0, memory_length 2000, epsilon 0.07344817634626606, time 727.0, rides 125\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2900, reward 1100.0, memory_length 2000, epsilon 0.07338207298755442, time 726.0, rides 130\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 2901, reward 828.0, memory_length 2000, epsilon 0.07331602912186562, time 733.0, rides 133\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 2902, reward 921.0, memory_length 2000, epsilon 0.07325004469565594, time 730.0, rides 147\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 2903, reward 860.0, memory_length 2000, epsilon 0.07318411965542984, time 730.0, rides 121\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 2904, reward 747.0, memory_length 2000, epsilon 0.07311825394773995, time 727.0, rides 134\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 2905, reward 552.0, memory_length 2000, epsilon 0.07305244751918698, time 728.0, rides 132\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 2906, reward 1026.0, memory_length 2000, epsilon 0.07298670031641971, time 729.0, rides 142\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 2907, reward 876.0, memory_length 2000, epsilon 0.07292101228613493, time 725.0, rides 122\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 2908, reward 824.0, memory_length 2000, epsilon 0.07285538337507741, time 729.0, rides 123\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 2909, reward 799.0, memory_length 2000, epsilon 0.07278981353003984, time 728.0, rides 133\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 2910, reward 880.0, memory_length 2000, epsilon 0.0727243026978628, time 728.0, rides 128\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 2911, reward 884.0, memory_length 2000, epsilon 0.07265885082543472, time 724.0, rides 130\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 2912, reward 945.0, memory_length 2000, epsilon 0.07259345785969183, time 731.0, rides 124\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 2913, reward 577.0, memory_length 2000, epsilon 0.0725281237476181, time 731.0, rides 135\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 2914, reward 864.0, memory_length 2000, epsilon 0.07246284843624524, time 722.0, rides 136\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 2915, reward 474.0, memory_length 2000, epsilon 0.07239763187265262, time 723.0, rides 139\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 2916, reward 729.0, memory_length 2000, epsilon 0.07233247400396724, time 728.0, rides 144\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 2917, reward 1013.0, memory_length 2000, epsilon 0.07226737477736367, time 729.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 2918, reward 747.0, memory_length 2000, epsilon 0.07220233414006404, time 726.0, rides 138\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 2919, reward 1011.0, memory_length 2000, epsilon 0.07213735203933798, time 738.0, rides 132\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 2920, reward 961.0, memory_length 2000, epsilon 0.07207242842250257, time 726.0, rides 135\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 2921, reward 858.0, memory_length 2000, epsilon 0.07200756323692231, time 748.0, rides 139\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 2922, reward 841.0, memory_length 2000, epsilon 0.07194275643000908, time 727.0, rides 141\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 2923, reward 829.0, memory_length 2000, epsilon 0.07187800794922207, time 724.0, rides 130\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 2924, reward 1086.0, memory_length 2000, epsilon 0.07181331774206777, time 730.0, rides 127\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 2925, reward 1035.0, memory_length 2000, epsilon 0.07174868575609991, time 733.0, rides 131\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 2926, reward 661.0, memory_length 2000, epsilon 0.07168411193891942, time 729.0, rides 127\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 2927, reward 727.0, memory_length 2000, epsilon 0.07161959623817439, time 729.0, rides 122\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 2928, reward 602.0, memory_length 2000, epsilon 0.07155513860156003, time 730.0, rides 118\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 2929, reward 660.0, memory_length 2000, epsilon 0.07149073897681862, time 722.0, rides 134\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 2930, reward 861.0, memory_length 2000, epsilon 0.07142639731173948, time 727.0, rides 129\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 2931, reward 726.0, memory_length 2000, epsilon 0.07136211355415892, time 725.0, rides 131\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 2932, reward 1149.0, memory_length 2000, epsilon 0.07129788765196017, time 728.0, rides 120\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 2933, reward 794.0, memory_length 2000, epsilon 0.07123371955307341, time 728.0, rides 121\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 2934, reward 865.0, memory_length 2000, epsilon 0.07116960920547565, time 729.0, rides 146\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 2935, reward 1060.0, memory_length 2000, epsilon 0.07110555655719071, time 728.0, rides 126\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 2936, reward 824.0, memory_length 2000, epsilon 0.07104156155628924, time 723.0, rides 117\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 2937, reward 675.0, memory_length 2000, epsilon 0.07097762415088858, time 737.0, rides 120\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 2938, reward 690.0, memory_length 2000, epsilon 0.07091374428915279, time 729.0, rides 138\n",
      "Initial State is  [3, 9, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2939, reward 811.0, memory_length 2000, epsilon 0.07084992191929254, time 737.0, rides 121\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 2940, reward 580.0, memory_length 2000, epsilon 0.07078615698956518, time 733.0, rides 130\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 2941, reward 1075.0, memory_length 2000, epsilon 0.07072244944827458, time 724.0, rides 129\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 2942, reward 722.0, memory_length 2000, epsilon 0.07065879924377112, time 724.0, rides 143\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 2943, reward 579.0, memory_length 2000, epsilon 0.07059520632445172, time 725.0, rides 127\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 2944, reward 622.0, memory_length 2000, epsilon 0.07053167063875972, time 725.0, rides 128\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 2945, reward 486.0, memory_length 2000, epsilon 0.07046819213518483, time 728.0, rides 123\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 2946, reward 1087.0, memory_length 2000, epsilon 0.07040477076226316, time 730.0, rides 134\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 2947, reward 893.0, memory_length 2000, epsilon 0.07034140646857712, time 726.0, rides 137\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 2948, reward 800.0, memory_length 2000, epsilon 0.07027809920275539, time 728.0, rides 137\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2949, reward 780.0, memory_length 2000, epsilon 0.07021484891347292, time 725.0, rides 142\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 2950, reward 478.0, memory_length 2000, epsilon 0.0701516555494508, time 729.0, rides 126\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 2951, reward 922.0, memory_length 2000, epsilon 0.07008851905945629, time 725.0, rides 126\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 2952, reward 733.0, memory_length 2000, epsilon 0.07002543939230278, time 728.0, rides 116\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 2953, reward 669.0, memory_length 2000, epsilon 0.06996241649684971, time 727.0, rides 115\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 2954, reward 828.0, memory_length 2000, epsilon 0.06989945032200255, time 721.0, rides 120\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 2955, reward 813.0, memory_length 2000, epsilon 0.06983654081671274, time 728.0, rides 129\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 2956, reward 744.0, memory_length 2000, epsilon 0.06977368792997769, time 727.0, rides 120\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 2957, reward 1026.0, memory_length 2000, epsilon 0.06971089161084071, time 733.0, rides 128\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 2958, reward 918.0, memory_length 2000, epsilon 0.06964815180839096, time 731.0, rides 127\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 2959, reward 832.0, memory_length 2000, epsilon 0.0695854684717634, time 732.0, rides 125\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 2960, reward 792.0, memory_length 2000, epsilon 0.06952284155013881, time 735.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 2961, reward 855.0, memory_length 2000, epsilon 0.06946027099274368, time 730.0, rides 121\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 2962, reward 656.0, memory_length 2000, epsilon 0.06939775674885021, time 727.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2963, reward 1125.0, memory_length 2000, epsilon 0.06933529876777625, time 727.0, rides 130\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 2964, reward 592.0, memory_length 2000, epsilon 0.06927289699888525, time 726.0, rides 135\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 2965, reward 834.0, memory_length 2000, epsilon 0.06921055139158626, time 729.0, rides 133\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 2966, reward 713.0, memory_length 2000, epsilon 0.06914826189533382, time 733.0, rides 130\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 2967, reward 819.0, memory_length 2000, epsilon 0.06908602845962802, time 726.0, rides 121\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 2968, reward 815.0, memory_length 2000, epsilon 0.06902385103401436, time 727.0, rides 133\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 2969, reward 1084.0, memory_length 2000, epsilon 0.06896172956808375, time 731.0, rides 136\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 2970, reward 912.0, memory_length 2000, epsilon 0.06889966401147248, time 733.0, rides 126\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 2971, reward 827.0, memory_length 2000, epsilon 0.06883765431386214, time 727.0, rides 158\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 2972, reward 812.0, memory_length 2000, epsilon 0.06877570042497967, time 738.0, rides 134\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 2973, reward 867.0, memory_length 2000, epsilon 0.06871380229459718, time 723.0, rides 127\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 2974, reward 965.0, memory_length 2000, epsilon 0.06865195987253205, time 726.0, rides 137\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 2975, reward 1083.0, memory_length 2000, epsilon 0.06859017310864676, time 735.0, rides 139\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 2976, reward 926.0, memory_length 2000, epsilon 0.06852844195284898, time 723.0, rides 123\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 2977, reward 890.0, memory_length 2000, epsilon 0.06846676635509141, time 734.0, rides 125\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 2978, reward 687.0, memory_length 2000, epsilon 0.06840514626537184, time 726.0, rides 142\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 2979, reward 1097.0, memory_length 2000, epsilon 0.068343581633733, time 726.0, rides 140\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 2980, reward 849.0, memory_length 2000, epsilon 0.06828207241026264, time 732.0, rides 123\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 2981, reward 784.0, memory_length 2000, epsilon 0.06822061854509341, time 724.0, rides 137\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 2982, reward 1150.0, memory_length 2000, epsilon 0.06815921998840282, time 725.0, rides 135\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 2983, reward 1109.0, memory_length 2000, epsilon 0.06809787669041326, time 729.0, rides 136\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 2984, reward 886.0, memory_length 2000, epsilon 0.06803658860139189, time 730.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 2985, reward 783.0, memory_length 2000, epsilon 0.06797535567165064, time 732.0, rides 126\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 2986, reward 1101.0, memory_length 2000, epsilon 0.06791417785154616, time 731.0, rides 129\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 2987, reward 943.0, memory_length 2000, epsilon 0.06785305509147976, time 728.0, rides 126\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 2988, reward 966.0, memory_length 2000, epsilon 0.06779198734189743, time 734.0, rides 133\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 2989, reward 837.0, memory_length 2000, epsilon 0.06773097455328972, time 724.0, rides 126\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 2990, reward 995.0, memory_length 2000, epsilon 0.06767001667619175, time 722.0, rides 135\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 2991, reward 829.0, memory_length 2000, epsilon 0.06760911366118318, time 729.0, rides 137\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 2992, reward 987.0, memory_length 2000, epsilon 0.0675482654588881, time 728.0, rides 130\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 2993, reward 893.0, memory_length 2000, epsilon 0.0674874720199751, time 728.0, rides 135\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 2994, reward 1033.0, memory_length 2000, epsilon 0.06742673329515712, time 727.0, rides 135\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 2995, reward 928.0, memory_length 2000, epsilon 0.06736604923519147, time 727.0, rides 140\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 2996, reward 976.0, memory_length 2000, epsilon 0.0673054197908798, time 725.0, rides 128\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 2997, reward 1033.0, memory_length 2000, epsilon 0.06724484491306801, time 725.0, rides 133\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 2998, reward 635.0, memory_length 2000, epsilon 0.06718432455264625, time 727.0, rides 127\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 2999, reward 711.0, memory_length 2000, epsilon 0.06712385866054887, time 722.0, rides 142\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3000, reward 802.0, memory_length 2000, epsilon 0.06706344718775438, time 734.0, rides 134\n",
      "Initial State is  [1, 15, 1]\n",
      "episode 3001, reward 984.0, memory_length 2000, epsilon 0.0670030900852854, time 722.0, rides 138\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 3002, reward 855.0, memory_length 2000, epsilon 0.06694278730420865, time 735.0, rides 131\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 3003, reward 986.0, memory_length 2000, epsilon 0.06688253879563485, time 731.0, rides 125\n",
      "Initial State is  [3, 0, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3004, reward 967.0, memory_length 2000, epsilon 0.06682234451071878, time 723.0, rides 119\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 3005, reward 1135.0, memory_length 2000, epsilon 0.06676220440065914, time 729.0, rides 134\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 3006, reward 687.0, memory_length 2000, epsilon 0.06670211841669854, time 730.0, rides 136\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 3007, reward 995.0, memory_length 2000, epsilon 0.06664208651012352, time 732.0, rides 141\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 3008, reward 936.0, memory_length 2000, epsilon 0.06658210863226441, time 734.0, rides 126\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3009, reward 920.0, memory_length 2000, epsilon 0.06652218473449537, time 730.0, rides 154\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 3010, reward 713.0, memory_length 2000, epsilon 0.06646231476823432, time 727.0, rides 129\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3011, reward 956.0, memory_length 2000, epsilon 0.06640249868494291, time 728.0, rides 124\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3012, reward 933.0, memory_length 2000, epsilon 0.06634273643612647, time 724.0, rides 137\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 3013, reward 1243.0, memory_length 2000, epsilon 0.06628302797333395, time 725.0, rides 138\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 3014, reward 1047.0, memory_length 2000, epsilon 0.06622337324815795, time 725.0, rides 134\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3015, reward 996.0, memory_length 2000, epsilon 0.06616377221223461, time 737.0, rides 129\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3016, reward 900.0, memory_length 2000, epsilon 0.06610422481724361, time 726.0, rides 126\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3017, reward 758.0, memory_length 2000, epsilon 0.06604473101490808, time 726.0, rides 138\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 3018, reward 884.0, memory_length 2000, epsilon 0.06598529075699466, time 732.0, rides 133\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 3019, reward 974.0, memory_length 2000, epsilon 0.06592590399531337, time 730.0, rides 130\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 3020, reward 910.0, memory_length 2000, epsilon 0.06586657068171758, time 729.0, rides 128\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 3021, reward 776.0, memory_length 2000, epsilon 0.06580729076810404, time 728.0, rides 145\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 3022, reward 883.0, memory_length 2000, epsilon 0.06574806420641274, time 727.0, rides 137\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 3023, reward 888.0, memory_length 2000, epsilon 0.06568889094862697, time 725.0, rides 130\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 3024, reward 977.0, memory_length 2000, epsilon 0.0656297709467732, time 725.0, rides 152\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3025, reward 807.0, memory_length 2000, epsilon 0.06557070415292111, time 723.0, rides 125\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 3026, reward 853.0, memory_length 2000, epsilon 0.06551169051918349, time 734.0, rides 140\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 3027, reward 883.0, memory_length 2000, epsilon 0.06545272999771622, time 735.0, rides 135\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3028, reward 829.0, memory_length 2000, epsilon 0.06539382254071827, time 731.0, rides 135\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 3029, reward 799.0, memory_length 2000, epsilon 0.06533496810043161, time 724.0, rides 126\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 3030, reward 1113.0, memory_length 2000, epsilon 0.06527616662914122, time 726.0, rides 121\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 3031, reward 920.0, memory_length 2000, epsilon 0.065217418079175, time 722.0, rides 134\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 3032, reward 1044.0, memory_length 2000, epsilon 0.06515872240290374, time 730.0, rides 121\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3033, reward 828.0, memory_length 2000, epsilon 0.06510007955274112, time 727.0, rides 126\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3034, reward 967.0, memory_length 2000, epsilon 0.06504148948114366, time 728.0, rides 135\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 3035, reward 650.0, memory_length 2000, epsilon 0.06498295214061063, time 732.0, rides 140\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 3036, reward 722.0, memory_length 2000, epsilon 0.06492446748368408, time 724.0, rides 134\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3037, reward 837.0, memory_length 2000, epsilon 0.06486603546294877, time 729.0, rides 146\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 3038, reward 780.0, memory_length 2000, epsilon 0.06480765603103211, time 737.0, rides 142\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 3039, reward 994.0, memory_length 2000, epsilon 0.06474932914060419, time 722.0, rides 129\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 3040, reward 1032.0, memory_length 2000, epsilon 0.06469105474437764, time 727.0, rides 133\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 3041, reward 854.0, memory_length 2000, epsilon 0.0646328327951077, time 727.0, rides 141\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 3042, reward 778.0, memory_length 2000, epsilon 0.0645746632455921, time 733.0, rides 125\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 3043, reward 1012.0, memory_length 2000, epsilon 0.06451654604867108, time 725.0, rides 130\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 3044, reward 570.0, memory_length 2000, epsilon 0.06445848115722727, time 730.0, rides 129\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 3045, reward 1290.0, memory_length 2000, epsilon 0.06440046852418577, time 731.0, rides 132\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 3046, reward 1076.0, memory_length 2000, epsilon 0.064342508102514, time 727.0, rides 133\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3047, reward 771.0, memory_length 2000, epsilon 0.06428459984522174, time 736.0, rides 143\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 3048, reward 893.0, memory_length 2000, epsilon 0.06422674370536104, time 724.0, rides 131\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 3049, reward 864.0, memory_length 2000, epsilon 0.06416893963602621, time 728.0, rides 143\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 3050, reward 1049.0, memory_length 2000, epsilon 0.0641111875903538, time 732.0, rides 142\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 3051, reward 935.0, memory_length 2000, epsilon 0.06405348752152247, time 727.0, rides 137\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3052, reward 765.0, memory_length 2000, epsilon 0.0639958393827531, time 727.0, rides 126\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 3053, reward 745.0, memory_length 2000, epsilon 0.06393824312730863, time 728.0, rides 139\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 3054, reward 837.0, memory_length 2000, epsilon 0.06388069870849405, time 728.0, rides 139\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3055, reward 821.0, memory_length 2000, epsilon 0.06382320607965641, time 724.0, rides 131\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 3056, reward 878.0, memory_length 2000, epsilon 0.06376576519418473, time 728.0, rides 146\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 3057, reward 960.0, memory_length 2000, epsilon 0.06370837600550996, time 729.0, rides 137\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 3058, reward 863.0, memory_length 2000, epsilon 0.063651038467105, time 725.0, rides 139\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3059, reward 842.0, memory_length 2000, epsilon 0.0635937525324846, time 727.0, rides 145\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 3060, reward 811.0, memory_length 2000, epsilon 0.06353651815520536, time 724.0, rides 140\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3061, reward 944.0, memory_length 2000, epsilon 0.06347933528886568, time 731.0, rides 137\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3062, reward 870.0, memory_length 2000, epsilon 0.0634222038871057, time 728.0, rides 126\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 3063, reward 847.0, memory_length 2000, epsilon 0.06336512390360731, time 724.0, rides 140\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 3064, reward 888.0, memory_length 2000, epsilon 0.06330809529209407, time 731.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3065, reward 921.0, memory_length 2000, epsilon 0.06325111800633118, time 731.0, rides 133\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 3066, reward 1270.0, memory_length 2000, epsilon 0.06319419200012548, time 720.0, rides 128\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3067, reward 684.0, memory_length 2000, epsilon 0.06313731722732537, time 728.0, rides 132\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 3068, reward 805.0, memory_length 2000, epsilon 0.06308049364182078, time 724.0, rides 131\n",
      "Initial State is  [2, 5, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3069, reward 888.0, memory_length 2000, epsilon 0.06302372119754314, time 731.0, rides 134\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 3070, reward 767.0, memory_length 2000, epsilon 0.06296699984846535, time 730.0, rides 139\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 3071, reward 923.0, memory_length 2000, epsilon 0.06291032954860173, time 726.0, rides 128\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 3072, reward 834.0, memory_length 2000, epsilon 0.06285371025200799, time 730.0, rides 142\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3073, reward 905.0, memory_length 2000, epsilon 0.06279714191278118, time 730.0, rides 135\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 3074, reward 837.0, memory_length 2000, epsilon 0.06274062448505968, time 725.0, rides 148\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 3075, reward 917.0, memory_length 2000, epsilon 0.06268415792302312, time 727.0, rides 135\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 3076, reward 687.0, memory_length 2000, epsilon 0.0626277421808924, time 727.0, rides 135\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 3077, reward 768.0, memory_length 2000, epsilon 0.06257137721292959, time 732.0, rides 131\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3078, reward 912.0, memory_length 2000, epsilon 0.06251506297343795, time 725.0, rides 130\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 3079, reward 853.0, memory_length 2000, epsilon 0.06245879941676186, time 729.0, rides 136\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3080, reward 846.0, memory_length 2000, epsilon 0.06240258649728677, time 729.0, rides 120\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3081, reward 666.0, memory_length 2000, epsilon 0.06234642416943921, time 723.0, rides 125\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3082, reward 770.0, memory_length 2000, epsilon 0.062290312387686717, time 726.0, rides 139\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3083, reward 642.0, memory_length 2000, epsilon 0.0622342511065378, time 725.0, rides 146\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3084, reward 926.0, memory_length 2000, epsilon 0.06217824028054191, time 726.0, rides 127\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 3085, reward 843.0, memory_length 2000, epsilon 0.06212227986428942, time 728.0, rides 147\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 3086, reward 583.0, memory_length 2000, epsilon 0.06206636981241156, time 733.0, rides 123\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 3087, reward 742.0, memory_length 2000, epsilon 0.06201051007958039, time 738.0, rides 128\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 3088, reward 1233.0, memory_length 2000, epsilon 0.061954700620508764, time 737.0, rides 133\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 3089, reward 915.0, memory_length 2000, epsilon 0.06189894138995031, time 732.0, rides 148\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 3090, reward 931.0, memory_length 2000, epsilon 0.06184323234269935, time 724.0, rides 134\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 3091, reward 756.0, memory_length 2000, epsilon 0.061787573433590925, time 728.0, rides 135\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 3092, reward 717.0, memory_length 2000, epsilon 0.06173196461750069, time 723.0, rides 127\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 3093, reward 722.0, memory_length 2000, epsilon 0.06167640584934494, time 729.0, rides 131\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3094, reward 934.0, memory_length 2000, epsilon 0.06162089708408053, time 731.0, rides 129\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 3095, reward 797.0, memory_length 2000, epsilon 0.061565438276704854, time 728.0, rides 124\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 3096, reward 981.0, memory_length 2000, epsilon 0.06151002938225582, time 728.0, rides 139\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 3097, reward 966.0, memory_length 2000, epsilon 0.061454670355811786, time 734.0, rides 141\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 3098, reward 682.0, memory_length 2000, epsilon 0.061399361152491554, time 731.0, rides 133\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 3099, reward 973.0, memory_length 2000, epsilon 0.06134410172745431, time 722.0, rides 134\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 3100, reward 843.0, memory_length 2000, epsilon 0.0612888920358996, time 731.0, rides 138\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 3101, reward 1103.0, memory_length 2000, epsilon 0.06123373203306729, time 733.0, rides 144\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3102, reward 724.0, memory_length 2000, epsilon 0.06117862167423753, time 733.0, rides 145\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3103, reward 1031.0, memory_length 2000, epsilon 0.061123560914730715, time 733.0, rides 135\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 3104, reward 991.0, memory_length 2000, epsilon 0.06106854970990746, time 722.0, rides 145\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 3105, reward 824.0, memory_length 2000, epsilon 0.06101358801516854, time 723.0, rides 120\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 3106, reward 925.0, memory_length 2000, epsilon 0.06095867578595489, time 729.0, rides 138\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 3107, reward 803.0, memory_length 2000, epsilon 0.06090381297774753, time 723.0, rides 125\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 3108, reward 796.0, memory_length 2000, epsilon 0.06084899954606756, time 729.0, rides 135\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 3109, reward 633.0, memory_length 2000, epsilon 0.0607942354464761, time 730.0, rides 126\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 3110, reward 971.0, memory_length 2000, epsilon 0.06073952063457427, time 722.0, rides 127\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3111, reward 681.0, memory_length 2000, epsilon 0.06068485506600316, time 728.0, rides 151\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3112, reward 1077.0, memory_length 2000, epsilon 0.06063023869644375, time 726.0, rides 135\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 3113, reward 837.0, memory_length 2000, epsilon 0.06057567148161695, time 729.0, rides 125\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3114, reward 1137.0, memory_length 2000, epsilon 0.0605211533772835, time 730.0, rides 130\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 3115, reward 724.0, memory_length 2000, epsilon 0.06046668433924394, time 729.0, rides 133\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 3116, reward 786.0, memory_length 2000, epsilon 0.06041226432333862, time 723.0, rides 124\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 3117, reward 869.0, memory_length 2000, epsilon 0.06035789328544761, time 724.0, rides 131\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3118, reward 649.0, memory_length 2000, epsilon 0.06030357118149071, time 731.0, rides 137\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 3119, reward 847.0, memory_length 2000, epsilon 0.06024929796742737, time 728.0, rides 122\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 3120, reward 1196.0, memory_length 2000, epsilon 0.06019507359925668, time 728.0, rides 143\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3121, reward 870.0, memory_length 2000, epsilon 0.06014089803301735, time 723.0, rides 124\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 3122, reward 542.0, memory_length 2000, epsilon 0.06008677122478764, time 730.0, rides 139\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 3123, reward 744.0, memory_length 2000, epsilon 0.06003269313068533, time 723.0, rides 135\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 3124, reward 881.0, memory_length 2000, epsilon 0.05997866370686771, time 727.0, rides 141\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 3125, reward 901.0, memory_length 2000, epsilon 0.05992468290953153, time 727.0, rides 143\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 3126, reward 1083.0, memory_length 2000, epsilon 0.059870750694912954, time 726.0, rides 134\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3127, reward 872.0, memory_length 2000, epsilon 0.05981686701928753, time 729.0, rides 132\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 3128, reward 940.0, memory_length 2000, epsilon 0.05976303183897017, time 733.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 3129, reward 916.0, memory_length 2000, epsilon 0.0597092451103151, time 744.0, rides 146\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 3130, reward 650.0, memory_length 2000, epsilon 0.05965550678971582, time 729.0, rides 121\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 3131, reward 1060.0, memory_length 2000, epsilon 0.059601816833605076, time 730.0, rides 135\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 3132, reward 719.0, memory_length 2000, epsilon 0.05954817519845483, time 727.0, rides 120\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 3133, reward 897.0, memory_length 2000, epsilon 0.05949458184077622, time 733.0, rides 135\n",
      "Initial State is  [1, 23, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3134, reward 674.0, memory_length 2000, epsilon 0.05944103671711952, time 724.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 3135, reward 791.0, memory_length 2000, epsilon 0.059387539784074114, time 728.0, rides 110\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 3136, reward 707.0, memory_length 2000, epsilon 0.059334090998268446, time 724.0, rides 124\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3137, reward 960.0, memory_length 2000, epsilon 0.059280690316370004, time 734.0, rides 141\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 3138, reward 883.0, memory_length 2000, epsilon 0.05922733769508527, time 737.0, rides 134\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3139, reward 895.0, memory_length 2000, epsilon 0.05917403309115969, time 729.0, rides 136\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 3140, reward 651.0, memory_length 2000, epsilon 0.059120776461377644, time 731.0, rides 131\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 3141, reward 892.0, memory_length 2000, epsilon 0.059067567762562403, time 730.0, rides 136\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 3142, reward 594.0, memory_length 2000, epsilon 0.059014406951576094, time 729.0, rides 135\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 3143, reward 953.0, memory_length 2000, epsilon 0.05896129398531968, time 730.0, rides 125\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3144, reward 780.0, memory_length 2000, epsilon 0.05890822882073289, time 728.0, rides 135\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 3145, reward 665.0, memory_length 2000, epsilon 0.05885521141479423, time 733.0, rides 128\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 3146, reward 804.0, memory_length 2000, epsilon 0.058802241724520914, time 733.0, rides 127\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 3147, reward 850.0, memory_length 2000, epsilon 0.058749319706968846, time 735.0, rides 132\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 3148, reward 877.0, memory_length 2000, epsilon 0.05869644531923257, time 737.0, rides 143\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 3149, reward 1043.0, memory_length 2000, epsilon 0.05864361851844526, time 729.0, rides 125\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 3150, reward 749.0, memory_length 2000, epsilon 0.05859083926177866, time 729.0, rides 140\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 3151, reward 737.0, memory_length 2000, epsilon 0.05853810750644306, time 724.0, rides 134\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 3152, reward 830.0, memory_length 2000, epsilon 0.05848542320968726, time 721.0, rides 119\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 3153, reward 748.0, memory_length 2000, epsilon 0.058432786328798544, time 733.0, rides 139\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 3154, reward 733.0, memory_length 2000, epsilon 0.058380196821102626, time 723.0, rides 129\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 3155, reward 882.0, memory_length 2000, epsilon 0.05832765464396363, time 731.0, rides 139\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 3156, reward 879.0, memory_length 2000, epsilon 0.05827515975478406, time 727.0, rides 138\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 3157, reward 905.0, memory_length 2000, epsilon 0.05822271211100476, time 725.0, rides 142\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 3158, reward 1165.0, memory_length 2000, epsilon 0.05817031167010485, time 736.0, rides 152\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 3159, reward 755.0, memory_length 2000, epsilon 0.05811795838960175, time 729.0, rides 128\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 3160, reward 349.0, memory_length 2000, epsilon 0.05806565222705111, time 733.0, rides 126\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 3161, reward 724.0, memory_length 2000, epsilon 0.05801339314004676, time 735.0, rides 130\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 3162, reward 1007.0, memory_length 2000, epsilon 0.05796118108622072, time 726.0, rides 135\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 3163, reward 1007.0, memory_length 2000, epsilon 0.057909016023243116, time 730.0, rides 131\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 3164, reward 833.0, memory_length 2000, epsilon 0.057856897908822195, time 734.0, rides 124\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 3165, reward 869.0, memory_length 2000, epsilon 0.057804826700704255, time 734.0, rides 125\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 3166, reward 793.0, memory_length 2000, epsilon 0.05775280235667362, time 723.0, rides 134\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 3167, reward 969.0, memory_length 2000, epsilon 0.05770082483455261, time 729.0, rides 137\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 3168, reward 1115.0, memory_length 2000, epsilon 0.057648894092201516, time 729.0, rides 139\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 3169, reward 752.0, memory_length 2000, epsilon 0.05759701008751853, time 727.0, rides 150\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 3170, reward 884.0, memory_length 2000, epsilon 0.05754517277843976, time 725.0, rides 145\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 3171, reward 852.0, memory_length 2000, epsilon 0.05749338212293917, time 724.0, rides 122\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 3172, reward 1181.0, memory_length 2000, epsilon 0.05744163807902852, time 728.0, rides 138\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 3173, reward 1001.0, memory_length 2000, epsilon 0.0573899406047574, time 725.0, rides 125\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3174, reward 844.0, memory_length 2000, epsilon 0.05733828965821312, time 725.0, rides 134\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3175, reward 895.0, memory_length 2000, epsilon 0.057286685197520726, time 734.0, rides 125\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 3176, reward 877.0, memory_length 2000, epsilon 0.057235127180842955, time 729.0, rides 132\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3177, reward 718.0, memory_length 2000, epsilon 0.05718361556638019, time 727.0, rides 118\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 3178, reward 939.0, memory_length 2000, epsilon 0.05713215031237045, time 729.0, rides 125\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 3179, reward 1003.0, memory_length 2000, epsilon 0.057080731377089314, time 728.0, rides 137\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 3180, reward 986.0, memory_length 2000, epsilon 0.05702935871884993, time 726.0, rides 115\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 3181, reward 1188.0, memory_length 2000, epsilon 0.05697803229600297, time 729.0, rides 129\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 3182, reward 764.0, memory_length 2000, epsilon 0.056926752066936565, time 730.0, rides 126\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 3183, reward 736.0, memory_length 2000, epsilon 0.05687551799007632, time 728.0, rides 123\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 3184, reward 707.0, memory_length 2000, epsilon 0.05682433002388525, time 732.0, rides 121\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 3185, reward 772.0, memory_length 2000, epsilon 0.05677318812686375, time 722.0, rides 123\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 3186, reward 463.0, memory_length 2000, epsilon 0.056722092257549574, time 731.0, rides 109\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 3187, reward 896.0, memory_length 2000, epsilon 0.056671042374517776, time 733.0, rides 126\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 3188, reward 772.0, memory_length 2000, epsilon 0.05662003843638071, time 729.0, rides 122\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3189, reward 1081.0, memory_length 2000, epsilon 0.056569080401787965, time 726.0, rides 137\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3190, reward 720.0, memory_length 2000, epsilon 0.056518168229426353, time 729.0, rides 132\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 3191, reward 962.0, memory_length 2000, epsilon 0.05646730187801987, time 727.0, rides 133\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 3192, reward 974.0, memory_length 2000, epsilon 0.056416481306329654, time 731.0, rides 135\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 3193, reward 728.0, memory_length 2000, epsilon 0.056365706473153955, time 738.0, rides 127\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3194, reward 929.0, memory_length 2000, epsilon 0.05631497733732812, time 727.0, rides 151\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3195, reward 939.0, memory_length 2000, epsilon 0.05626429385772452, time 728.0, rides 131\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 3196, reward 1044.0, memory_length 2000, epsilon 0.05621365599325257, time 730.0, rides 141\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3197, reward 786.0, memory_length 2000, epsilon 0.056163063702858645, time 727.0, rides 130\n",
      "Initial State is  [3, 7, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3198, reward 940.0, memory_length 2000, epsilon 0.056112516945526075, time 725.0, rides 132\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 3199, reward 1097.0, memory_length 2000, epsilon 0.0560620156802751, time 725.0, rides 132\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 3200, reward 947.0, memory_length 2000, epsilon 0.05601155986616285, time 728.0, rides 142\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 3201, reward 828.0, memory_length 2000, epsilon 0.055961149462283304, time 725.0, rides 138\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 3202, reward 1007.0, memory_length 2000, epsilon 0.05591078442776725, time 731.0, rides 136\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 3203, reward 986.0, memory_length 2000, epsilon 0.05586046472178226, time 734.0, rides 134\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 3204, reward 1035.0, memory_length 2000, epsilon 0.05581019030353265, time 731.0, rides 136\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 3205, reward 758.0, memory_length 2000, epsilon 0.05575996113225947, time 728.0, rides 131\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3206, reward 820.0, memory_length 2000, epsilon 0.05570977716724044, time 726.0, rides 129\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3207, reward 1043.0, memory_length 2000, epsilon 0.05565963836778992, time 723.0, rides 133\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 3208, reward 824.0, memory_length 2000, epsilon 0.05560954469325891, time 723.0, rides 134\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 3209, reward 983.0, memory_length 2000, epsilon 0.055559496103034976, time 729.0, rides 153\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3210, reward 995.0, memory_length 2000, epsilon 0.05550949255654224, time 725.0, rides 132\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3211, reward 997.0, memory_length 2000, epsilon 0.05545953401324136, time 730.0, rides 130\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 3212, reward 1075.0, memory_length 2000, epsilon 0.05540962043262944, time 729.0, rides 123\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3213, reward 1041.0, memory_length 2000, epsilon 0.055359751774240074, time 721.0, rides 141\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 3214, reward 793.0, memory_length 2000, epsilon 0.055309927997643255, time 731.0, rides 137\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3215, reward 1092.0, memory_length 2000, epsilon 0.05526014906244538, time 727.0, rides 139\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 3216, reward 924.0, memory_length 2000, epsilon 0.055210414928289174, time 731.0, rides 133\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3217, reward 846.0, memory_length 2000, epsilon 0.05516072555485371, time 732.0, rides 127\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 3218, reward 1082.0, memory_length 2000, epsilon 0.05511108090185434, time 729.0, rides 142\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 3219, reward 856.0, memory_length 2000, epsilon 0.05506148092904267, time 727.0, rides 144\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 3220, reward 747.0, memory_length 2000, epsilon 0.05501192559620653, time 736.0, rides 131\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 3221, reward 885.0, memory_length 2000, epsilon 0.054962414863169946, time 730.0, rides 132\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 3222, reward 879.0, memory_length 2000, epsilon 0.054912948689793094, time 732.0, rides 135\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 3223, reward 573.0, memory_length 2000, epsilon 0.054863527035972276, time 738.0, rides 127\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 3224, reward 1187.0, memory_length 2000, epsilon 0.0548141498616399, time 735.0, rides 133\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 3225, reward 730.0, memory_length 2000, epsilon 0.05476481712676442, time 727.0, rides 136\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 3226, reward 815.0, memory_length 2000, epsilon 0.05471552879135033, time 731.0, rides 137\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 3227, reward 1004.0, memory_length 2000, epsilon 0.054666284815438115, time 744.0, rides 130\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 3228, reward 761.0, memory_length 2000, epsilon 0.05461708515910422, time 727.0, rides 131\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 3229, reward 949.0, memory_length 2000, epsilon 0.05456792978246102, time 720.0, rides 146\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 3230, reward 864.0, memory_length 2000, epsilon 0.0545188186456568, time 724.0, rides 141\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 3231, reward 816.0, memory_length 2000, epsilon 0.05446975170887571, time 727.0, rides 135\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 3232, reward 1234.0, memory_length 2000, epsilon 0.05442072893233772, time 740.0, rides 129\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 3233, reward 1136.0, memory_length 2000, epsilon 0.05437175027629862, time 729.0, rides 132\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 3234, reward 1227.0, memory_length 2000, epsilon 0.05432281570104995, time 729.0, rides 142\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3235, reward 1053.0, memory_length 2000, epsilon 0.05427392516691901, time 726.0, rides 117\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 3236, reward 916.0, memory_length 2000, epsilon 0.05422507863426878, time 724.0, rides 135\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 3237, reward 895.0, memory_length 2000, epsilon 0.05417627606349794, time 727.0, rides 123\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3238, reward 786.0, memory_length 2000, epsilon 0.054127517415040786, time 732.0, rides 133\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 3239, reward 655.0, memory_length 2000, epsilon 0.05407880264936725, time 729.0, rides 117\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 3240, reward 826.0, memory_length 2000, epsilon 0.054030131726982816, time 726.0, rides 128\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3241, reward 997.0, memory_length 2000, epsilon 0.05398150460842853, time 736.0, rides 133\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3242, reward 1187.0, memory_length 2000, epsilon 0.053932921254280945, time 728.0, rides 116\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3243, reward 813.0, memory_length 2000, epsilon 0.05388438162515209, time 727.0, rides 137\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 3244, reward 553.0, memory_length 2000, epsilon 0.053835885681689455, time 723.0, rides 131\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3245, reward 959.0, memory_length 2000, epsilon 0.053787433384575936, time 729.0, rides 127\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 3246, reward 1028.0, memory_length 2000, epsilon 0.05373902469452982, time 731.0, rides 124\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 3247, reward 793.0, memory_length 2000, epsilon 0.05369065957230474, time 736.0, rides 126\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3248, reward 828.0, memory_length 2000, epsilon 0.05364233797868966, time 724.0, rides 140\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 3249, reward 1079.0, memory_length 2000, epsilon 0.05359405987450884, time 732.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 3250, reward 902.0, memory_length 2000, epsilon 0.05354582522062178, time 731.0, rides 128\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 3251, reward 869.0, memory_length 2000, epsilon 0.053497633977923224, time 728.0, rides 136\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 3252, reward 890.0, memory_length 2000, epsilon 0.05344948610734309, time 721.0, rides 135\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 3253, reward 1097.0, memory_length 2000, epsilon 0.05340138156984648, time 729.0, rides 130\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 3254, reward 704.0, memory_length 2000, epsilon 0.05335332032643362, time 730.0, rides 122\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 3255, reward 1035.0, memory_length 2000, epsilon 0.05330530233813983, time 722.0, rides 145\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 3256, reward 1282.0, memory_length 2000, epsilon 0.0532573275660355, time 727.0, rides 125\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 3257, reward 948.0, memory_length 2000, epsilon 0.05320939597122607, time 727.0, rides 131\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 3258, reward 958.0, memory_length 2000, epsilon 0.05316150751485197, time 727.0, rides 145\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 3259, reward 871.0, memory_length 2000, epsilon 0.053113662158088604, time 728.0, rides 124\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 3260, reward 692.0, memory_length 2000, epsilon 0.053065859862146326, time 730.0, rides 113\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 3261, reward 996.0, memory_length 2000, epsilon 0.053018100588270396, time 731.0, rides 139\n",
      "Initial State is  [0, 5, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3262, reward 1093.0, memory_length 2000, epsilon 0.05297038429774095, time 731.0, rides 123\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 3263, reward 986.0, memory_length 2000, epsilon 0.05292271095187299, time 733.0, rides 132\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 3264, reward 1176.0, memory_length 2000, epsilon 0.0528750805120163, time 726.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 3265, reward 886.0, memory_length 2000, epsilon 0.052827492939555486, time 728.0, rides 143\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 3266, reward 829.0, memory_length 2000, epsilon 0.052779948195909886, time 730.0, rides 142\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 3267, reward 676.0, memory_length 2000, epsilon 0.052732446242533565, time 733.0, rides 138\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 3268, reward 694.0, memory_length 2000, epsilon 0.05268498704091528, time 726.0, rides 124\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3269, reward 994.0, memory_length 2000, epsilon 0.05263757055257846, time 722.0, rides 127\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 3270, reward 1004.0, memory_length 2000, epsilon 0.052590196739081135, time 731.0, rides 122\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 3271, reward 968.0, memory_length 2000, epsilon 0.05254286556201596, time 724.0, rides 143\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3272, reward 861.0, memory_length 2000, epsilon 0.05249557698301015, time 725.0, rides 124\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 3273, reward 1006.0, memory_length 2000, epsilon 0.05244833096372544, time 725.0, rides 129\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 3274, reward 928.0, memory_length 2000, epsilon 0.05240112746585809, time 726.0, rides 132\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3275, reward 682.0, memory_length 2000, epsilon 0.052353966451138816, time 725.0, rides 114\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 3276, reward 825.0, memory_length 2000, epsilon 0.05230684788133279, time 726.0, rides 131\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 3277, reward 886.0, memory_length 2000, epsilon 0.05225977171823959, time 723.0, rides 134\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 3278, reward 1097.0, memory_length 2000, epsilon 0.05221273792369317, time 726.0, rides 128\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 3279, reward 804.0, memory_length 2000, epsilon 0.052165746459561846, time 728.0, rides 141\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3280, reward 1119.0, memory_length 2000, epsilon 0.052118797287748236, time 725.0, rides 124\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3281, reward 886.0, memory_length 2000, epsilon 0.052071890370189264, time 728.0, rides 120\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3282, reward 818.0, memory_length 2000, epsilon 0.05202502566885609, time 733.0, rides 124\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3283, reward 742.0, memory_length 2000, epsilon 0.05197820314575412, time 728.0, rides 137\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 3284, reward 768.0, memory_length 2000, epsilon 0.05193142276292294, time 739.0, rides 114\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 3285, reward 914.0, memory_length 2000, epsilon 0.05188468448243631, time 728.0, rides 125\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 3286, reward 747.0, memory_length 2000, epsilon 0.05183798826640211, time 729.0, rides 134\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 3287, reward 1106.0, memory_length 2000, epsilon 0.05179133407696235, time 730.0, rides 147\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3288, reward 1155.0, memory_length 2000, epsilon 0.05174472187629308, time 729.0, rides 122\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3289, reward 1254.0, memory_length 2000, epsilon 0.05169815162660442, time 730.0, rides 125\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 3290, reward 770.0, memory_length 2000, epsilon 0.051651623290140475, time 725.0, rides 135\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3291, reward 1018.0, memory_length 2000, epsilon 0.051605136829179346, time 729.0, rides 140\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 3292, reward 1016.0, memory_length 2000, epsilon 0.05155869220603308, time 736.0, rides 112\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 3293, reward 1025.0, memory_length 2000, epsilon 0.05151228938304765, time 724.0, rides 133\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 3294, reward 926.0, memory_length 2000, epsilon 0.05146592832260291, time 732.0, rides 132\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 3295, reward 1000.0, memory_length 2000, epsilon 0.05141960898711257, time 735.0, rides 139\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 3296, reward 1038.0, memory_length 2000, epsilon 0.05137333133902417, time 730.0, rides 126\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 3297, reward 764.0, memory_length 2000, epsilon 0.05132709534081905, time 733.0, rides 130\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 3298, reward 704.0, memory_length 2000, epsilon 0.05128090095501231, time 720.0, rides 138\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 3299, reward 805.0, memory_length 2000, epsilon 0.0512347481441528, time 736.0, rides 135\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 3300, reward 1072.0, memory_length 2000, epsilon 0.05118863687082306, time 732.0, rides 134\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 3301, reward 1288.0, memory_length 2000, epsilon 0.05114256709763932, time 727.0, rides 149\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 3302, reward 1035.0, memory_length 2000, epsilon 0.05109653878725144, time 731.0, rides 130\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 3303, reward 678.0, memory_length 2000, epsilon 0.051050551902342915, time 730.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 3304, reward 1063.0, memory_length 2000, epsilon 0.05100460640563081, time 724.0, rides 128\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3305, reward 866.0, memory_length 2000, epsilon 0.05095870225986574, time 727.0, rides 140\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 3306, reward 810.0, memory_length 2000, epsilon 0.05091283942783186, time 728.0, rides 137\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 3307, reward 715.0, memory_length 2000, epsilon 0.05086701787234681, time 728.0, rides 137\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 3308, reward 944.0, memory_length 2000, epsilon 0.0508212375562617, time 728.0, rides 132\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 3309, reward 967.0, memory_length 2000, epsilon 0.05077549844246106, time 736.0, rides 133\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 3310, reward 677.0, memory_length 2000, epsilon 0.050729800493862845, time 730.0, rides 123\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 3311, reward 1257.0, memory_length 2000, epsilon 0.05068414367341837, time 732.0, rides 129\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 3312, reward 1133.0, memory_length 2000, epsilon 0.05063852794411229, time 734.0, rides 125\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 3313, reward 990.0, memory_length 2000, epsilon 0.05059295326896259, time 736.0, rides 155\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 3314, reward 1007.0, memory_length 2000, epsilon 0.05054741961102052, time 728.0, rides 135\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 3315, reward 1034.0, memory_length 2000, epsilon 0.050501926933370606, time 728.0, rides 135\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 3316, reward 1267.0, memory_length 2000, epsilon 0.050456475199130574, time 731.0, rides 128\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 3317, reward 608.0, memory_length 2000, epsilon 0.050411064371451354, time 728.0, rides 131\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 3318, reward 896.0, memory_length 2000, epsilon 0.05036569441351705, time 734.0, rides 125\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 3319, reward 963.0, memory_length 2000, epsilon 0.05032036528854488, time 725.0, rides 126\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 3320, reward 1295.0, memory_length 2000, epsilon 0.05027507695978519, time 724.0, rides 127\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 3321, reward 671.0, memory_length 2000, epsilon 0.05022982939052138, time 733.0, rides 113\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3322, reward 490.0, memory_length 2000, epsilon 0.05018462254406991, time 723.0, rides 119\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3323, reward 871.0, memory_length 2000, epsilon 0.05013945638378025, time 734.0, rides 131\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3324, reward 1115.0, memory_length 2000, epsilon 0.050094330873034845, time 728.0, rides 126\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3325, reward 871.0, memory_length 2000, epsilon 0.05004924597524912, time 723.0, rides 122\n",
      "Initial State is  [2, 13, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3326, reward 1072.0, memory_length 2000, epsilon 0.05000420165387139, time 733.0, rides 132\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 3327, reward 719.0, memory_length 2000, epsilon 0.049959197872382906, time 730.0, rides 132\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 3328, reward 836.0, memory_length 2000, epsilon 0.04991423459429776, time 727.0, rides 130\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 3329, reward 1104.0, memory_length 2000, epsilon 0.04986931178316289, time 732.0, rides 138\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 3330, reward 966.0, memory_length 2000, epsilon 0.04982442940255804, time 731.0, rides 131\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 3331, reward 867.0, memory_length 2000, epsilon 0.049779587416095734, time 727.0, rides 125\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3332, reward 847.0, memory_length 2000, epsilon 0.04973478578742125, time 727.0, rides 119\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3333, reward 973.0, memory_length 2000, epsilon 0.04969002448021257, time 726.0, rides 135\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3334, reward 1009.0, memory_length 2000, epsilon 0.04964530345818038, time 727.0, rides 122\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 3335, reward 943.0, memory_length 2000, epsilon 0.04960062268506801, time 729.0, rides 121\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 3336, reward 1045.0, memory_length 2000, epsilon 0.049555982124651454, time 724.0, rides 131\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 3337, reward 666.0, memory_length 2000, epsilon 0.04951138174073927, time 723.0, rides 132\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 3338, reward 1338.0, memory_length 2000, epsilon 0.0494668214971726, time 727.0, rides 138\n",
      "Initial State is  [2, 11, 5]\n",
      "episode 3339, reward 1022.0, memory_length 2000, epsilon 0.049422301357825146, time 731.0, rides 123\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 3340, reward 802.0, memory_length 2000, epsilon 0.049377821286603105, time 728.0, rides 133\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3341, reward 1039.0, memory_length 2000, epsilon 0.049333381247445164, time 726.0, rides 128\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 3342, reward 967.0, memory_length 2000, epsilon 0.049288981204322464, time 729.0, rides 128\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 3343, reward 1000.0, memory_length 2000, epsilon 0.04924462112123857, time 736.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3344, reward 679.0, memory_length 2000, epsilon 0.04920030096222946, time 728.0, rides 120\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 3345, reward 666.0, memory_length 2000, epsilon 0.049156020691363454, time 730.0, rides 123\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 3346, reward 1090.0, memory_length 2000, epsilon 0.049111780272741226, time 730.0, rides 141\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 3347, reward 1008.0, memory_length 2000, epsilon 0.049067579670495756, time 730.0, rides 128\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 3348, reward 910.0, memory_length 2000, epsilon 0.049023418848792306, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 3349, reward 754.0, memory_length 2000, epsilon 0.04897929777182839, time 723.0, rides 137\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 3350, reward 913.0, memory_length 2000, epsilon 0.04893521640383375, time 725.0, rides 128\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 3351, reward 1231.0, memory_length 2000, epsilon 0.0488911747090703, time 731.0, rides 120\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 3352, reward 649.0, memory_length 2000, epsilon 0.04884717265183213, time 737.0, rides 140\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 3353, reward 863.0, memory_length 2000, epsilon 0.048803210196445485, time 734.0, rides 144\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 3354, reward 1149.0, memory_length 2000, epsilon 0.04875928730726868, time 726.0, rides 131\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 3355, reward 1092.0, memory_length 2000, epsilon 0.048715403948692136, time 732.0, rides 136\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 3356, reward 878.0, memory_length 2000, epsilon 0.048671560085138316, time 730.0, rides 129\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 3357, reward 894.0, memory_length 2000, epsilon 0.04862775568106169, time 728.0, rides 127\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 3358, reward 903.0, memory_length 2000, epsilon 0.04858399070094873, time 724.0, rides 137\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 3359, reward 663.0, memory_length 2000, epsilon 0.04854026510931787, time 728.0, rides 125\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 3360, reward 872.0, memory_length 2000, epsilon 0.04849657887071949, time 727.0, rides 124\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 3361, reward 860.0, memory_length 2000, epsilon 0.04845293194973584, time 724.0, rides 115\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 3362, reward 1061.0, memory_length 2000, epsilon 0.04840932431098108, time 733.0, rides 134\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 3363, reward 1081.0, memory_length 2000, epsilon 0.048365755919101194, time 744.0, rides 136\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 3364, reward 949.0, memory_length 2000, epsilon 0.048322226738774, time 727.0, rides 125\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 3365, reward 755.0, memory_length 2000, epsilon 0.04827873673470911, time 730.0, rides 131\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 3366, reward 1024.0, memory_length 2000, epsilon 0.04823528587164787, time 727.0, rides 136\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 3367, reward 1089.0, memory_length 2000, epsilon 0.04819187411436338, time 731.0, rides 129\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3368, reward 1111.0, memory_length 2000, epsilon 0.04814850142766045, time 724.0, rides 119\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 3369, reward 1024.0, memory_length 2000, epsilon 0.04810516777637556, time 726.0, rides 139\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 3370, reward 1083.0, memory_length 2000, epsilon 0.04806187312537682, time 727.0, rides 140\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3371, reward 1060.0, memory_length 2000, epsilon 0.048018617439563975, time 727.0, rides 137\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 3372, reward 714.0, memory_length 2000, epsilon 0.047975400683868366, time 725.0, rides 126\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 3373, reward 785.0, memory_length 2000, epsilon 0.047932222823252886, time 726.0, rides 125\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3374, reward 628.0, memory_length 2000, epsilon 0.04788908382271196, time 727.0, rides 120\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 3375, reward 865.0, memory_length 2000, epsilon 0.047845983647271516, time 723.0, rides 126\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 3376, reward 993.0, memory_length 2000, epsilon 0.04780292226198897, time 732.0, rides 137\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3377, reward 974.0, memory_length 2000, epsilon 0.04775989963195318, time 727.0, rides 135\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 3378, reward 788.0, memory_length 2000, epsilon 0.04771691572228442, time 724.0, rides 132\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 3379, reward 713.0, memory_length 2000, epsilon 0.04767397049813436, time 726.0, rides 136\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 3380, reward 583.0, memory_length 2000, epsilon 0.047631063924686044, time 731.0, rides 150\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 3381, reward 779.0, memory_length 2000, epsilon 0.04758819596715383, time 742.0, rides 128\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3382, reward 895.0, memory_length 2000, epsilon 0.04754536659078339, time 727.0, rides 138\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 3383, reward 963.0, memory_length 2000, epsilon 0.047502575760851685, time 733.0, rides 129\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 3384, reward 1088.0, memory_length 2000, epsilon 0.047459823442666915, time 721.0, rides 131\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 3385, reward 1004.0, memory_length 2000, epsilon 0.047417109601568516, time 734.0, rides 141\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 3386, reward 1007.0, memory_length 2000, epsilon 0.047374434202927106, time 731.0, rides 125\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 3387, reward 1058.0, memory_length 2000, epsilon 0.04733179721214447, time 732.0, rides 146\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 3388, reward 691.0, memory_length 2000, epsilon 0.04728919859465354, time 726.0, rides 140\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 3389, reward 895.0, memory_length 2000, epsilon 0.04724663831591835, time 730.0, rides 128\n",
      "Initial State is  [0, 5, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3390, reward 990.0, memory_length 2000, epsilon 0.04720411634143402, time 728.0, rides 137\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 3391, reward 796.0, memory_length 2000, epsilon 0.04716163263672673, time 729.0, rides 137\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 3392, reward 884.0, memory_length 2000, epsilon 0.04711918716735367, time 725.0, rides 128\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 3393, reward 1165.0, memory_length 2000, epsilon 0.047076779898903055, time 729.0, rides 128\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 3394, reward 933.0, memory_length 2000, epsilon 0.04703441079699404, time 725.0, rides 147\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 3395, reward 1255.0, memory_length 2000, epsilon 0.046992079827276746, time 732.0, rides 124\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 3396, reward 1038.0, memory_length 2000, epsilon 0.0469497869554322, time 732.0, rides 144\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 3397, reward 989.0, memory_length 2000, epsilon 0.04690753214717231, time 722.0, rides 134\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3398, reward 1259.0, memory_length 2000, epsilon 0.04686531536823985, time 730.0, rides 124\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 3399, reward 1014.0, memory_length 2000, epsilon 0.04682313658440844, time 731.0, rides 144\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 3400, reward 880.0, memory_length 2000, epsilon 0.04678099576148247, time 728.0, rides 141\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 3401, reward 1072.0, memory_length 2000, epsilon 0.04673889286529714, time 725.0, rides 132\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3402, reward 740.0, memory_length 2000, epsilon 0.04669682786171837, time 740.0, rides 138\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 3403, reward 828.0, memory_length 2000, epsilon 0.04665480071664282, time 729.0, rides 122\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3404, reward 651.0, memory_length 2000, epsilon 0.046612811395997836, time 728.0, rides 145\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 3405, reward 1005.0, memory_length 2000, epsilon 0.046570859865741436, time 729.0, rides 153\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3406, reward 800.0, memory_length 2000, epsilon 0.04652894609186227, time 722.0, rides 127\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 3407, reward 798.0, memory_length 2000, epsilon 0.046487070040379594, time 726.0, rides 125\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 3408, reward 724.0, memory_length 2000, epsilon 0.046445231677343254, time 736.0, rides 138\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3409, reward 1174.0, memory_length 2000, epsilon 0.04640343096883365, time 727.0, rides 136\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 3410, reward 1069.0, memory_length 2000, epsilon 0.046361667880961695, time 723.0, rides 152\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 3411, reward 907.0, memory_length 2000, epsilon 0.04631994237986883, time 731.0, rides 130\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 3412, reward 782.0, memory_length 2000, epsilon 0.046278254431726944, time 731.0, rides 133\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 3413, reward 1256.0, memory_length 2000, epsilon 0.046236604002738386, time 732.0, rides 149\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 3414, reward 704.0, memory_length 2000, epsilon 0.04619499105913592, time 732.0, rides 134\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 3415, reward 787.0, memory_length 2000, epsilon 0.0461534155671827, time 737.0, rides 124\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 3416, reward 864.0, memory_length 2000, epsilon 0.046111877493172235, time 732.0, rides 131\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 3417, reward 964.0, memory_length 2000, epsilon 0.04607037680342838, time 733.0, rides 141\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 3418, reward 988.0, memory_length 2000, epsilon 0.04602891346430529, time 727.0, rides 116\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 3419, reward 991.0, memory_length 2000, epsilon 0.04598748744218742, time 730.0, rides 135\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 3420, reward 871.0, memory_length 2000, epsilon 0.04594609870348945, time 735.0, rides 127\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 3421, reward 811.0, memory_length 2000, epsilon 0.04590474721465631, time 731.0, rides 121\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 3422, reward 729.0, memory_length 2000, epsilon 0.04586343294216312, time 736.0, rides 125\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 3423, reward 1264.0, memory_length 2000, epsilon 0.04582215585251517, time 728.0, rides 139\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3424, reward 1057.0, memory_length 2000, epsilon 0.04578091591224791, time 729.0, rides 131\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 3425, reward 747.0, memory_length 2000, epsilon 0.04573971308792688, time 724.0, rides 139\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 3426, reward 737.0, memory_length 2000, epsilon 0.04569854734614775, time 731.0, rides 132\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3427, reward 846.0, memory_length 2000, epsilon 0.045657418653536216, time 725.0, rides 138\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 3428, reward 802.0, memory_length 2000, epsilon 0.045616326976748035, time 726.0, rides 136\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 3429, reward 1005.0, memory_length 2000, epsilon 0.045575272282468965, time 729.0, rides 124\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3430, reward 1064.0, memory_length 2000, epsilon 0.04553425453741474, time 724.0, rides 137\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 3431, reward 1139.0, memory_length 2000, epsilon 0.04549327370833107, time 728.0, rides 138\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 3432, reward 999.0, memory_length 2000, epsilon 0.04545232976199357, time 723.0, rides 130\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 3433, reward 753.0, memory_length 2000, epsilon 0.04541142266520778, time 735.0, rides 130\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3434, reward 874.0, memory_length 2000, epsilon 0.04537055238480909, time 728.0, rides 129\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3435, reward 794.0, memory_length 2000, epsilon 0.04532971888766276, time 730.0, rides 124\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 3436, reward 702.0, memory_length 2000, epsilon 0.045288922140663865, time 727.0, rides 129\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 3437, reward 1065.0, memory_length 2000, epsilon 0.04524816211073727, time 729.0, rides 135\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 3438, reward 1079.0, memory_length 2000, epsilon 0.045207438764837606, time 734.0, rides 131\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 3439, reward 736.0, memory_length 2000, epsilon 0.04516675206994925, time 727.0, rides 118\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 3440, reward 932.0, memory_length 2000, epsilon 0.045126101993086296, time 736.0, rides 124\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 3441, reward 640.0, memory_length 2000, epsilon 0.045085488501292514, time 732.0, rides 139\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3442, reward 823.0, memory_length 2000, epsilon 0.04504491156164135, time 726.0, rides 128\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 3443, reward 1002.0, memory_length 2000, epsilon 0.04500437114123587, time 726.0, rides 141\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 3444, reward 1158.0, memory_length 2000, epsilon 0.04496386720720876, time 725.0, rides 133\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3445, reward 584.0, memory_length 2000, epsilon 0.044923399726722275, time 723.0, rides 139\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 3446, reward 841.0, memory_length 2000, epsilon 0.044882968666968226, time 727.0, rides 136\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 3447, reward 782.0, memory_length 2000, epsilon 0.04484257399516795, time 725.0, rides 124\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 3448, reward 846.0, memory_length 2000, epsilon 0.0448022156785723, time 730.0, rides 135\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 3449, reward 1209.0, memory_length 2000, epsilon 0.04476189368446159, time 731.0, rides 122\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 3450, reward 697.0, memory_length 2000, epsilon 0.04472160798014557, time 730.0, rides 128\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 3451, reward 757.0, memory_length 2000, epsilon 0.04468135853296344, time 732.0, rides 129\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 3452, reward 1023.0, memory_length 2000, epsilon 0.04464114531028377, time 726.0, rides 137\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 3453, reward 850.0, memory_length 2000, epsilon 0.044600968279504515, time 724.0, rides 135\n",
      "Initial State is  [3, 18, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3454, reward 871.0, memory_length 2000, epsilon 0.04456082740805296, time 727.0, rides 129\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 3455, reward 571.0, memory_length 2000, epsilon 0.044520722663385706, time 724.0, rides 127\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 3456, reward 650.0, memory_length 2000, epsilon 0.04448065401298866, time 731.0, rides 123\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3457, reward 1129.0, memory_length 2000, epsilon 0.04444062142437697, time 723.0, rides 139\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 3458, reward 880.0, memory_length 2000, epsilon 0.04440062486509503, time 729.0, rides 135\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3459, reward 719.0, memory_length 2000, epsilon 0.04436066430271644, time 736.0, rides 130\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 3460, reward 769.0, memory_length 2000, epsilon 0.044320739704844, time 727.0, rides 135\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 3461, reward 918.0, memory_length 2000, epsilon 0.04428085103910964, time 731.0, rides 133\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 3462, reward 1150.0, memory_length 2000, epsilon 0.044240998273174445, time 728.0, rides 138\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 3463, reward 947.0, memory_length 2000, epsilon 0.04420118137472859, time 724.0, rides 131\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 3464, reward 834.0, memory_length 2000, epsilon 0.04416140031149133, time 725.0, rides 130\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 3465, reward 826.0, memory_length 2000, epsilon 0.04412165505121099, time 727.0, rides 131\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 3466, reward 877.0, memory_length 2000, epsilon 0.0440819455616649, time 735.0, rides 133\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 3467, reward 842.0, memory_length 2000, epsilon 0.0440422718106594, time 736.0, rides 144\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 3468, reward 911.0, memory_length 2000, epsilon 0.04400263376602981, time 724.0, rides 132\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 3469, reward 993.0, memory_length 2000, epsilon 0.04396303139564038, time 740.0, rides 142\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 3470, reward 838.0, memory_length 2000, epsilon 0.0439234646673843, time 728.0, rides 125\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 3471, reward 929.0, memory_length 2000, epsilon 0.04388393354918366, time 725.0, rides 131\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 3472, reward 1280.0, memory_length 2000, epsilon 0.04384443800898939, time 732.0, rides 133\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 3473, reward 800.0, memory_length 2000, epsilon 0.0438049780147813, time 726.0, rides 130\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 3474, reward 519.0, memory_length 2000, epsilon 0.043765553534568, time 727.0, rides 125\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 3475, reward 1163.0, memory_length 2000, epsilon 0.04372616453638689, time 726.0, rides 129\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 3476, reward 898.0, memory_length 2000, epsilon 0.04368681098830414, time 731.0, rides 135\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 3477, reward 1258.0, memory_length 2000, epsilon 0.04364749285841466, time 736.0, rides 125\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 3478, reward 841.0, memory_length 2000, epsilon 0.04360821011484209, time 731.0, rides 134\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 3479, reward 845.0, memory_length 2000, epsilon 0.04356896272573873, time 732.0, rides 132\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3480, reward 907.0, memory_length 2000, epsilon 0.04352975065928556, time 732.0, rides 141\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 3481, reward 843.0, memory_length 2000, epsilon 0.04349057388369221, time 729.0, rides 137\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 3482, reward 546.0, memory_length 2000, epsilon 0.04345143236719688, time 737.0, rides 126\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3483, reward 1161.0, memory_length 2000, epsilon 0.0434123260780664, time 732.0, rides 130\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 3484, reward 1161.0, memory_length 2000, epsilon 0.04337325498459614, time 727.0, rides 133\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 3485, reward 1052.0, memory_length 2000, epsilon 0.04333421905511001, time 729.0, rides 129\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 3486, reward 895.0, memory_length 2000, epsilon 0.043295218257960406, time 732.0, rides 135\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 3487, reward 706.0, memory_length 2000, epsilon 0.04325625256152824, time 729.0, rides 128\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3488, reward 1053.0, memory_length 2000, epsilon 0.04321732193422287, time 734.0, rides 139\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 3489, reward 773.0, memory_length 2000, epsilon 0.04317842634448207, time 734.0, rides 137\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 3490, reward 899.0, memory_length 2000, epsilon 0.04313956576077203, time 724.0, rides 131\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 3491, reward 883.0, memory_length 2000, epsilon 0.04310074015158734, time 727.0, rides 135\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 3492, reward 597.0, memory_length 2000, epsilon 0.04306194948545091, time 729.0, rides 132\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 3493, reward 1109.0, memory_length 2000, epsilon 0.043023193730914004, time 736.0, rides 138\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 3494, reward 1033.0, memory_length 2000, epsilon 0.04298447285655618, time 730.0, rides 132\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 3495, reward 842.0, memory_length 2000, epsilon 0.04294578683098528, time 733.0, rides 143\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 3496, reward 1219.0, memory_length 2000, epsilon 0.04290713562283739, time 728.0, rides 121\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 3497, reward 1202.0, memory_length 2000, epsilon 0.04286851920077684, time 727.0, rides 132\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 3498, reward 1056.0, memory_length 2000, epsilon 0.04282993753349614, time 733.0, rides 136\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 3499, reward 869.0, memory_length 2000, epsilon 0.042791390589716, time 727.0, rides 134\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 3500, reward 1155.0, memory_length 2000, epsilon 0.04275287833818525, time 730.0, rides 126\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 3501, reward 802.0, memory_length 2000, epsilon 0.04271440074768088, time 734.0, rides 134\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 3502, reward 1068.0, memory_length 2000, epsilon 0.042675957787007966, time 731.0, rides 129\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 3503, reward 869.0, memory_length 2000, epsilon 0.04263754942499966, time 732.0, rides 132\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 3504, reward 1097.0, memory_length 2000, epsilon 0.042599175630517155, time 737.0, rides 134\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 3505, reward 1024.0, memory_length 2000, epsilon 0.04256083637244969, time 730.0, rides 129\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 3506, reward 1031.0, memory_length 2000, epsilon 0.04252253161971448, time 733.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 3507, reward 1065.0, memory_length 2000, epsilon 0.04248426134125674, time 734.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 3508, reward 1047.0, memory_length 2000, epsilon 0.04244602550604961, time 728.0, rides 142\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 3509, reward 998.0, memory_length 2000, epsilon 0.04240782408309417, time 728.0, rides 129\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 3510, reward 1064.0, memory_length 2000, epsilon 0.04236965704141938, time 737.0, rides 136\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 3511, reward 986.0, memory_length 2000, epsilon 0.042331524350082105, time 723.0, rides 143\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 3512, reward 839.0, memory_length 2000, epsilon 0.04229342597816703, time 730.0, rides 138\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 3513, reward 1035.0, memory_length 2000, epsilon 0.04225536189478668, time 735.0, rides 141\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 3514, reward 842.0, memory_length 2000, epsilon 0.04221733206908137, time 728.0, rides 131\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 3515, reward 827.0, memory_length 2000, epsilon 0.042179336470219195, time 732.0, rides 119\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 3516, reward 870.0, memory_length 2000, epsilon 0.042141375067396, time 724.0, rides 115\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 3517, reward 1004.0, memory_length 2000, epsilon 0.04210344782983534, time 724.0, rides 134\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 3518, reward 932.0, memory_length 2000, epsilon 0.04206555472678849, time 729.0, rides 133\n",
      "Initial State is  [3, 23, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3519, reward 1018.0, memory_length 2000, epsilon 0.04202769572753438, time 728.0, rides 130\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 3520, reward 1009.0, memory_length 2000, epsilon 0.04198987080137959, time 725.0, rides 144\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 3521, reward 882.0, memory_length 2000, epsilon 0.04195207991765835, time 743.0, rides 137\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 3522, reward 943.0, memory_length 2000, epsilon 0.041914323045732456, time 730.0, rides 118\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 3523, reward 671.0, memory_length 2000, epsilon 0.0418766001549913, time 725.0, rides 126\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 3524, reward 937.0, memory_length 2000, epsilon 0.0418389112148518, time 721.0, rides 131\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 3525, reward 993.0, memory_length 2000, epsilon 0.041801256194758434, time 730.0, rides 122\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 3526, reward 1088.0, memory_length 2000, epsilon 0.04176363506418315, time 730.0, rides 133\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3527, reward 1031.0, memory_length 2000, epsilon 0.041726047792625384, time 728.0, rides 137\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 3528, reward 1070.0, memory_length 2000, epsilon 0.04168849434961202, time 733.0, rides 126\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 3529, reward 1302.0, memory_length 2000, epsilon 0.04165097470469737, time 728.0, rides 147\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 3530, reward 960.0, memory_length 2000, epsilon 0.041613488827463144, time 726.0, rides 127\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3531, reward 940.0, memory_length 2000, epsilon 0.04157603668751843, time 734.0, rides 129\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 3532, reward 950.0, memory_length 2000, epsilon 0.041538618254499664, time 728.0, rides 127\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 3533, reward 1078.0, memory_length 2000, epsilon 0.04150123349807061, time 729.0, rides 122\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 3534, reward 598.0, memory_length 2000, epsilon 0.04146388238792235, time 729.0, rides 131\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 3535, reward 772.0, memory_length 2000, epsilon 0.041426564893773214, time 740.0, rides 141\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 3536, reward 832.0, memory_length 2000, epsilon 0.041389280985368815, time 724.0, rides 136\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 3537, reward 669.0, memory_length 2000, epsilon 0.04135203063248198, time 728.0, rides 119\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 3538, reward 954.0, memory_length 2000, epsilon 0.041314813804912746, time 731.0, rides 125\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3539, reward 794.0, memory_length 2000, epsilon 0.04127763047248832, time 727.0, rides 126\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3540, reward 893.0, memory_length 2000, epsilon 0.04124048060506308, time 728.0, rides 131\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3541, reward 975.0, memory_length 2000, epsilon 0.04120336417251852, time 726.0, rides 143\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 3542, reward 766.0, memory_length 2000, epsilon 0.04116628114476325, time 729.0, rides 121\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 3543, reward 864.0, memory_length 2000, epsilon 0.04112923149173296, time 727.0, rides 123\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 3544, reward 626.0, memory_length 2000, epsilon 0.0410922151833904, time 728.0, rides 125\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 3545, reward 881.0, memory_length 2000, epsilon 0.04105523218972535, time 722.0, rides 129\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3546, reward 1044.0, memory_length 2000, epsilon 0.0410182824807546, time 732.0, rides 142\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 3547, reward 1189.0, memory_length 2000, epsilon 0.04098136602652192, time 730.0, rides 136\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 3548, reward 1089.0, memory_length 2000, epsilon 0.04094448279709805, time 723.0, rides 135\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 3549, reward 714.0, memory_length 2000, epsilon 0.040907632762580665, time 725.0, rides 129\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 3550, reward 759.0, memory_length 2000, epsilon 0.04087081589309434, time 734.0, rides 119\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 3551, reward 1041.0, memory_length 2000, epsilon 0.040834032158790556, time 728.0, rides 141\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 3552, reward 766.0, memory_length 2000, epsilon 0.04079728152984764, time 726.0, rides 133\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 3553, reward 874.0, memory_length 2000, epsilon 0.04076056397647078, time 724.0, rides 133\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 3554, reward 1012.0, memory_length 2000, epsilon 0.04072387946889196, time 731.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 3555, reward 1124.0, memory_length 2000, epsilon 0.040687227977369955, time 722.0, rides 138\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 3556, reward 921.0, memory_length 2000, epsilon 0.04065060947219032, time 729.0, rides 134\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3557, reward 849.0, memory_length 2000, epsilon 0.040614023923665345, time 723.0, rides 131\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 3558, reward 963.0, memory_length 2000, epsilon 0.040577471302134044, time 731.0, rides 133\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3559, reward 1082.0, memory_length 2000, epsilon 0.04054095157796212, time 724.0, rides 136\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 3560, reward 1184.0, memory_length 2000, epsilon 0.040504464721541955, time 733.0, rides 138\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3561, reward 1103.0, memory_length 2000, epsilon 0.04046801070329257, time 728.0, rides 134\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 3562, reward 827.0, memory_length 2000, epsilon 0.0404315894936596, time 726.0, rides 125\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 3563, reward 1163.0, memory_length 2000, epsilon 0.04039520106311531, time 735.0, rides 131\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 3564, reward 1096.0, memory_length 2000, epsilon 0.040358845382158504, time 723.0, rides 133\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 3565, reward 886.0, memory_length 2000, epsilon 0.04032252242131456, time 733.0, rides 135\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 3566, reward 772.0, memory_length 2000, epsilon 0.04028623215113537, time 734.0, rides 127\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 3567, reward 1181.0, memory_length 2000, epsilon 0.04024997454219935, time 730.0, rides 151\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 3568, reward 951.0, memory_length 2000, epsilon 0.04021374956511137, time 722.0, rides 125\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3569, reward 1101.0, memory_length 2000, epsilon 0.04017755719050277, time 731.0, rides 136\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 3570, reward 912.0, memory_length 2000, epsilon 0.040141397389031316, time 732.0, rides 140\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 3571, reward 1178.0, memory_length 2000, epsilon 0.04010527013138119, time 727.0, rides 133\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3572, reward 883.0, memory_length 2000, epsilon 0.04006917538826295, time 725.0, rides 127\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 3573, reward 1041.0, memory_length 2000, epsilon 0.04003311313041351, time 725.0, rides 139\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 3574, reward 1051.0, memory_length 2000, epsilon 0.03999708332859614, time 729.0, rides 142\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3575, reward 1074.0, memory_length 2000, epsilon 0.0399610859536004, time 723.0, rides 130\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 3576, reward 736.0, memory_length 2000, epsilon 0.03992512097624216, time 737.0, rides 129\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 3577, reward 737.0, memory_length 2000, epsilon 0.03988918836736354, time 730.0, rides 127\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3578, reward 1262.0, memory_length 2000, epsilon 0.039853288097832916, time 733.0, rides 137\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 3579, reward 1137.0, memory_length 2000, epsilon 0.03981742013854487, time 731.0, rides 140\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 3580, reward 619.0, memory_length 2000, epsilon 0.039781584460420176, time 727.0, rides 137\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 3581, reward 559.0, memory_length 2000, epsilon 0.0397457810344058, time 730.0, rides 127\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 3582, reward 802.0, memory_length 2000, epsilon 0.03971000983147483, time 726.0, rides 135\n",
      "Initial State is  [4, 2, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3583, reward 930.0, memory_length 2000, epsilon 0.039674270822626506, time 726.0, rides 131\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 3584, reward 1216.0, memory_length 2000, epsilon 0.03963856397888614, time 723.0, rides 146\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 3585, reward 701.0, memory_length 2000, epsilon 0.03960288927130514, time 728.0, rides 137\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 3586, reward 970.0, memory_length 2000, epsilon 0.03956724667096097, time 725.0, rides 138\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 3587, reward 872.0, memory_length 2000, epsilon 0.039531636148957106, time 740.0, rides 148\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 3588, reward 1035.0, memory_length 2000, epsilon 0.039496057676423044, time 724.0, rides 147\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 3589, reward 1001.0, memory_length 2000, epsilon 0.039460511224514265, time 726.0, rides 128\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 3590, reward 1150.0, memory_length 2000, epsilon 0.039424996764412204, time 731.0, rides 144\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3591, reward 723.0, memory_length 2000, epsilon 0.03938951426732423, time 726.0, rides 144\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3592, reward 1138.0, memory_length 2000, epsilon 0.03935406370448364, time 729.0, rides 144\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3593, reward 1030.0, memory_length 2000, epsilon 0.0393186450471496, time 726.0, rides 130\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 3594, reward 899.0, memory_length 2000, epsilon 0.03928325826660717, time 736.0, rides 139\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 3595, reward 652.0, memory_length 2000, epsilon 0.03924790333416722, time 733.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 3596, reward 1047.0, memory_length 2000, epsilon 0.03921258022116647, time 722.0, rides 134\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3597, reward 903.0, memory_length 2000, epsilon 0.03917728889896742, time 727.0, rides 129\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 3598, reward 1023.0, memory_length 2000, epsilon 0.03914202933895835, time 725.0, rides 131\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 3599, reward 1164.0, memory_length 2000, epsilon 0.03910680151255329, time 732.0, rides 134\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 3600, reward 812.0, memory_length 2000, epsilon 0.03907160539119199, time 730.0, rides 130\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3601, reward 908.0, memory_length 2000, epsilon 0.039036440946339915, time 727.0, rides 127\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 3602, reward 949.0, memory_length 2000, epsilon 0.039001308149488205, time 725.0, rides 144\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 3603, reward 852.0, memory_length 2000, epsilon 0.038966206972153666, time 724.0, rides 139\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 3604, reward 1066.0, memory_length 2000, epsilon 0.03893113738587873, time 730.0, rides 148\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3605, reward 905.0, memory_length 2000, epsilon 0.038896099362231436, time 736.0, rides 122\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3606, reward 896.0, memory_length 2000, epsilon 0.038861092872805425, time 732.0, rides 121\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 3607, reward 845.0, memory_length 2000, epsilon 0.0388261178892199, time 727.0, rides 134\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 3608, reward 1158.0, memory_length 2000, epsilon 0.0387911743831196, time 727.0, rides 142\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3609, reward 1196.0, memory_length 2000, epsilon 0.038756262326174795, time 727.0, rides 125\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 3610, reward 848.0, memory_length 2000, epsilon 0.038721381690081234, time 729.0, rides 131\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 3611, reward 927.0, memory_length 2000, epsilon 0.03868653244656016, time 725.0, rides 127\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 3612, reward 1339.0, memory_length 2000, epsilon 0.038651714567358254, time 725.0, rides 126\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 3613, reward 798.0, memory_length 2000, epsilon 0.03861692802424763, time 727.0, rides 133\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3614, reward 869.0, memory_length 2000, epsilon 0.03858217278902581, time 730.0, rides 132\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 3615, reward 1185.0, memory_length 2000, epsilon 0.038547448833515685, time 732.0, rides 133\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 3616, reward 1024.0, memory_length 2000, epsilon 0.03851275612956552, time 725.0, rides 143\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 3617, reward 643.0, memory_length 2000, epsilon 0.03847809464904891, time 737.0, rides 130\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 3618, reward 1062.0, memory_length 2000, epsilon 0.03844346436386476, time 723.0, rides 141\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 3619, reward 857.0, memory_length 2000, epsilon 0.038408865245937285, time 725.0, rides 137\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 3620, reward 1007.0, memory_length 2000, epsilon 0.03837429726721594, time 737.0, rides 133\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 3621, reward 1038.0, memory_length 2000, epsilon 0.038339760399675446, time 731.0, rides 129\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 3622, reward 890.0, memory_length 2000, epsilon 0.03830525461531574, time 731.0, rides 132\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 3623, reward 953.0, memory_length 2000, epsilon 0.038270779886161954, time 732.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 3624, reward 887.0, memory_length 2000, epsilon 0.038236336184264405, time 722.0, rides 125\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 3625, reward 926.0, memory_length 2000, epsilon 0.03820192348169857, time 741.0, rides 125\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 3626, reward 950.0, memory_length 2000, epsilon 0.03816754175056504, time 731.0, rides 129\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 3627, reward 913.0, memory_length 2000, epsilon 0.03813319096298953, time 732.0, rides 123\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 3628, reward 890.0, memory_length 2000, epsilon 0.038098871091122845, time 725.0, rides 130\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 3629, reward 839.0, memory_length 2000, epsilon 0.03806458210714083, time 731.0, rides 133\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 3630, reward 882.0, memory_length 2000, epsilon 0.0380303239832444, time 728.0, rides 124\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 3631, reward 969.0, memory_length 2000, epsilon 0.03799609669165948, time 735.0, rides 139\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 3632, reward 864.0, memory_length 2000, epsilon 0.03796190020463699, time 727.0, rides 133\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 3633, reward 867.0, memory_length 2000, epsilon 0.03792773449445282, time 728.0, rides 131\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 3634, reward 983.0, memory_length 2000, epsilon 0.03789359953340781, time 738.0, rides 129\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 3635, reward 756.0, memory_length 2000, epsilon 0.03785949529382775, time 730.0, rides 134\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 3636, reward 930.0, memory_length 2000, epsilon 0.037825421748063304, time 733.0, rides 134\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 3637, reward 934.0, memory_length 2000, epsilon 0.037791378868490044, time 726.0, rides 131\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 3638, reward 907.0, memory_length 2000, epsilon 0.0377573666275084, time 725.0, rides 140\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3639, reward 795.0, memory_length 2000, epsilon 0.037723384997543644, time 727.0, rides 133\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3640, reward 915.0, memory_length 2000, epsilon 0.037689433951045855, time 731.0, rides 125\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 3641, reward 1069.0, memory_length 2000, epsilon 0.03765551346048991, time 729.0, rides 141\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 3642, reward 1063.0, memory_length 2000, epsilon 0.03762162349837547, time 727.0, rides 121\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3643, reward 1202.0, memory_length 2000, epsilon 0.03758776403722693, time 732.0, rides 143\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 3644, reward 838.0, memory_length 2000, epsilon 0.03755393504959343, time 727.0, rides 144\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3645, reward 1061.0, memory_length 2000, epsilon 0.03752013650804879, time 727.0, rides 150\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3646, reward 1030.0, memory_length 2000, epsilon 0.03748636838519155, time 729.0, rides 130\n",
      "Initial State is  [2, 12, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3647, reward 1286.0, memory_length 2000, epsilon 0.03745263065364488, time 729.0, rides 127\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 3648, reward 1142.0, memory_length 2000, epsilon 0.0374189232860566, time 727.0, rides 140\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3649, reward 1039.0, memory_length 2000, epsilon 0.03738524625509915, time 740.0, rides 133\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 3650, reward 883.0, memory_length 2000, epsilon 0.03735159953346956, time 730.0, rides 136\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 3651, reward 972.0, memory_length 2000, epsilon 0.03731798309388944, time 734.0, rides 125\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 3652, reward 918.0, memory_length 2000, epsilon 0.037284396909104935, time 733.0, rides 144\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 3653, reward 856.0, memory_length 2000, epsilon 0.037250840951886736, time 732.0, rides 137\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 3654, reward 698.0, memory_length 2000, epsilon 0.037217315195030035, time 723.0, rides 142\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3655, reward 707.0, memory_length 2000, epsilon 0.03718381961135451, time 723.0, rides 128\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 3656, reward 1276.0, memory_length 2000, epsilon 0.03715035417370429, time 731.0, rides 147\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 3657, reward 932.0, memory_length 2000, epsilon 0.03711691885494796, time 729.0, rides 141\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3658, reward 835.0, memory_length 2000, epsilon 0.03708351362797851, time 735.0, rides 134\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 3659, reward 849.0, memory_length 2000, epsilon 0.037050138465713325, time 725.0, rides 143\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 3660, reward 1160.0, memory_length 2000, epsilon 0.03701679334109418, time 727.0, rides 132\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 3661, reward 1053.0, memory_length 2000, epsilon 0.036983478227087196, time 731.0, rides 127\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 3662, reward 999.0, memory_length 2000, epsilon 0.03695019309668282, time 735.0, rides 116\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 3663, reward 929.0, memory_length 2000, epsilon 0.036916937922895805, time 726.0, rides 132\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 3664, reward 760.0, memory_length 2000, epsilon 0.036883712678765196, time 725.0, rides 132\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 3665, reward 828.0, memory_length 2000, epsilon 0.036850517337354304, time 739.0, rides 145\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 3666, reward 1264.0, memory_length 2000, epsilon 0.036817351871750684, time 733.0, rides 133\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 3667, reward 787.0, memory_length 2000, epsilon 0.03678421625506611, time 723.0, rides 134\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 3668, reward 1000.0, memory_length 2000, epsilon 0.03675111046043655, time 733.0, rides 141\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 3669, reward 752.0, memory_length 2000, epsilon 0.036718034461022155, time 729.0, rides 125\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 3670, reward 979.0, memory_length 2000, epsilon 0.03668498823000724, time 729.0, rides 121\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 3671, reward 849.0, memory_length 2000, epsilon 0.03665197174060023, time 729.0, rides 140\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3672, reward 895.0, memory_length 2000, epsilon 0.03661898496603369, time 731.0, rides 148\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 3673, reward 683.0, memory_length 2000, epsilon 0.03658602787956426, time 732.0, rides 131\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 3674, reward 1026.0, memory_length 2000, epsilon 0.03655310045447265, time 731.0, rides 141\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 3675, reward 936.0, memory_length 2000, epsilon 0.036520202664063625, time 737.0, rides 133\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 3676, reward 803.0, memory_length 2000, epsilon 0.03648733448166597, time 733.0, rides 137\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 3677, reward 984.0, memory_length 2000, epsilon 0.036454495880632466, time 729.0, rides 128\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 3678, reward 1085.0, memory_length 2000, epsilon 0.0364216868343399, time 725.0, rides 144\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 3679, reward 958.0, memory_length 2000, epsilon 0.03638890731618899, time 735.0, rides 147\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 3680, reward 732.0, memory_length 2000, epsilon 0.03635615729960442, time 725.0, rides 140\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 3681, reward 1077.0, memory_length 2000, epsilon 0.036323436758034774, time 725.0, rides 142\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3682, reward 1020.0, memory_length 2000, epsilon 0.036290745664952544, time 729.0, rides 137\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 3683, reward 736.0, memory_length 2000, epsilon 0.036258083993854086, time 732.0, rides 127\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 3684, reward 937.0, memory_length 2000, epsilon 0.03622545171825962, time 726.0, rides 152\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 3685, reward 860.0, memory_length 2000, epsilon 0.03619284881171318, time 737.0, rides 141\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 3686, reward 896.0, memory_length 2000, epsilon 0.03616027524778264, time 736.0, rides 138\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 3687, reward 1135.0, memory_length 2000, epsilon 0.036127731000059636, time 723.0, rides 136\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 3688, reward 949.0, memory_length 2000, epsilon 0.03609521604215958, time 725.0, rides 140\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 3689, reward 1268.0, memory_length 2000, epsilon 0.03606273034772164, time 723.0, rides 133\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 3690, reward 1038.0, memory_length 2000, epsilon 0.036030273890408686, time 726.0, rides 147\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 3691, reward 832.0, memory_length 2000, epsilon 0.035997846643907316, time 724.0, rides 151\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 3692, reward 945.0, memory_length 2000, epsilon 0.0359654485819278, time 728.0, rides 135\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 3693, reward 798.0, memory_length 2000, epsilon 0.03593307967820407, time 735.0, rides 136\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 3694, reward 907.0, memory_length 2000, epsilon 0.03590073990649369, time 742.0, rides 130\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 3695, reward 863.0, memory_length 2000, epsilon 0.03586842924057784, time 728.0, rides 143\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 3696, reward 975.0, memory_length 2000, epsilon 0.035836147654261324, time 734.0, rides 139\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 3697, reward 1142.0, memory_length 2000, epsilon 0.03580389512137249, time 734.0, rides 133\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3698, reward 967.0, memory_length 2000, epsilon 0.03577167161576326, time 736.0, rides 126\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 3699, reward 934.0, memory_length 2000, epsilon 0.03573947711130907, time 726.0, rides 143\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 3700, reward 891.0, memory_length 2000, epsilon 0.035707311581908895, time 728.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 3701, reward 743.0, memory_length 2000, epsilon 0.035675175001485177, time 727.0, rides 133\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 3702, reward 636.0, memory_length 2000, epsilon 0.03564306734398384, time 735.0, rides 145\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 3703, reward 1194.0, memory_length 2000, epsilon 0.035610988583374255, time 730.0, rides 127\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 3704, reward 831.0, memory_length 2000, epsilon 0.03557893869364922, time 731.0, rides 128\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 3705, reward 1067.0, memory_length 2000, epsilon 0.035546917648824936, time 728.0, rides 126\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 3706, reward 884.0, memory_length 2000, epsilon 0.03551492542294099, time 737.0, rides 137\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 3707, reward 975.0, memory_length 2000, epsilon 0.03548296199006035, time 726.0, rides 129\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 3708, reward 819.0, memory_length 2000, epsilon 0.035451027324269295, time 729.0, rides 126\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 3709, reward 882.0, memory_length 2000, epsilon 0.035419121399677456, time 729.0, rides 122\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 3710, reward 939.0, memory_length 2000, epsilon 0.03538724419041774, time 722.0, rides 141\n",
      "Initial State is  [1, 21, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3711, reward 876.0, memory_length 2000, epsilon 0.03535539567064636, time 730.0, rides 136\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 3712, reward 864.0, memory_length 2000, epsilon 0.03532357581454278, time 733.0, rides 127\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 3713, reward 866.0, memory_length 2000, epsilon 0.035291784596309696, time 728.0, rides 139\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3714, reward 649.0, memory_length 2000, epsilon 0.035260021990173016, time 732.0, rides 133\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 3715, reward 1132.0, memory_length 2000, epsilon 0.03522828797038186, time 746.0, rides 120\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 3716, reward 957.0, memory_length 2000, epsilon 0.03519658251120852, time 729.0, rides 132\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3717, reward 698.0, memory_length 2000, epsilon 0.03516490558694843, time 726.0, rides 120\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3718, reward 1002.0, memory_length 2000, epsilon 0.035133257171920174, time 731.0, rides 124\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 3719, reward 824.0, memory_length 2000, epsilon 0.035101637240465444, time 729.0, rides 125\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 3720, reward 1029.0, memory_length 2000, epsilon 0.035070045766949026, time 724.0, rides 122\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 3721, reward 1112.0, memory_length 2000, epsilon 0.03503848272575877, time 727.0, rides 109\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 3722, reward 818.0, memory_length 2000, epsilon 0.035006948091305584, time 733.0, rides 136\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 3723, reward 704.0, memory_length 2000, epsilon 0.03497544183802341, time 724.0, rides 143\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 3724, reward 1203.0, memory_length 2000, epsilon 0.03494396394036919, time 730.0, rides 134\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 3725, reward 789.0, memory_length 2000, epsilon 0.034912514372822855, time 722.0, rides 129\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 3726, reward 747.0, memory_length 2000, epsilon 0.034881093109887316, time 727.0, rides 134\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 3727, reward 1107.0, memory_length 2000, epsilon 0.034849700126088415, time 723.0, rides 127\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 3728, reward 626.0, memory_length 2000, epsilon 0.03481833539597493, time 723.0, rides 142\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 3729, reward 792.0, memory_length 2000, epsilon 0.034786998894118557, time 729.0, rides 131\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 3730, reward 645.0, memory_length 2000, epsilon 0.03475569059511385, time 730.0, rides 135\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 3731, reward 935.0, memory_length 2000, epsilon 0.03472441047357825, time 727.0, rides 138\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3732, reward 954.0, memory_length 2000, epsilon 0.03469315850415203, time 724.0, rides 144\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 3733, reward 1207.0, memory_length 2000, epsilon 0.03466193466149829, time 729.0, rides 135\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 3734, reward 969.0, memory_length 2000, epsilon 0.034630738920302946, time 734.0, rides 148\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 3735, reward 1049.0, memory_length 2000, epsilon 0.03459957125527467, time 724.0, rides 140\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 3736, reward 1004.0, memory_length 2000, epsilon 0.034568431641144926, time 727.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 3737, reward 850.0, memory_length 2000, epsilon 0.034537320052667894, time 720.0, rides 139\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 3738, reward 964.0, memory_length 2000, epsilon 0.03450623646462049, time 724.0, rides 139\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3739, reward 974.0, memory_length 2000, epsilon 0.03447518085180233, time 725.0, rides 136\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 3740, reward 799.0, memory_length 2000, epsilon 0.03444415318903571, time 726.0, rides 139\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 3741, reward 1117.0, memory_length 2000, epsilon 0.03441315345116558, time 723.0, rides 117\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 3742, reward 881.0, memory_length 2000, epsilon 0.03438218161305953, time 729.0, rides 128\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 3743, reward 860.0, memory_length 2000, epsilon 0.03435123764960778, time 724.0, rides 124\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3744, reward 1320.0, memory_length 2000, epsilon 0.034320321535723126, time 724.0, rides 130\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 3745, reward 554.0, memory_length 2000, epsilon 0.034289433246340977, time 725.0, rides 138\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 3746, reward 591.0, memory_length 2000, epsilon 0.03425857275641927, time 727.0, rides 124\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3747, reward 883.0, memory_length 2000, epsilon 0.03422774004093849, time 734.0, rides 127\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 3748, reward 858.0, memory_length 2000, epsilon 0.034196935074901645, time 726.0, rides 120\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 3749, reward 1100.0, memory_length 2000, epsilon 0.03416615783333423, time 731.0, rides 138\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 3750, reward 1046.0, memory_length 2000, epsilon 0.03413540829128423, time 725.0, rides 126\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 3751, reward 1012.0, memory_length 2000, epsilon 0.03410468642382208, time 731.0, rides 117\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 3752, reward 863.0, memory_length 2000, epsilon 0.03407399220604063, time 729.0, rides 140\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3753, reward 781.0, memory_length 2000, epsilon 0.034043325613055196, time 730.0, rides 142\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 3754, reward 1030.0, memory_length 2000, epsilon 0.034012686620003445, time 723.0, rides 121\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 3755, reward 1084.0, memory_length 2000, epsilon 0.03398207520204544, time 731.0, rides 126\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 3756, reward 1238.0, memory_length 2000, epsilon 0.0339514913343636, time 727.0, rides 127\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 3757, reward 1001.0, memory_length 2000, epsilon 0.03392093499216267, time 735.0, rides 122\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 3758, reward 804.0, memory_length 2000, epsilon 0.033890406150669725, time 729.0, rides 140\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 3759, reward 1094.0, memory_length 2000, epsilon 0.03385990478513412, time 727.0, rides 144\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 3760, reward 804.0, memory_length 2000, epsilon 0.0338294308708275, time 730.0, rides 136\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 3761, reward 796.0, memory_length 2000, epsilon 0.033798984383043754, time 724.0, rides 133\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 3762, reward 893.0, memory_length 2000, epsilon 0.03376856529709901, time 738.0, rides 137\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 3763, reward 764.0, memory_length 2000, epsilon 0.03373817358833162, time 734.0, rides 141\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3764, reward 1368.0, memory_length 2000, epsilon 0.03370780923210212, time 734.0, rides 125\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 3765, reward 745.0, memory_length 2000, epsilon 0.033677472203793225, time 725.0, rides 130\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3766, reward 988.0, memory_length 2000, epsilon 0.03364716247880981, time 724.0, rides 146\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 3767, reward 1104.0, memory_length 2000, epsilon 0.033616880032578886, time 727.0, rides 124\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 3768, reward 1180.0, memory_length 2000, epsilon 0.03358662484054956, time 733.0, rides 122\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 3769, reward 567.0, memory_length 2000, epsilon 0.03355639687819307, time 732.0, rides 132\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3770, reward 668.0, memory_length 2000, epsilon 0.033526196121002695, time 726.0, rides 139\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3771, reward 792.0, memory_length 2000, epsilon 0.03349602254449379, time 728.0, rides 124\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 3772, reward 1239.0, memory_length 2000, epsilon 0.03346587612420374, time 730.0, rides 138\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 3773, reward 986.0, memory_length 2000, epsilon 0.03343575683569196, time 733.0, rides 136\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 3774, reward 864.0, memory_length 2000, epsilon 0.033405664654539834, time 727.0, rides 132\n",
      "Initial State is  [4, 6, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3775, reward 695.0, memory_length 2000, epsilon 0.03337559955635075, time 732.0, rides 128\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 3776, reward 829.0, memory_length 2000, epsilon 0.033345561516750034, time 732.0, rides 137\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 3777, reward 1155.0, memory_length 2000, epsilon 0.03331555051138496, time 731.0, rides 126\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 3778, reward 626.0, memory_length 2000, epsilon 0.033285566515924715, time 729.0, rides 119\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 3779, reward 558.0, memory_length 2000, epsilon 0.03325560950606038, time 725.0, rides 129\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3780, reward 760.0, memory_length 2000, epsilon 0.033225679457504924, time 724.0, rides 123\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 3781, reward 1196.0, memory_length 2000, epsilon 0.03319577634599317, time 737.0, rides 138\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 3782, reward 1008.0, memory_length 2000, epsilon 0.033165900147281775, time 731.0, rides 138\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 3783, reward 694.0, memory_length 2000, epsilon 0.03313605083714922, time 733.0, rides 131\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 3784, reward 463.0, memory_length 2000, epsilon 0.033106228391395785, time 725.0, rides 137\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 3785, reward 996.0, memory_length 2000, epsilon 0.03307643278584353, time 728.0, rides 139\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 3786, reward 941.0, memory_length 2000, epsilon 0.033046663996336274, time 738.0, rides 137\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 3787, reward 819.0, memory_length 2000, epsilon 0.03301692199873957, time 722.0, rides 140\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 3788, reward 715.0, memory_length 2000, epsilon 0.0329872067689407, time 727.0, rides 127\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3789, reward 670.0, memory_length 2000, epsilon 0.03295751828284865, time 734.0, rides 122\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 3790, reward 818.0, memory_length 2000, epsilon 0.032927856516394086, time 733.0, rides 152\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 3791, reward 967.0, memory_length 2000, epsilon 0.032898221445529334, time 726.0, rides 134\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 3792, reward 1410.0, memory_length 2000, epsilon 0.03286861304622836, time 728.0, rides 144\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 3793, reward 1122.0, memory_length 2000, epsilon 0.03283903129448675, time 727.0, rides 140\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 3794, reward 923.0, memory_length 2000, epsilon 0.03280947616632171, time 732.0, rides 138\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 3795, reward 869.0, memory_length 2000, epsilon 0.03277994763777202, time 732.0, rides 125\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 3796, reward 823.0, memory_length 2000, epsilon 0.03275044568489802, time 730.0, rides 137\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 3797, reward 1045.0, memory_length 2000, epsilon 0.03272097028378161, time 732.0, rides 142\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 3798, reward 969.0, memory_length 2000, epsilon 0.032691521410526204, time 738.0, rides 143\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 3799, reward 412.0, memory_length 2000, epsilon 0.03266209904125673, time 740.0, rides 133\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3800, reward 692.0, memory_length 2000, epsilon 0.032632703152119594, time 726.0, rides 134\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 3801, reward 607.0, memory_length 2000, epsilon 0.03260333371928269, time 727.0, rides 122\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 3802, reward 830.0, memory_length 2000, epsilon 0.03257399071893533, time 727.0, rides 133\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 3803, reward 1111.0, memory_length 2000, epsilon 0.03254467412728829, time 736.0, rides 148\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 3804, reward 969.0, memory_length 2000, epsilon 0.03251538392057373, time 728.0, rides 139\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 3805, reward 657.0, memory_length 2000, epsilon 0.03248612007504521, time 730.0, rides 138\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 3806, reward 1035.0, memory_length 2000, epsilon 0.03245688256697767, time 725.0, rides 143\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 3807, reward 1085.0, memory_length 2000, epsilon 0.032427671372667395, time 724.0, rides 147\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 3808, reward 1146.0, memory_length 2000, epsilon 0.03239848646843199, time 730.0, rides 135\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 3809, reward 930.0, memory_length 2000, epsilon 0.0323693278306104, time 740.0, rides 134\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 3810, reward 1086.0, memory_length 2000, epsilon 0.03234019543556285, time 721.0, rides 130\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 3811, reward 996.0, memory_length 2000, epsilon 0.03231108925967084, time 730.0, rides 152\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3812, reward 1190.0, memory_length 2000, epsilon 0.03228200927933714, time 727.0, rides 132\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 3813, reward 1093.0, memory_length 2000, epsilon 0.032252955470985736, time 741.0, rides 127\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 3814, reward 678.0, memory_length 2000, epsilon 0.03222392781106185, time 727.0, rides 145\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 3815, reward 789.0, memory_length 2000, epsilon 0.03219492627603189, time 731.0, rides 143\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 3816, reward 634.0, memory_length 2000, epsilon 0.03216595084238346, time 736.0, rides 132\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 3817, reward 886.0, memory_length 2000, epsilon 0.032137001486625315, time 734.0, rides 141\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 3818, reward 1148.0, memory_length 2000, epsilon 0.03210807818528735, time 725.0, rides 142\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 3819, reward 737.0, memory_length 2000, epsilon 0.032079180914920596, time 724.0, rides 119\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 3820, reward 886.0, memory_length 2000, epsilon 0.03205030965209717, time 726.0, rides 125\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 3821, reward 709.0, memory_length 2000, epsilon 0.03202146437341028, time 731.0, rides 123\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 3822, reward 1070.0, memory_length 2000, epsilon 0.03199264505547421, time 721.0, rides 124\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 3823, reward 943.0, memory_length 2000, epsilon 0.031963851674924285, time 733.0, rides 144\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 3824, reward 887.0, memory_length 2000, epsilon 0.031935084208416856, time 723.0, rides 134\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3825, reward 1022.0, memory_length 2000, epsilon 0.03190634263262928, time 731.0, rides 138\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 3826, reward 1091.0, memory_length 2000, epsilon 0.03187762692425991, time 732.0, rides 132\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 3827, reward 907.0, memory_length 2000, epsilon 0.031848937060028074, time 724.0, rides 131\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 3828, reward 996.0, memory_length 2000, epsilon 0.03182027301667405, time 727.0, rides 127\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 3829, reward 1059.0, memory_length 2000, epsilon 0.03179163477095904, time 728.0, rides 129\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 3830, reward 950.0, memory_length 2000, epsilon 0.031763022299665176, time 725.0, rides 144\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 3831, reward 1089.0, memory_length 2000, epsilon 0.031734435579595474, time 722.0, rides 143\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 3832, reward 1086.0, memory_length 2000, epsilon 0.03170587458757384, time 732.0, rides 130\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 3833, reward 1090.0, memory_length 2000, epsilon 0.03167733930044502, time 724.0, rides 142\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 3834, reward 762.0, memory_length 2000, epsilon 0.03164882969507462, time 734.0, rides 129\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 3835, reward 963.0, memory_length 2000, epsilon 0.03162034574834905, time 729.0, rides 133\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 3836, reward 991.0, memory_length 2000, epsilon 0.03159188743717554, time 734.0, rides 142\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 3837, reward 881.0, memory_length 2000, epsilon 0.03156345473848208, time 731.0, rides 135\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 3838, reward 809.0, memory_length 2000, epsilon 0.031535047629217446, time 724.0, rides 137\n",
      "Initial State is  [4, 15, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3839, reward 900.0, memory_length 2000, epsilon 0.03150666608635115, time 726.0, rides 122\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 3840, reward 970.0, memory_length 2000, epsilon 0.031478310086873434, time 738.0, rides 122\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 3841, reward 1053.0, memory_length 2000, epsilon 0.03144997960779525, time 727.0, rides 135\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 3842, reward 709.0, memory_length 2000, epsilon 0.031421674626148234, time 729.0, rides 127\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 3843, reward 1010.0, memory_length 2000, epsilon 0.0313933951189847, time 725.0, rides 134\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 3844, reward 961.0, memory_length 2000, epsilon 0.031365141063377615, time 734.0, rides 125\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 3845, reward 1010.0, memory_length 2000, epsilon 0.031336912436420575, time 728.0, rides 127\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 3846, reward 1033.0, memory_length 2000, epsilon 0.0313087092152278, time 721.0, rides 143\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 3847, reward 985.0, memory_length 2000, epsilon 0.031280531376934095, time 729.0, rides 124\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3848, reward 736.0, memory_length 2000, epsilon 0.03125237889869485, time 731.0, rides 128\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 3849, reward 814.0, memory_length 2000, epsilon 0.031224251757686027, time 726.0, rides 145\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 3850, reward 896.0, memory_length 2000, epsilon 0.03119614993110411, time 733.0, rides 140\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 3851, reward 1117.0, memory_length 2000, epsilon 0.031168073396166115, time 726.0, rides 142\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 3852, reward 1268.0, memory_length 2000, epsilon 0.031140022130109565, time 727.0, rides 133\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3853, reward 1185.0, memory_length 2000, epsilon 0.031111996110192466, time 730.0, rides 126\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 3854, reward 760.0, memory_length 2000, epsilon 0.031083995313693293, time 727.0, rides 134\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 3855, reward 1120.0, memory_length 2000, epsilon 0.031056019717910967, time 728.0, rides 141\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 3856, reward 907.0, memory_length 2000, epsilon 0.031028069300164846, time 724.0, rides 156\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 3857, reward 709.0, memory_length 2000, epsilon 0.031000144037794698, time 728.0, rides 122\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 3858, reward 582.0, memory_length 2000, epsilon 0.030972243908160682, time 728.0, rides 138\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 3859, reward 1146.0, memory_length 2000, epsilon 0.030944368888643336, time 731.0, rides 127\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 3860, reward 1051.0, memory_length 2000, epsilon 0.030916518956643557, time 731.0, rides 139\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 3861, reward 950.0, memory_length 2000, epsilon 0.030888694089582575, time 735.0, rides 135\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 3862, reward 1003.0, memory_length 2000, epsilon 0.03086089426490195, time 724.0, rides 131\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3863, reward 912.0, memory_length 2000, epsilon 0.03083311946006354, time 728.0, rides 133\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 3864, reward 744.0, memory_length 2000, epsilon 0.030805369652549482, time 737.0, rides 129\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 3865, reward 705.0, memory_length 2000, epsilon 0.03077764481986219, time 728.0, rides 143\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 3866, reward 821.0, memory_length 2000, epsilon 0.03074994493952431, time 730.0, rides 140\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 3867, reward 865.0, memory_length 2000, epsilon 0.03072226998907874, time 733.0, rides 140\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 3868, reward 997.0, memory_length 2000, epsilon 0.030694619946088568, time 726.0, rides 125\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 3869, reward 1290.0, memory_length 2000, epsilon 0.030666994788137086, time 722.0, rides 144\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 3870, reward 1232.0, memory_length 2000, epsilon 0.03063939449282776, time 728.0, rides 132\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 3871, reward 830.0, memory_length 2000, epsilon 0.030611819037784215, time 728.0, rides 132\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 3872, reward 840.0, memory_length 2000, epsilon 0.03058426840065021, time 726.0, rides 142\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 3873, reward 920.0, memory_length 2000, epsilon 0.030556742559089623, time 723.0, rides 135\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 3874, reward 865.0, memory_length 2000, epsilon 0.03052924149078644, time 725.0, rides 140\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 3875, reward 1110.0, memory_length 2000, epsilon 0.030501765173444734, time 731.0, rides 135\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 3876, reward 1166.0, memory_length 2000, epsilon 0.030474313584788634, time 730.0, rides 122\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 3877, reward 884.0, memory_length 2000, epsilon 0.030446886702562324, time 734.0, rides 127\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 3878, reward 970.0, memory_length 2000, epsilon 0.03041948450453002, time 724.0, rides 132\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 3879, reward 946.0, memory_length 2000, epsilon 0.03039210696847594, time 731.0, rides 123\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3880, reward 813.0, memory_length 2000, epsilon 0.030364754072204313, time 729.0, rides 138\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 3881, reward 668.0, memory_length 2000, epsilon 0.03033742579353933, time 735.0, rides 130\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 3882, reward 935.0, memory_length 2000, epsilon 0.030310122110325143, time 737.0, rides 128\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 3883, reward 695.0, memory_length 2000, epsilon 0.03028284300042585, time 731.0, rides 135\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3884, reward 669.0, memory_length 2000, epsilon 0.03025558844172547, time 727.0, rides 128\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 3885, reward 1051.0, memory_length 2000, epsilon 0.030228358412127915, time 736.0, rides 134\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 3886, reward 581.0, memory_length 2000, epsilon 0.030201152889557, time 730.0, rides 134\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 3887, reward 1079.0, memory_length 2000, epsilon 0.0301739718519564, time 725.0, rides 123\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 3888, reward 978.0, memory_length 2000, epsilon 0.030146815277289636, time 734.0, rides 142\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 3889, reward 875.0, memory_length 2000, epsilon 0.030119683143540073, time 730.0, rides 140\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 3890, reward 905.0, memory_length 2000, epsilon 0.030092575428710886, time 723.0, rides 137\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 3891, reward 969.0, memory_length 2000, epsilon 0.030065492110825046, time 728.0, rides 130\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 3892, reward 673.0, memory_length 2000, epsilon 0.030038433167925302, time 732.0, rides 122\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 3893, reward 922.0, memory_length 2000, epsilon 0.03001139857807417, time 722.0, rides 150\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 3894, reward 957.0, memory_length 2000, epsilon 0.0299843883193539, time 735.0, rides 130\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 3895, reward 950.0, memory_length 2000, epsilon 0.029957402369866482, time 725.0, rides 137\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 3896, reward 1173.0, memory_length 2000, epsilon 0.029930440707733603, time 728.0, rides 152\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 3897, reward 1090.0, memory_length 2000, epsilon 0.029903503311096643, time 731.0, rides 133\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 3898, reward 866.0, memory_length 2000, epsilon 0.029876590158116657, time 730.0, rides 134\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 3899, reward 1003.0, memory_length 2000, epsilon 0.029849701226974352, time 730.0, rides 137\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 3900, reward 758.0, memory_length 2000, epsilon 0.029822836495870076, time 728.0, rides 135\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 3901, reward 590.0, memory_length 2000, epsilon 0.029795995943023793, time 727.0, rides 131\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 3902, reward 788.0, memory_length 2000, epsilon 0.029769179546675073, time 723.0, rides 129\n",
      "Initial State is  [1, 9, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3903, reward 958.0, memory_length 2000, epsilon 0.029742387285083063, time 733.0, rides 138\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 3904, reward 1027.0, memory_length 2000, epsilon 0.029715619136526487, time 730.0, rides 136\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 3905, reward 1173.0, memory_length 2000, epsilon 0.029688875079303612, time 723.0, rides 124\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3906, reward 792.0, memory_length 2000, epsilon 0.02966215509173224, time 723.0, rides 136\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 3907, reward 701.0, memory_length 2000, epsilon 0.02963545915214968, time 729.0, rides 117\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 3908, reward 899.0, memory_length 2000, epsilon 0.029608787238912745, time 726.0, rides 119\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 3909, reward 994.0, memory_length 2000, epsilon 0.029582139330397723, time 727.0, rides 123\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 3910, reward 806.0, memory_length 2000, epsilon 0.029555515405000364, time 721.0, rides 117\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3911, reward 696.0, memory_length 2000, epsilon 0.029528915441135863, time 724.0, rides 134\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 3912, reward 1218.0, memory_length 2000, epsilon 0.02950233941723884, time 724.0, rides 139\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3913, reward 992.0, memory_length 2000, epsilon 0.029475787311763323, time 724.0, rides 146\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 3914, reward 929.0, memory_length 2000, epsilon 0.029449259103182735, time 730.0, rides 133\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 3915, reward 913.0, memory_length 2000, epsilon 0.02942275476998987, time 742.0, rides 130\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 3916, reward 912.0, memory_length 2000, epsilon 0.02939627429069688, time 727.0, rides 123\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 3917, reward 953.0, memory_length 2000, epsilon 0.029369817643835252, time 738.0, rides 124\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 3918, reward 899.0, memory_length 2000, epsilon 0.0293433848079558, time 725.0, rides 133\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 3919, reward 1197.0, memory_length 2000, epsilon 0.02931697576162864, time 729.0, rides 132\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 3920, reward 859.0, memory_length 2000, epsilon 0.029290590483443176, time 729.0, rides 135\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 3921, reward 887.0, memory_length 2000, epsilon 0.029264228952008076, time 733.0, rides 128\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 3922, reward 1095.0, memory_length 2000, epsilon 0.02923789114595127, time 729.0, rides 135\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 3923, reward 957.0, memory_length 2000, epsilon 0.029211577043919915, time 725.0, rides 129\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 3924, reward 1016.0, memory_length 2000, epsilon 0.02918528662458039, time 729.0, rides 129\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 3925, reward 751.0, memory_length 2000, epsilon 0.029159019866618265, time 730.0, rides 120\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 3926, reward 817.0, memory_length 2000, epsilon 0.029132776748738307, time 734.0, rides 122\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 3927, reward 932.0, memory_length 2000, epsilon 0.02910655724966444, time 727.0, rides 145\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 3928, reward 994.0, memory_length 2000, epsilon 0.029080361348139742, time 728.0, rides 127\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 3929, reward 807.0, memory_length 2000, epsilon 0.029054189022926415, time 728.0, rides 142\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 3930, reward 954.0, memory_length 2000, epsilon 0.02902804025280578, time 730.0, rides 146\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 3931, reward 616.0, memory_length 2000, epsilon 0.029001915016578256, time 729.0, rides 141\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 3932, reward 613.0, memory_length 2000, epsilon 0.028975813293063334, time 728.0, rides 121\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 3933, reward 950.0, memory_length 2000, epsilon 0.028949735061099578, time 732.0, rides 138\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 3934, reward 829.0, memory_length 2000, epsilon 0.028923680299544587, time 733.0, rides 144\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 3935, reward 847.0, memory_length 2000, epsilon 0.028897648987274996, time 732.0, rides 133\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 3936, reward 1070.0, memory_length 2000, epsilon 0.02887164110318645, time 726.0, rides 132\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 3937, reward 855.0, memory_length 2000, epsilon 0.02884565662619358, time 732.0, rides 140\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 3938, reward 1265.0, memory_length 2000, epsilon 0.028819695535230005, time 725.0, rides 122\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 3939, reward 958.0, memory_length 2000, epsilon 0.028793757809248297, time 729.0, rides 134\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 3940, reward 569.0, memory_length 2000, epsilon 0.028767843427219972, time 720.0, rides 136\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 3941, reward 971.0, memory_length 2000, epsilon 0.028741952368135475, time 731.0, rides 136\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 3942, reward 845.0, memory_length 2000, epsilon 0.028716084611004153, time 732.0, rides 125\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 3943, reward 866.0, memory_length 2000, epsilon 0.028690240134854248, time 724.0, rides 126\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 3944, reward 1021.0, memory_length 2000, epsilon 0.02866441891873288, time 736.0, rides 131\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 3945, reward 1140.0, memory_length 2000, epsilon 0.02863862094170602, time 728.0, rides 139\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 3946, reward 1020.0, memory_length 2000, epsilon 0.028612846182858483, time 737.0, rides 136\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 3947, reward 1118.0, memory_length 2000, epsilon 0.02858709462129391, time 729.0, rides 138\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 3948, reward 927.0, memory_length 2000, epsilon 0.028561366236134745, time 724.0, rides 139\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 3949, reward 1279.0, memory_length 2000, epsilon 0.028535661006522224, time 729.0, rides 134\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 3950, reward 967.0, memory_length 2000, epsilon 0.028509978911616354, time 727.0, rides 132\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 3951, reward 1009.0, memory_length 2000, epsilon 0.0284843199305959, time 726.0, rides 135\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 3952, reward 1032.0, memory_length 2000, epsilon 0.028458684042658364, time 724.0, rides 143\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 3953, reward 1041.0, memory_length 2000, epsilon 0.028433071227019973, time 728.0, rides 126\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 3954, reward 669.0, memory_length 2000, epsilon 0.028407481462915656, time 735.0, rides 142\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 3955, reward 814.0, memory_length 2000, epsilon 0.02838191472959903, time 735.0, rides 133\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 3956, reward 650.0, memory_length 2000, epsilon 0.028356371006342394, time 723.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 3957, reward 789.0, memory_length 2000, epsilon 0.028330850272436685, time 728.0, rides 124\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 3958, reward 779.0, memory_length 2000, epsilon 0.028305352507191493, time 726.0, rides 130\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 3959, reward 904.0, memory_length 2000, epsilon 0.02827987768993502, time 724.0, rides 135\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 3960, reward 1162.0, memory_length 2000, epsilon 0.02825442580001408, time 723.0, rides 126\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 3961, reward 963.0, memory_length 2000, epsilon 0.028228996816794066, time 735.0, rides 131\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 3962, reward 1165.0, memory_length 2000, epsilon 0.02820359071965895, time 730.0, rides 131\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 3963, reward 955.0, memory_length 2000, epsilon 0.028178207488011257, time 729.0, rides 128\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 3964, reward 1003.0, memory_length 2000, epsilon 0.028152847101272045, time 726.0, rides 141\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 3965, reward 861.0, memory_length 2000, epsilon 0.0281275095388809, time 727.0, rides 144\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 3966, reward 1109.0, memory_length 2000, epsilon 0.028102194780295908, time 733.0, rides 126\n",
      "Initial State is  [3, 21, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 3967, reward 915.0, memory_length 2000, epsilon 0.028076902804993642, time 722.0, rides 136\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 3968, reward 987.0, memory_length 2000, epsilon 0.028051633592469146, time 730.0, rides 143\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 3969, reward 1247.0, memory_length 2000, epsilon 0.028026387122235923, time 731.0, rides 130\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3970, reward 773.0, memory_length 2000, epsilon 0.02800116337382591, time 731.0, rides 130\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 3971, reward 885.0, memory_length 2000, epsilon 0.027975962326789467, time 729.0, rides 141\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 3972, reward 869.0, memory_length 2000, epsilon 0.027950783960695356, time 728.0, rides 135\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 3973, reward 1148.0, memory_length 2000, epsilon 0.02792562825513073, time 729.0, rides 124\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 3974, reward 616.0, memory_length 2000, epsilon 0.027900495189701113, time 729.0, rides 116\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 3975, reward 1114.0, memory_length 2000, epsilon 0.027875384744030382, time 726.0, rides 132\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 3976, reward 855.0, memory_length 2000, epsilon 0.027850296897760755, time 738.0, rides 122\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 3977, reward 1316.0, memory_length 2000, epsilon 0.02782523163055277, time 736.0, rides 139\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 3978, reward 750.0, memory_length 2000, epsilon 0.02780018892208527, time 727.0, rides 134\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 3979, reward 813.0, memory_length 2000, epsilon 0.027775168752055393, time 736.0, rides 136\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 3980, reward 1017.0, memory_length 2000, epsilon 0.027750171100178543, time 728.0, rides 133\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 3981, reward 956.0, memory_length 2000, epsilon 0.027725195946188382, time 728.0, rides 130\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 3982, reward 1155.0, memory_length 2000, epsilon 0.027700243269836812, time 732.0, rides 141\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 3983, reward 967.0, memory_length 2000, epsilon 0.02767531305089396, time 737.0, rides 146\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 3984, reward 1090.0, memory_length 2000, epsilon 0.027650405269148155, time 726.0, rides 140\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 3985, reward 958.0, memory_length 2000, epsilon 0.02762551990440592, time 727.0, rides 147\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 3986, reward 1079.0, memory_length 2000, epsilon 0.027600656936491955, time 730.0, rides 125\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 3987, reward 790.0, memory_length 2000, epsilon 0.02757581634524911, time 726.0, rides 135\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 3988, reward 912.0, memory_length 2000, epsilon 0.027550998110538384, time 726.0, rides 133\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 3989, reward 668.0, memory_length 2000, epsilon 0.0275262022122389, time 725.0, rides 141\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 3990, reward 1204.0, memory_length 2000, epsilon 0.027501428630247883, time 724.0, rides 137\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 3991, reward 1347.0, memory_length 2000, epsilon 0.02747667734448066, time 728.0, rides 129\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 3992, reward 1226.0, memory_length 2000, epsilon 0.027451948334870628, time 734.0, rides 130\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 3993, reward 891.0, memory_length 2000, epsilon 0.027427241581369242, time 731.0, rides 123\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 3994, reward 778.0, memory_length 2000, epsilon 0.02740255706394601, time 732.0, rides 125\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 3995, reward 1154.0, memory_length 2000, epsilon 0.027377894762588458, time 727.0, rides 132\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 3996, reward 1024.0, memory_length 2000, epsilon 0.027353254657302126, time 735.0, rides 120\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 3997, reward 969.0, memory_length 2000, epsilon 0.027328636728110554, time 732.0, rides 129\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 3998, reward 971.0, memory_length 2000, epsilon 0.027304040955055255, time 731.0, rides 126\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 3999, reward 990.0, memory_length 2000, epsilon 0.027279467318195704, time 724.0, rides 139\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 4000, reward 843.0, memory_length 2000, epsilon 0.027254915797609327, time 727.0, rides 136\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4001, reward 789.0, memory_length 2000, epsilon 0.02723038637339148, time 732.0, rides 128\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 4002, reward 838.0, memory_length 2000, epsilon 0.027205879025655428, time 722.0, rides 134\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 4003, reward 1090.0, memory_length 2000, epsilon 0.02718139373453234, time 727.0, rides 135\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 4004, reward 639.0, memory_length 2000, epsilon 0.02715693048017126, time 724.0, rides 136\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 4005, reward 989.0, memory_length 2000, epsilon 0.027132489242739106, time 734.0, rides 132\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 4006, reward 847.0, memory_length 2000, epsilon 0.02710807000242064, time 722.0, rides 136\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 4007, reward 962.0, memory_length 2000, epsilon 0.027083672739418464, time 727.0, rides 143\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 4008, reward 1012.0, memory_length 2000, epsilon 0.027059297433952988, time 727.0, rides 139\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 4009, reward 906.0, memory_length 2000, epsilon 0.02703494406626243, time 733.0, rides 129\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 4010, reward 876.0, memory_length 2000, epsilon 0.027010612616602796, time 726.0, rides 121\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4011, reward 1010.0, memory_length 2000, epsilon 0.026986303065247852, time 726.0, rides 128\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 4012, reward 893.0, memory_length 2000, epsilon 0.026962015392489127, time 726.0, rides 138\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 4013, reward 982.0, memory_length 2000, epsilon 0.026937749578635886, time 734.0, rides 143\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 4014, reward 971.0, memory_length 2000, epsilon 0.026913505604015113, time 731.0, rides 132\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 4015, reward 766.0, memory_length 2000, epsilon 0.0268892834489715, time 727.0, rides 115\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 4016, reward 934.0, memory_length 2000, epsilon 0.026865083093867426, time 723.0, rides 121\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 4017, reward 743.0, memory_length 2000, epsilon 0.026840904519082946, time 724.0, rides 127\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4018, reward 772.0, memory_length 2000, epsilon 0.02681674770501577, time 730.0, rides 133\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4019, reward 1051.0, memory_length 2000, epsilon 0.026792612632081256, time 739.0, rides 134\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 4020, reward 927.0, memory_length 2000, epsilon 0.02676849928071238, time 730.0, rides 132\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 4021, reward 891.0, memory_length 2000, epsilon 0.02674440763135974, time 726.0, rides 126\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 4022, reward 1026.0, memory_length 2000, epsilon 0.026720337664491518, time 724.0, rides 130\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 4023, reward 823.0, memory_length 2000, epsilon 0.026696289360593473, time 728.0, rides 134\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 4024, reward 873.0, memory_length 2000, epsilon 0.02667226270016894, time 732.0, rides 137\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 4025, reward 843.0, memory_length 2000, epsilon 0.026648257663738788, time 724.0, rides 150\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4026, reward 815.0, memory_length 2000, epsilon 0.02662427423184142, time 734.0, rides 133\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 4027, reward 880.0, memory_length 2000, epsilon 0.026600312385032764, time 726.0, rides 132\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 4028, reward 907.0, memory_length 2000, epsilon 0.026576372103886234, time 724.0, rides 139\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4029, reward 1004.0, memory_length 2000, epsilon 0.026552453368992736, time 723.0, rides 133\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 4030, reward 1089.0, memory_length 2000, epsilon 0.026528556160960642, time 726.0, rides 137\n",
      "Initial State is  [3, 12, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4031, reward 900.0, memory_length 2000, epsilon 0.026504680460415778, time 726.0, rides 131\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 4032, reward 975.0, memory_length 2000, epsilon 0.026480826248001403, time 730.0, rides 141\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 4033, reward 773.0, memory_length 2000, epsilon 0.0264569935043782, time 727.0, rides 128\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 4034, reward 858.0, memory_length 2000, epsilon 0.02643318221022426, time 734.0, rides 128\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 4035, reward 825.0, memory_length 2000, epsilon 0.02640939234623506, time 726.0, rides 127\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4036, reward 868.0, memory_length 2000, epsilon 0.026385623893123447, time 725.0, rides 148\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 4037, reward 841.0, memory_length 2000, epsilon 0.026361876831619637, time 734.0, rides 116\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 4038, reward 722.0, memory_length 2000, epsilon 0.026338151142471178, time 731.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 4039, reward 700.0, memory_length 2000, epsilon 0.026314446806442952, time 726.0, rides 114\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4040, reward 809.0, memory_length 2000, epsilon 0.026290763804317153, time 733.0, rides 132\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 4041, reward 975.0, memory_length 2000, epsilon 0.026267102116893266, time 729.0, rides 133\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4042, reward 1070.0, memory_length 2000, epsilon 0.026243461724988062, time 735.0, rides 127\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4043, reward 861.0, memory_length 2000, epsilon 0.02621984260943557, time 723.0, rides 124\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 4044, reward 792.0, memory_length 2000, epsilon 0.02619624475108708, time 726.0, rides 136\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 4045, reward 992.0, memory_length 2000, epsilon 0.0261726681308111, time 727.0, rides 129\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4046, reward 765.0, memory_length 2000, epsilon 0.02614911272949337, time 723.0, rides 124\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 4047, reward 1019.0, memory_length 2000, epsilon 0.026125578528036826, time 723.0, rides 132\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 4048, reward 921.0, memory_length 2000, epsilon 0.02610206550736159, time 731.0, rides 135\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4049, reward 902.0, memory_length 2000, epsilon 0.026078573648404966, time 738.0, rides 136\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 4050, reward 671.0, memory_length 2000, epsilon 0.0260551029321214, time 730.0, rides 131\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 4051, reward 908.0, memory_length 2000, epsilon 0.026031653339482493, time 725.0, rides 132\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 4052, reward 951.0, memory_length 2000, epsilon 0.02600822485147696, time 724.0, rides 133\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 4053, reward 803.0, memory_length 2000, epsilon 0.025984817449110627, time 720.0, rides 114\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4054, reward 778.0, memory_length 2000, epsilon 0.025961431113406427, time 726.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 4055, reward 996.0, memory_length 2000, epsilon 0.02593806582540436, time 726.0, rides 130\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4056, reward 730.0, memory_length 2000, epsilon 0.025914721566161494, time 724.0, rides 113\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 4057, reward 1135.0, memory_length 2000, epsilon 0.025891398316751947, time 727.0, rides 133\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 4058, reward 957.0, memory_length 2000, epsilon 0.02586809605826687, time 727.0, rides 124\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 4059, reward 621.0, memory_length 2000, epsilon 0.02584481477181443, time 735.0, rides 131\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 4060, reward 456.0, memory_length 2000, epsilon 0.025821554438519797, time 722.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4061, reward 932.0, memory_length 2000, epsilon 0.02579831503952513, time 732.0, rides 148\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 4062, reward 930.0, memory_length 2000, epsilon 0.025775096555989554, time 726.0, rides 133\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 4063, reward 903.0, memory_length 2000, epsilon 0.025751898969089162, time 727.0, rides 134\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 4064, reward 623.0, memory_length 2000, epsilon 0.025728722260016983, time 736.0, rides 122\n",
      "Initial State is  [4, 11, 2]\n",
      "episode 4065, reward 1050.0, memory_length 2000, epsilon 0.025705566409982967, time 729.0, rides 142\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 4066, reward 1033.0, memory_length 2000, epsilon 0.025682431400213982, time 724.0, rides 123\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 4067, reward 1115.0, memory_length 2000, epsilon 0.02565931721195379, time 731.0, rides 127\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 4068, reward 1032.0, memory_length 2000, epsilon 0.02563622382646303, time 735.0, rides 134\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 4069, reward 1016.0, memory_length 2000, epsilon 0.025613151225019212, time 729.0, rides 129\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 4070, reward 1057.0, memory_length 2000, epsilon 0.025590099388916696, time 727.0, rides 132\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 4071, reward 904.0, memory_length 2000, epsilon 0.02556706829946667, time 722.0, rides 129\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 4072, reward 1133.0, memory_length 2000, epsilon 0.025544057937997147, time 735.0, rides 143\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4073, reward 783.0, memory_length 2000, epsilon 0.02552106828585295, time 725.0, rides 115\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4074, reward 1159.0, memory_length 2000, epsilon 0.02549809932439568, time 733.0, rides 122\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 4075, reward 971.0, memory_length 2000, epsilon 0.025475151035003724, time 733.0, rides 127\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 4076, reward 816.0, memory_length 2000, epsilon 0.02545222339907222, time 736.0, rides 133\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 4077, reward 1041.0, memory_length 2000, epsilon 0.025429316398013053, time 723.0, rides 137\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 4078, reward 927.0, memory_length 2000, epsilon 0.025406430013254842, time 732.0, rides 131\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 4079, reward 986.0, memory_length 2000, epsilon 0.025383564226242914, time 730.0, rides 128\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 4080, reward 931.0, memory_length 2000, epsilon 0.025360719018439296, time 726.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4081, reward 711.0, memory_length 2000, epsilon 0.0253378943713227, time 728.0, rides 132\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 4082, reward 690.0, memory_length 2000, epsilon 0.02531509026638851, time 727.0, rides 127\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 4083, reward 803.0, memory_length 2000, epsilon 0.02529230668514876, time 723.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4084, reward 732.0, memory_length 2000, epsilon 0.02526954360913213, time 726.0, rides 122\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 4085, reward 940.0, memory_length 2000, epsilon 0.02524680101988391, time 729.0, rides 125\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 4086, reward 867.0, memory_length 2000, epsilon 0.025224078898966013, time 723.0, rides 127\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 4087, reward 908.0, memory_length 2000, epsilon 0.025201377227956942, time 722.0, rides 133\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 4088, reward 1003.0, memory_length 2000, epsilon 0.02517869598845178, time 727.0, rides 135\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 4089, reward 934.0, memory_length 2000, epsilon 0.025156035162062173, time 732.0, rides 125\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 4090, reward 1043.0, memory_length 2000, epsilon 0.025133394730416318, time 733.0, rides 124\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 4091, reward 950.0, memory_length 2000, epsilon 0.02511077467515894, time 726.0, rides 129\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 4092, reward 1206.0, memory_length 2000, epsilon 0.025088174977951298, time 732.0, rides 128\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 4093, reward 778.0, memory_length 2000, epsilon 0.025065595620471143, time 725.0, rides 128\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 4094, reward 939.0, memory_length 2000, epsilon 0.025043036584412717, time 731.0, rides 116\n",
      "Initial State is  [0, 12, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4095, reward 1086.0, memory_length 2000, epsilon 0.025020497851486745, time 725.0, rides 128\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 4096, reward 802.0, memory_length 2000, epsilon 0.024997979403420408, time 730.0, rides 125\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 4097, reward 1060.0, memory_length 2000, epsilon 0.02497548122195733, time 736.0, rides 119\n",
      "Initial State is  [4, 2, 0]\n",
      "episode 4098, reward 839.0, memory_length 2000, epsilon 0.024953003288857568, time 731.0, rides 133\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4099, reward 898.0, memory_length 2000, epsilon 0.024930545585897596, time 730.0, rides 118\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 4100, reward 765.0, memory_length 2000, epsilon 0.024908108094870287, time 726.0, rides 128\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 4101, reward 830.0, memory_length 2000, epsilon 0.024885690797584903, time 725.0, rides 130\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 4102, reward 802.0, memory_length 2000, epsilon 0.024863293675867076, time 737.0, rides 134\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4103, reward 671.0, memory_length 2000, epsilon 0.024840916711558796, time 724.0, rides 124\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4104, reward 1000.0, memory_length 2000, epsilon 0.024818559886518394, time 725.0, rides 132\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 4105, reward 1130.0, memory_length 2000, epsilon 0.024796223182620526, time 721.0, rides 125\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4106, reward 835.0, memory_length 2000, epsilon 0.024773906581756166, time 724.0, rides 124\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 4107, reward 977.0, memory_length 2000, epsilon 0.024751610065832586, time 728.0, rides 125\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 4108, reward 849.0, memory_length 2000, epsilon 0.024729333616773336, time 725.0, rides 134\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 4109, reward 1010.0, memory_length 2000, epsilon 0.024707077216518242, time 724.0, rides 137\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 4110, reward 1091.0, memory_length 2000, epsilon 0.024684840847023375, time 729.0, rides 126\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 4111, reward 986.0, memory_length 2000, epsilon 0.02466262449026105, time 730.0, rides 122\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4112, reward 1167.0, memory_length 2000, epsilon 0.024640428128219816, time 725.0, rides 141\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4113, reward 779.0, memory_length 2000, epsilon 0.02461825174290442, time 735.0, rides 127\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 4114, reward 967.0, memory_length 2000, epsilon 0.024596095316335807, time 731.0, rides 125\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 4115, reward 1106.0, memory_length 2000, epsilon 0.024573958830551103, time 738.0, rides 137\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 4116, reward 963.0, memory_length 2000, epsilon 0.024551842267603607, time 729.0, rides 134\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 4117, reward 839.0, memory_length 2000, epsilon 0.024529745609562763, time 727.0, rides 149\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 4118, reward 976.0, memory_length 2000, epsilon 0.024507668838514157, time 733.0, rides 142\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4119, reward 687.0, memory_length 2000, epsilon 0.024485611936559494, time 722.0, rides 123\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 4120, reward 899.0, memory_length 2000, epsilon 0.02446357488581659, time 723.0, rides 120\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4121, reward 791.0, memory_length 2000, epsilon 0.024441557668419354, time 732.0, rides 120\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 4122, reward 1030.0, memory_length 2000, epsilon 0.024419560266517776, time 735.0, rides 124\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 4123, reward 783.0, memory_length 2000, epsilon 0.02439758266227791, time 725.0, rides 118\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 4124, reward 704.0, memory_length 2000, epsilon 0.02437562483788186, time 726.0, rides 141\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 4125, reward 797.0, memory_length 2000, epsilon 0.024353686775527766, time 733.0, rides 122\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4126, reward 976.0, memory_length 2000, epsilon 0.024331768457429792, time 728.0, rides 129\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 4127, reward 916.0, memory_length 2000, epsilon 0.024309869865818106, time 725.0, rides 125\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 4128, reward 969.0, memory_length 2000, epsilon 0.024287990982938868, time 730.0, rides 136\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 4129, reward 1104.0, memory_length 2000, epsilon 0.024266131791054222, time 728.0, rides 130\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 4130, reward 809.0, memory_length 2000, epsilon 0.024244292272442274, time 724.0, rides 131\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4131, reward 979.0, memory_length 2000, epsilon 0.024222472409397077, time 726.0, rides 136\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 4132, reward 745.0, memory_length 2000, epsilon 0.024200672184228618, time 723.0, rides 129\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 4133, reward 765.0, memory_length 2000, epsilon 0.024178891579262812, time 732.0, rides 126\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 4134, reward 892.0, memory_length 2000, epsilon 0.024157130576841476, time 725.0, rides 121\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4135, reward 806.0, memory_length 2000, epsilon 0.02413538915932232, time 724.0, rides 117\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 4136, reward 1176.0, memory_length 2000, epsilon 0.024113667309078927, time 730.0, rides 123\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 4137, reward 855.0, memory_length 2000, epsilon 0.024091965008500756, time 733.0, rides 126\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 4138, reward 838.0, memory_length 2000, epsilon 0.024070282239993104, time 724.0, rides 128\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 4139, reward 861.0, memory_length 2000, epsilon 0.02404861898597711, time 724.0, rides 133\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 4140, reward 911.0, memory_length 2000, epsilon 0.02402697522888973, time 727.0, rides 136\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 4141, reward 658.0, memory_length 2000, epsilon 0.024005350951183727, time 725.0, rides 130\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 4142, reward 991.0, memory_length 2000, epsilon 0.023983746135327663, time 735.0, rides 124\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 4143, reward 840.0, memory_length 2000, epsilon 0.02396216076380587, time 726.0, rides 117\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 4144, reward 906.0, memory_length 2000, epsilon 0.023940594819118442, time 720.0, rides 128\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 4145, reward 874.0, memory_length 2000, epsilon 0.023919048283781236, time 728.0, rides 137\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4146, reward 1126.0, memory_length 2000, epsilon 0.023897521140325832, time 729.0, rides 137\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4147, reward 1078.0, memory_length 2000, epsilon 0.023876013371299538, time 734.0, rides 134\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 4148, reward 784.0, memory_length 2000, epsilon 0.023854524959265367, time 727.0, rides 135\n",
      "Initial State is  [1, 12, 5]\n",
      "episode 4149, reward 1073.0, memory_length 2000, epsilon 0.023833055886802026, time 726.0, rides 132\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 4150, reward 1164.0, memory_length 2000, epsilon 0.023811606136503904, time 733.0, rides 120\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 4151, reward 621.0, memory_length 2000, epsilon 0.02379017569098105, time 727.0, rides 121\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4152, reward 887.0, memory_length 2000, epsilon 0.023768764532859168, time 742.0, rides 125\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 4153, reward 697.0, memory_length 2000, epsilon 0.023747372644779594, time 730.0, rides 128\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 4154, reward 819.0, memory_length 2000, epsilon 0.02372600000939929, time 722.0, rides 128\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 4155, reward 945.0, memory_length 2000, epsilon 0.023704646609390832, time 732.0, rides 125\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 4156, reward 816.0, memory_length 2000, epsilon 0.02368331242744238, time 724.0, rides 132\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 4157, reward 1320.0, memory_length 2000, epsilon 0.023661997446257684, time 732.0, rides 129\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4158, reward 876.0, memory_length 2000, epsilon 0.023640701648556053, time 723.0, rides 136\n",
      "Initial State is  [0, 2, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4159, reward 1018.0, memory_length 2000, epsilon 0.023619425017072353, time 726.0, rides 140\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4160, reward 1010.0, memory_length 2000, epsilon 0.02359816753455699, time 732.0, rides 138\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 4161, reward 1143.0, memory_length 2000, epsilon 0.023576929183775887, time 729.0, rides 135\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 4162, reward 820.0, memory_length 2000, epsilon 0.023555709947510488, time 729.0, rides 133\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 4163, reward 942.0, memory_length 2000, epsilon 0.02353450980855773, time 738.0, rides 145\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 4164, reward 942.0, memory_length 2000, epsilon 0.023513328749730028, time 732.0, rides 126\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 4165, reward 802.0, memory_length 2000, epsilon 0.02349216675385527, time 726.0, rides 142\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 4166, reward 1025.0, memory_length 2000, epsilon 0.023471023803776803, time 729.0, rides 138\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 4167, reward 536.0, memory_length 2000, epsilon 0.023449899882353402, time 736.0, rides 116\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 4168, reward 998.0, memory_length 2000, epsilon 0.023428794972459283, time 733.0, rides 146\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 4169, reward 1151.0, memory_length 2000, epsilon 0.02340770905698407, time 726.0, rides 136\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 4170, reward 561.0, memory_length 2000, epsilon 0.023386642118832783, time 727.0, rides 131\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4171, reward 1246.0, memory_length 2000, epsilon 0.023365594140925833, time 722.0, rides 127\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 4172, reward 828.0, memory_length 2000, epsilon 0.023344565106199, time 728.0, rides 136\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 4173, reward 547.0, memory_length 2000, epsilon 0.02332355499760342, time 726.0, rides 123\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 4174, reward 806.0, memory_length 2000, epsilon 0.023302563798105577, time 738.0, rides 138\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 4175, reward 1194.0, memory_length 2000, epsilon 0.02328159149068728, time 725.0, rides 145\n",
      "Initial State is  [2, 5, 6]\n",
      "episode 4176, reward 1056.0, memory_length 2000, epsilon 0.023260638058345662, time 731.0, rides 141\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 4177, reward 934.0, memory_length 2000, epsilon 0.02323970348409315, time 733.0, rides 138\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 4178, reward 743.0, memory_length 2000, epsilon 0.023218787750957467, time 733.0, rides 135\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 4179, reward 1007.0, memory_length 2000, epsilon 0.023197890841981605, time 725.0, rides 131\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4180, reward 1267.0, memory_length 2000, epsilon 0.02317701274022382, time 730.0, rides 154\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 4181, reward 1069.0, memory_length 2000, epsilon 0.02315615342875762, time 735.0, rides 140\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4182, reward 989.0, memory_length 2000, epsilon 0.023135312890671736, time 728.0, rides 132\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 4183, reward 684.0, memory_length 2000, epsilon 0.023114491109070132, time 727.0, rides 141\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 4184, reward 1240.0, memory_length 2000, epsilon 0.02309368806707197, time 731.0, rides 156\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 4185, reward 857.0, memory_length 2000, epsilon 0.023072903747811607, time 729.0, rides 134\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 4186, reward 807.0, memory_length 2000, epsilon 0.023052138134438575, time 729.0, rides 125\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 4187, reward 883.0, memory_length 2000, epsilon 0.02303139121011758, time 727.0, rides 122\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 4188, reward 760.0, memory_length 2000, epsilon 0.023010662958028474, time 722.0, rides 129\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 4189, reward 1009.0, memory_length 2000, epsilon 0.022989953361366246, time 723.0, rides 124\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 4190, reward 844.0, memory_length 2000, epsilon 0.022969262403341018, time 729.0, rides 137\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 4191, reward 400.0, memory_length 2000, epsilon 0.02294859006717801, time 733.0, rides 132\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 4192, reward 1185.0, memory_length 2000, epsilon 0.02292793633611755, time 727.0, rides 131\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 4193, reward 969.0, memory_length 2000, epsilon 0.022907301193415042, time 734.0, rides 128\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4194, reward 1165.0, memory_length 2000, epsilon 0.022886684622340968, time 727.0, rides 123\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 4195, reward 1028.0, memory_length 2000, epsilon 0.02286608660618086, time 731.0, rides 123\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 4196, reward 921.0, memory_length 2000, epsilon 0.0228455071282353, time 726.0, rides 130\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 4197, reward 922.0, memory_length 2000, epsilon 0.022824946171819887, time 732.0, rides 132\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 4198, reward 1022.0, memory_length 2000, epsilon 0.022804403720265248, time 736.0, rides 128\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 4199, reward 1045.0, memory_length 2000, epsilon 0.022783879756917008, time 730.0, rides 127\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 4200, reward 877.0, memory_length 2000, epsilon 0.022763374265135784, time 728.0, rides 134\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 4201, reward 1128.0, memory_length 2000, epsilon 0.022742887228297162, time 729.0, rides 148\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4202, reward 931.0, memory_length 2000, epsilon 0.022722418629791696, time 730.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 4203, reward 1093.0, memory_length 2000, epsilon 0.022701968453024884, time 728.0, rides 115\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4204, reward 940.0, memory_length 2000, epsilon 0.02268153668141716, time 724.0, rides 141\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 4205, reward 823.0, memory_length 2000, epsilon 0.022661123298403887, time 724.0, rides 122\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 4206, reward 881.0, memory_length 2000, epsilon 0.022640728287435324, time 730.0, rides 137\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 4207, reward 853.0, memory_length 2000, epsilon 0.02262035163197663, time 737.0, rides 120\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4208, reward 1037.0, memory_length 2000, epsilon 0.02259999331550785, time 732.0, rides 136\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 4209, reward 974.0, memory_length 2000, epsilon 0.022579653321523892, time 736.0, rides 123\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 4210, reward 1000.0, memory_length 2000, epsilon 0.022559331633534522, time 730.0, rides 129\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 4211, reward 720.0, memory_length 2000, epsilon 0.022539028235064342, time 722.0, rides 129\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 4212, reward 1102.0, memory_length 2000, epsilon 0.022518743109652784, time 721.0, rides 128\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4213, reward 860.0, memory_length 2000, epsilon 0.022498476240854097, time 727.0, rides 140\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 4214, reward 669.0, memory_length 2000, epsilon 0.022478227612237327, time 735.0, rides 130\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 4215, reward 698.0, memory_length 2000, epsilon 0.022457997207386313, time 734.0, rides 131\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 4216, reward 687.0, memory_length 2000, epsilon 0.022437785009899666, time 725.0, rides 129\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 4217, reward 1195.0, memory_length 2000, epsilon 0.022417591003390757, time 726.0, rides 131\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4218, reward 1083.0, memory_length 2000, epsilon 0.022397415171487706, time 722.0, rides 134\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 4219, reward 954.0, memory_length 2000, epsilon 0.022377257497833366, time 732.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 4220, reward 1045.0, memory_length 2000, epsilon 0.022357117966085315, time 726.0, rides 131\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 4221, reward 865.0, memory_length 2000, epsilon 0.022336996559915837, time 726.0, rides 132\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4222, reward 697.0, memory_length 2000, epsilon 0.02231689326301191, time 731.0, rides 131\n",
      "Initial State is  [1, 3, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4223, reward 995.0, memory_length 2000, epsilon 0.0222968080590752, time 724.0, rides 131\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 4224, reward 1109.0, memory_length 2000, epsilon 0.022276740931822032, time 729.0, rides 139\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4225, reward 1040.0, memory_length 2000, epsilon 0.022256691864983393, time 723.0, rides 134\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 4226, reward 911.0, memory_length 2000, epsilon 0.022236660842304908, time 724.0, rides 131\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4227, reward 1001.0, memory_length 2000, epsilon 0.022216647847546834, time 726.0, rides 130\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 4228, reward 1021.0, memory_length 2000, epsilon 0.02219665286448404, time 728.0, rides 126\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4229, reward 751.0, memory_length 2000, epsilon 0.022176675876906006, time 733.0, rides 124\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 4230, reward 1082.0, memory_length 2000, epsilon 0.02215671686861679, time 722.0, rides 138\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4231, reward 874.0, memory_length 2000, epsilon 0.022136775823435033, time 725.0, rides 147\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 4232, reward 1100.0, memory_length 2000, epsilon 0.022116852725193942, time 726.0, rides 131\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 4233, reward 726.0, memory_length 2000, epsilon 0.02209694755774127, time 723.0, rides 124\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 4234, reward 945.0, memory_length 2000, epsilon 0.022077060304939302, time 738.0, rides 121\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 4235, reward 1094.0, memory_length 2000, epsilon 0.022057190950664857, time 729.0, rides 119\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 4236, reward 956.0, memory_length 2000, epsilon 0.02203733947880926, time 730.0, rides 120\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 4237, reward 1054.0, memory_length 2000, epsilon 0.02201750587327833, time 721.0, rides 123\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 4238, reward 810.0, memory_length 2000, epsilon 0.02199769011799238, time 729.0, rides 138\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 4239, reward 851.0, memory_length 2000, epsilon 0.021977892196886187, time 727.0, rides 124\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4240, reward 1144.0, memory_length 2000, epsilon 0.02195811209390899, time 737.0, rides 126\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 4241, reward 1116.0, memory_length 2000, epsilon 0.021938349793024472, time 723.0, rides 129\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 4242, reward 1077.0, memory_length 2000, epsilon 0.02191860527821075, time 725.0, rides 128\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 4243, reward 733.0, memory_length 2000, epsilon 0.02189887853346036, time 723.0, rides 122\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 4244, reward 890.0, memory_length 2000, epsilon 0.021879169542780245, time 736.0, rides 135\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4245, reward 732.0, memory_length 2000, epsilon 0.021859478290191744, time 727.0, rides 124\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 4246, reward 981.0, memory_length 2000, epsilon 0.02183980475973057, time 732.0, rides 126\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 4247, reward 735.0, memory_length 2000, epsilon 0.021820148935446815, time 723.0, rides 127\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 4248, reward 947.0, memory_length 2000, epsilon 0.021800510801404913, time 728.0, rides 147\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 4249, reward 767.0, memory_length 2000, epsilon 0.021780890341683647, time 727.0, rides 135\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 4250, reward 1093.0, memory_length 2000, epsilon 0.021761287540376133, time 725.0, rides 129\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 4251, reward 718.0, memory_length 2000, epsilon 0.021741702381589796, time 732.0, rides 120\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 4252, reward 1031.0, memory_length 2000, epsilon 0.021722134849446365, time 727.0, rides 124\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 4253, reward 893.0, memory_length 2000, epsilon 0.021702584928081862, time 736.0, rides 118\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 4254, reward 949.0, memory_length 2000, epsilon 0.021683052601646588, time 723.0, rides 129\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4255, reward 1017.0, memory_length 2000, epsilon 0.021663537854305106, time 733.0, rides 124\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4256, reward 1189.0, memory_length 2000, epsilon 0.02164404067023623, time 724.0, rides 124\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 4257, reward 722.0, memory_length 2000, epsilon 0.021624561033633017, time 725.0, rides 128\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 4258, reward 942.0, memory_length 2000, epsilon 0.021605098928702746, time 733.0, rides 139\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4259, reward 505.0, memory_length 2000, epsilon 0.021585654339666912, time 731.0, rides 131\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 4260, reward 1057.0, memory_length 2000, epsilon 0.02156622725076121, time 732.0, rides 131\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 4261, reward 1146.0, memory_length 2000, epsilon 0.021546817646235526, time 730.0, rides 127\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4262, reward 878.0, memory_length 2000, epsilon 0.021527425510353915, time 722.0, rides 126\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 4263, reward 776.0, memory_length 2000, epsilon 0.021508050827394595, time 728.0, rides 121\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 4264, reward 1023.0, memory_length 2000, epsilon 0.02148869358164994, time 729.0, rides 132\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 4265, reward 819.0, memory_length 2000, epsilon 0.021469353757426455, time 733.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 4266, reward 762.0, memory_length 2000, epsilon 0.02145003133904477, time 724.0, rides 121\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 4267, reward 775.0, memory_length 2000, epsilon 0.02143072631083963, time 727.0, rides 137\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 4268, reward 897.0, memory_length 2000, epsilon 0.021411438657159873, time 725.0, rides 131\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 4269, reward 700.0, memory_length 2000, epsilon 0.02139216836236843, time 728.0, rides 139\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 4270, reward 833.0, memory_length 2000, epsilon 0.021372915410842297, time 730.0, rides 127\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4271, reward 871.0, memory_length 2000, epsilon 0.02135367978697254, time 735.0, rides 127\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 4272, reward 1101.0, memory_length 2000, epsilon 0.021334461475164265, time 724.0, rides 133\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4273, reward 547.0, memory_length 2000, epsilon 0.021315260459836616, time 727.0, rides 134\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 4274, reward 1010.0, memory_length 2000, epsilon 0.021296076725422764, time 727.0, rides 138\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 4275, reward 1164.0, memory_length 2000, epsilon 0.021276910256369883, time 734.0, rides 142\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 4276, reward 707.0, memory_length 2000, epsilon 0.02125776103713915, time 726.0, rides 135\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 4277, reward 1112.0, memory_length 2000, epsilon 0.021238629052205724, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 4278, reward 842.0, memory_length 2000, epsilon 0.021219514286058738, time 725.0, rides 135\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4279, reward 900.0, memory_length 2000, epsilon 0.021200416723201283, time 732.0, rides 126\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 4280, reward 847.0, memory_length 2000, epsilon 0.021181336348150403, time 736.0, rides 133\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 4281, reward 1384.0, memory_length 2000, epsilon 0.021162273145437067, time 728.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 4282, reward 971.0, memory_length 2000, epsilon 0.021143227099606175, time 737.0, rides 148\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 4283, reward 739.0, memory_length 2000, epsilon 0.021124198195216527, time 733.0, rides 119\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 4284, reward 833.0, memory_length 2000, epsilon 0.02110518641684083, time 731.0, rides 129\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 4285, reward 716.0, memory_length 2000, epsilon 0.021086191749065675, time 724.0, rides 121\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 4286, reward 957.0, memory_length 2000, epsilon 0.021067214176491517, time 730.0, rides 134\n",
      "Initial State is  [0, 13, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4287, reward 1134.0, memory_length 2000, epsilon 0.021048253683732674, time 728.0, rides 132\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 4288, reward 1144.0, memory_length 2000, epsilon 0.021029310255417315, time 729.0, rides 133\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 4289, reward 913.0, memory_length 2000, epsilon 0.02101038387618744, time 727.0, rides 114\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4290, reward 1095.0, memory_length 2000, epsilon 0.02099147453069887, time 731.0, rides 131\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 4291, reward 868.0, memory_length 2000, epsilon 0.02097258220362124, time 737.0, rides 135\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 4292, reward 1156.0, memory_length 2000, epsilon 0.020953706879637983, time 727.0, rides 147\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 4293, reward 1100.0, memory_length 2000, epsilon 0.020934848543446308, time 727.0, rides 138\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 4294, reward 1014.0, memory_length 2000, epsilon 0.020916007179757206, time 723.0, rides 118\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 4295, reward 590.0, memory_length 2000, epsilon 0.020897182773295424, time 726.0, rides 129\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 4296, reward 1335.0, memory_length 2000, epsilon 0.02087837530879946, time 728.0, rides 127\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 4297, reward 733.0, memory_length 2000, epsilon 0.02085958477102154, time 728.0, rides 126\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 4298, reward 983.0, memory_length 2000, epsilon 0.02084081114472762, time 724.0, rides 133\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4299, reward 892.0, memory_length 2000, epsilon 0.020822054414697363, time 727.0, rides 135\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 4300, reward 1036.0, memory_length 2000, epsilon 0.020803314565724134, time 728.0, rides 140\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 4301, reward 642.0, memory_length 2000, epsilon 0.020784591582614982, time 724.0, rides 130\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 4302, reward 755.0, memory_length 2000, epsilon 0.02076588545019063, time 731.0, rides 129\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 4303, reward 1053.0, memory_length 2000, epsilon 0.020747196153285456, time 724.0, rides 139\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4304, reward 983.0, memory_length 2000, epsilon 0.0207285236767475, time 726.0, rides 126\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 4305, reward 979.0, memory_length 2000, epsilon 0.020709868005438427, time 728.0, rides 125\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4306, reward 1182.0, memory_length 2000, epsilon 0.02069122912423353, time 735.0, rides 132\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 4307, reward 961.0, memory_length 2000, epsilon 0.020672607018021722, time 730.0, rides 123\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 4308, reward 869.0, memory_length 2000, epsilon 0.020654001671705502, time 725.0, rides 137\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 4309, reward 1034.0, memory_length 2000, epsilon 0.02063541307020097, time 727.0, rides 135\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4310, reward 1259.0, memory_length 2000, epsilon 0.020616841198437787, time 727.0, rides 135\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 4311, reward 928.0, memory_length 2000, epsilon 0.020598286041359194, time 732.0, rides 127\n",
      "Initial State is  [3, 17, 0]\n",
      "episode 4312, reward 1131.0, memory_length 2000, epsilon 0.020579747583921972, time 730.0, rides 137\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4313, reward 996.0, memory_length 2000, epsilon 0.020561225811096442, time 728.0, rides 143\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 4314, reward 619.0, memory_length 2000, epsilon 0.020542720707866457, time 733.0, rides 135\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 4315, reward 1037.0, memory_length 2000, epsilon 0.020524232259229377, time 721.0, rides 138\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 4316, reward 865.0, memory_length 2000, epsilon 0.02050576045019607, time 721.0, rides 135\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 4317, reward 846.0, memory_length 2000, epsilon 0.020487305265790894, time 730.0, rides 132\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 4318, reward 790.0, memory_length 2000, epsilon 0.02046886669105168, time 725.0, rides 125\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 4319, reward 950.0, memory_length 2000, epsilon 0.020450444711029733, time 735.0, rides 128\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 4320, reward 925.0, memory_length 2000, epsilon 0.020432039310789806, time 724.0, rides 135\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 4321, reward 1051.0, memory_length 2000, epsilon 0.020413650475410095, time 724.0, rides 132\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 4322, reward 1002.0, memory_length 2000, epsilon 0.020395278189982227, time 723.0, rides 129\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 4323, reward 998.0, memory_length 2000, epsilon 0.020376922439611242, time 737.0, rides 139\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 4324, reward 954.0, memory_length 2000, epsilon 0.020358583209415592, time 732.0, rides 123\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 4325, reward 932.0, memory_length 2000, epsilon 0.02034026048452712, time 725.0, rides 131\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 4326, reward 949.0, memory_length 2000, epsilon 0.020321954250091045, time 731.0, rides 127\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 4327, reward 751.0, memory_length 2000, epsilon 0.02030366449126596, time 734.0, rides 124\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 4328, reward 1093.0, memory_length 2000, epsilon 0.020285391193223822, time 725.0, rides 125\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 4329, reward 1052.0, memory_length 2000, epsilon 0.02026713434114992, time 731.0, rides 128\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 4330, reward 832.0, memory_length 2000, epsilon 0.020248893920242886, time 730.0, rides 120\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 4331, reward 899.0, memory_length 2000, epsilon 0.020230669915714667, time 732.0, rides 116\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 4332, reward 1053.0, memory_length 2000, epsilon 0.020212462312790523, time 732.0, rides 131\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 4333, reward 858.0, memory_length 2000, epsilon 0.020194271096709012, time 732.0, rides 132\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4334, reward 834.0, memory_length 2000, epsilon 0.020176096252721973, time 740.0, rides 128\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 4335, reward 965.0, memory_length 2000, epsilon 0.020157937766094522, time 726.0, rides 119\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 4336, reward 887.0, memory_length 2000, epsilon 0.020139795622105036, time 724.0, rides 138\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4337, reward 761.0, memory_length 2000, epsilon 0.020121669806045142, time 726.0, rides 117\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4338, reward 1035.0, memory_length 2000, epsilon 0.020103560303219702, time 724.0, rides 123\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 4339, reward 469.0, memory_length 2000, epsilon 0.020085467098946805, time 725.0, rides 122\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 4340, reward 930.0, memory_length 2000, epsilon 0.020067390178557753, time 727.0, rides 138\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 4341, reward 856.0, memory_length 2000, epsilon 0.02004932952739705, time 734.0, rides 124\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4342, reward 1104.0, memory_length 2000, epsilon 0.020031285130822394, time 725.0, rides 123\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 4343, reward 877.0, memory_length 2000, epsilon 0.020013256974204655, time 731.0, rides 130\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 4344, reward 897.0, memory_length 2000, epsilon 0.01999524504292787, time 729.0, rides 137\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 4345, reward 984.0, memory_length 2000, epsilon 0.019977249322389236, time 723.0, rides 142\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4346, reward 669.0, memory_length 2000, epsilon 0.019959269797999085, time 731.0, rides 129\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 4347, reward 1253.0, memory_length 2000, epsilon 0.019941306455180885, time 728.0, rides 134\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 4348, reward 904.0, memory_length 2000, epsilon 0.019923359279371222, time 729.0, rides 123\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 4349, reward 964.0, memory_length 2000, epsilon 0.019905428256019788, time 729.0, rides 128\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 4350, reward 952.0, memory_length 2000, epsilon 0.01988751337058937, time 725.0, rides 131\n",
      "Initial State is  [0, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4351, reward 956.0, memory_length 2000, epsilon 0.01986961460855584, time 735.0, rides 133\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 4352, reward 668.0, memory_length 2000, epsilon 0.01985173195540814, time 733.0, rides 130\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 4353, reward 1203.0, memory_length 2000, epsilon 0.019833865396648272, time 725.0, rides 135\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4354, reward 855.0, memory_length 2000, epsilon 0.019816014917791287, time 732.0, rides 122\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 4355, reward 972.0, memory_length 2000, epsilon 0.019798180504365274, time 725.0, rides 123\n",
      "Initial State is  [0, 23, 4]\n",
      "episode 4356, reward 1059.0, memory_length 2000, epsilon 0.019780362141911347, time 729.0, rides 127\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 4357, reward 1398.0, memory_length 2000, epsilon 0.019762559815983627, time 731.0, rides 122\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 4358, reward 975.0, memory_length 2000, epsilon 0.01974477351214924, time 736.0, rides 115\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 4359, reward 1030.0, memory_length 2000, epsilon 0.019727003215988307, time 726.0, rides 136\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4360, reward 1016.0, memory_length 2000, epsilon 0.01970924891309392, time 725.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 4361, reward 798.0, memory_length 2000, epsilon 0.019691510589072134, time 726.0, rides 118\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 4362, reward 1075.0, memory_length 2000, epsilon 0.01967378822954197, time 723.0, rides 124\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 4363, reward 801.0, memory_length 2000, epsilon 0.019656081820135382, time 728.0, rides 123\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 4364, reward 874.0, memory_length 2000, epsilon 0.01963839134649726, time 726.0, rides 119\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 4365, reward 839.0, memory_length 2000, epsilon 0.01962071679428541, time 727.0, rides 123\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 4366, reward 903.0, memory_length 2000, epsilon 0.019603058149170554, time 733.0, rides 109\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 4367, reward 1168.0, memory_length 2000, epsilon 0.019585415396836302, time 729.0, rides 118\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 4368, reward 918.0, memory_length 2000, epsilon 0.01956778852297915, time 730.0, rides 125\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 4369, reward 870.0, memory_length 2000, epsilon 0.019550177513308467, time 734.0, rides 123\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 4370, reward 848.0, memory_length 2000, epsilon 0.01953258235354649, time 727.0, rides 132\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 4371, reward 772.0, memory_length 2000, epsilon 0.0195150030294283, time 724.0, rides 135\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 4372, reward 916.0, memory_length 2000, epsilon 0.019497439526701812, time 726.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 4373, reward 747.0, memory_length 2000, epsilon 0.01947989183112778, time 732.0, rides 139\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 4374, reward 680.0, memory_length 2000, epsilon 0.019462359928479764, time 736.0, rides 122\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 4375, reward 786.0, memory_length 2000, epsilon 0.019444843804544133, time 724.0, rides 114\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 4376, reward 738.0, memory_length 2000, epsilon 0.01942734344512004, time 732.0, rides 127\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 4377, reward 762.0, memory_length 2000, epsilon 0.019409858836019433, time 728.0, rides 112\n",
      "Initial State is  [0, 7, 6]\n",
      "episode 4378, reward 319.0, memory_length 2000, epsilon 0.019392389963067014, time 727.0, rides 137\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 4379, reward 501.0, memory_length 2000, epsilon 0.019374936812100254, time 732.0, rides 116\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 4380, reward 827.0, memory_length 2000, epsilon 0.019357499368969362, time 732.0, rides 119\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 4381, reward 1092.0, memory_length 2000, epsilon 0.01934007761953729, time 735.0, rides 114\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 4382, reward 1074.0, memory_length 2000, epsilon 0.019322671549679708, time 724.0, rides 114\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 4383, reward 756.0, memory_length 2000, epsilon 0.019305281145284996, time 736.0, rides 132\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 4384, reward 1248.0, memory_length 2000, epsilon 0.01928790639225424, time 725.0, rides 125\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 4385, reward 679.0, memory_length 2000, epsilon 0.01927054727650121, time 734.0, rides 118\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 4386, reward 972.0, memory_length 2000, epsilon 0.019253203783952358, time 722.0, rides 129\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 4387, reward 983.0, memory_length 2000, epsilon 0.0192358759005468, time 729.0, rides 115\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 4388, reward 805.0, memory_length 2000, epsilon 0.019218563612236308, time 734.0, rides 137\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 4389, reward 1034.0, memory_length 2000, epsilon 0.019201266904985297, time 732.0, rides 118\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 4390, reward 726.0, memory_length 2000, epsilon 0.01918398576477081, time 730.0, rides 118\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 4391, reward 823.0, memory_length 2000, epsilon 0.019166720177582516, time 727.0, rides 126\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 4392, reward 1050.0, memory_length 2000, epsilon 0.019149470129422693, time 735.0, rides 131\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 4393, reward 756.0, memory_length 2000, epsilon 0.01913223560630621, time 736.0, rides 139\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 4394, reward 941.0, memory_length 2000, epsilon 0.019115016594260535, time 733.0, rides 120\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 4395, reward 866.0, memory_length 2000, epsilon 0.0190978130793257, time 727.0, rides 144\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 4396, reward 761.0, memory_length 2000, epsilon 0.019080625047554308, time 727.0, rides 122\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 4397, reward 957.0, memory_length 2000, epsilon 0.019063452485011508, time 727.0, rides 133\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 4398, reward 787.0, memory_length 2000, epsilon 0.019046295377774997, time 729.0, rides 135\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 4399, reward 966.0, memory_length 2000, epsilon 0.019029153711935, time 733.0, rides 121\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 4400, reward 657.0, memory_length 2000, epsilon 0.01901202747359426, time 729.0, rides 125\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 4401, reward 947.0, memory_length 2000, epsilon 0.018994916648868022, time 723.0, rides 129\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 4402, reward 907.0, memory_length 2000, epsilon 0.018977821223884042, time 733.0, rides 118\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 4403, reward 934.0, memory_length 2000, epsilon 0.018960741184782547, time 734.0, rides 122\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 4404, reward 860.0, memory_length 2000, epsilon 0.01894367651771624, time 725.0, rides 136\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4405, reward 744.0, memory_length 2000, epsilon 0.018926627208850296, time 737.0, rides 123\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4406, reward 1035.0, memory_length 2000, epsilon 0.01890959324436233, time 724.0, rides 129\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 4407, reward 902.0, memory_length 2000, epsilon 0.018892574610442404, time 723.0, rides 112\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4408, reward 1211.0, memory_length 2000, epsilon 0.018875571293293005, time 730.0, rides 138\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 4409, reward 728.0, memory_length 2000, epsilon 0.01885858327912904, time 741.0, rides 124\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 4410, reward 857.0, memory_length 2000, epsilon 0.018841610554177823, time 736.0, rides 132\n",
      "Initial State is  [4, 3, 2]\n",
      "episode 4411, reward 1106.0, memory_length 2000, epsilon 0.018824653104679064, time 724.0, rides 140\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 4412, reward 1254.0, memory_length 2000, epsilon 0.018807710916884855, time 731.0, rides 123\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 4413, reward 919.0, memory_length 2000, epsilon 0.018790783977059657, time 726.0, rides 132\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 4414, reward 800.0, memory_length 2000, epsilon 0.018773872271480304, time 726.0, rides 143\n",
      "Initial State is  [2, 14, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4415, reward 1072.0, memory_length 2000, epsilon 0.01875697578643597, time 733.0, rides 135\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 4416, reward 1133.0, memory_length 2000, epsilon 0.018740094508228177, time 724.0, rides 129\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 4417, reward 862.0, memory_length 2000, epsilon 0.01872322842317077, time 730.0, rides 130\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4418, reward 596.0, memory_length 2000, epsilon 0.018706377517589915, time 726.0, rides 123\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 4419, reward 1156.0, memory_length 2000, epsilon 0.018689541777824083, time 726.0, rides 136\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 4420, reward 956.0, memory_length 2000, epsilon 0.01867272119022404, time 732.0, rides 133\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 4421, reward 852.0, memory_length 2000, epsilon 0.01865591574115284, time 733.0, rides 148\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4422, reward 1060.0, memory_length 2000, epsilon 0.018639125416985803, time 728.0, rides 128\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 4423, reward 792.0, memory_length 2000, epsilon 0.018622350204110516, time 733.0, rides 134\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 4424, reward 863.0, memory_length 2000, epsilon 0.018605590088926816, time 724.0, rides 130\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 4425, reward 897.0, memory_length 2000, epsilon 0.018588845057846783, time 734.0, rides 142\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4426, reward 1031.0, memory_length 2000, epsilon 0.01857211509729472, time 733.0, rides 125\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 4427, reward 1073.0, memory_length 2000, epsilon 0.018555400193707154, time 730.0, rides 133\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4428, reward 768.0, memory_length 2000, epsilon 0.018538700333532818, time 721.0, rides 128\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 4429, reward 757.0, memory_length 2000, epsilon 0.01852201550323264, time 730.0, rides 128\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 4430, reward 739.0, memory_length 2000, epsilon 0.01850534568927973, time 735.0, rides 122\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 4431, reward 980.0, memory_length 2000, epsilon 0.018488690878159377, time 731.0, rides 148\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 4432, reward 969.0, memory_length 2000, epsilon 0.018472051056369034, time 729.0, rides 137\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 4433, reward 908.0, memory_length 2000, epsilon 0.0184554262104183, time 731.0, rides 124\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 4434, reward 1156.0, memory_length 2000, epsilon 0.018438816326828925, time 729.0, rides 130\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4435, reward 724.0, memory_length 2000, epsilon 0.01842222139213478, time 727.0, rides 135\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4436, reward 759.0, memory_length 2000, epsilon 0.018405641392881856, time 731.0, rides 136\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 4437, reward 1004.0, memory_length 2000, epsilon 0.01838907631562826, time 726.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 4438, reward 1066.0, memory_length 2000, epsilon 0.018372526146944193, time 729.0, rides 125\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 4439, reward 785.0, memory_length 2000, epsilon 0.018355990873411943, time 724.0, rides 140\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4440, reward 824.0, memory_length 2000, epsilon 0.01833947048162587, time 729.0, rides 132\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 4441, reward 1196.0, memory_length 2000, epsilon 0.018322964958192408, time 728.0, rides 131\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 4442, reward 932.0, memory_length 2000, epsilon 0.018306474289730035, time 726.0, rides 132\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 4443, reward 806.0, memory_length 2000, epsilon 0.018289998462869276, time 721.0, rides 138\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4444, reward 1414.0, memory_length 2000, epsilon 0.018273537464252695, time 731.0, rides 135\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4445, reward 1243.0, memory_length 2000, epsilon 0.018257091280534866, time 731.0, rides 128\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 4446, reward 1283.0, memory_length 2000, epsilon 0.018240659898382385, time 729.0, rides 129\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 4447, reward 762.0, memory_length 2000, epsilon 0.01822424330447384, time 728.0, rides 122\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 4448, reward 589.0, memory_length 2000, epsilon 0.018207841485499813, time 738.0, rides 121\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 4449, reward 865.0, memory_length 2000, epsilon 0.018191454428162862, time 738.0, rides 140\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 4450, reward 1141.0, memory_length 2000, epsilon 0.018175082119177514, time 724.0, rides 141\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 4451, reward 832.0, memory_length 2000, epsilon 0.018158724545270254, time 729.0, rides 132\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 4452, reward 915.0, memory_length 2000, epsilon 0.01814238169317951, time 729.0, rides 135\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 4453, reward 958.0, memory_length 2000, epsilon 0.018126053549655647, time 726.0, rides 129\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4454, reward 587.0, memory_length 2000, epsilon 0.018109740101460957, time 724.0, rides 125\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 4455, reward 779.0, memory_length 2000, epsilon 0.01809344133536964, time 724.0, rides 126\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 4456, reward 794.0, memory_length 2000, epsilon 0.01807715723816781, time 727.0, rides 125\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 4457, reward 933.0, memory_length 2000, epsilon 0.018060887796653456, time 725.0, rides 131\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 4458, reward 850.0, memory_length 2000, epsilon 0.018044632997636468, time 730.0, rides 127\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 4459, reward 747.0, memory_length 2000, epsilon 0.018028392827938593, time 728.0, rides 130\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 4460, reward 916.0, memory_length 2000, epsilon 0.018012167274393448, time 730.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4461, reward 849.0, memory_length 2000, epsilon 0.017995956323846495, time 728.0, rides 133\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 4462, reward 869.0, memory_length 2000, epsilon 0.017979759963155033, time 726.0, rides 134\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 4463, reward 740.0, memory_length 2000, epsilon 0.017963578179188193, time 731.0, rides 120\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 4464, reward 863.0, memory_length 2000, epsilon 0.017947410958826925, time 729.0, rides 130\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 4465, reward 700.0, memory_length 2000, epsilon 0.01793125828896398, time 727.0, rides 121\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 4466, reward 834.0, memory_length 2000, epsilon 0.017915120156503914, time 737.0, rides 131\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4467, reward 972.0, memory_length 2000, epsilon 0.01789899654836306, time 726.0, rides 125\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 4468, reward 889.0, memory_length 2000, epsilon 0.017882887451469532, time 728.0, rides 128\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 4469, reward 1172.0, memory_length 2000, epsilon 0.01786679285276321, time 735.0, rides 131\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 4470, reward 1243.0, memory_length 2000, epsilon 0.017850712739195723, time 733.0, rides 135\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 4471, reward 958.0, memory_length 2000, epsilon 0.017834647097730447, time 731.0, rides 138\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 4472, reward 1020.0, memory_length 2000, epsilon 0.01781859591534249, time 726.0, rides 127\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 4473, reward 832.0, memory_length 2000, epsilon 0.01780255917901868, time 725.0, rides 135\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 4474, reward 672.0, memory_length 2000, epsilon 0.017786536875757562, time 731.0, rides 121\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 4475, reward 965.0, memory_length 2000, epsilon 0.01777052899256938, time 723.0, rides 143\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 4476, reward 1080.0, memory_length 2000, epsilon 0.01775453551647607, time 732.0, rides 136\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 4477, reward 806.0, memory_length 2000, epsilon 0.01773855643451124, time 728.0, rides 138\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 4478, reward 839.0, memory_length 2000, epsilon 0.017722591733720178, time 731.0, rides 124\n",
      "Initial State is  [2, 10, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4479, reward 1043.0, memory_length 2000, epsilon 0.01770664140115983, time 724.0, rides 142\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 4480, reward 806.0, memory_length 2000, epsilon 0.017690705423898785, time 729.0, rides 138\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 4481, reward 735.0, memory_length 2000, epsilon 0.017674783789017275, time 725.0, rides 133\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4482, reward 1048.0, memory_length 2000, epsilon 0.017658876483607158, time 727.0, rides 132\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 4483, reward 1011.0, memory_length 2000, epsilon 0.017642983494771912, time 726.0, rides 123\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 4484, reward 858.0, memory_length 2000, epsilon 0.017627104809626617, time 725.0, rides 135\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 4485, reward 956.0, memory_length 2000, epsilon 0.017611240415297953, time 731.0, rides 125\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 4486, reward 1102.0, memory_length 2000, epsilon 0.017595390298924183, time 727.0, rides 144\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 4487, reward 730.0, memory_length 2000, epsilon 0.01757955444765515, time 729.0, rides 124\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 4488, reward 751.0, memory_length 2000, epsilon 0.01756373284865226, time 728.0, rides 122\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 4489, reward 987.0, memory_length 2000, epsilon 0.017547925489088474, time 735.0, rides 129\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 4490, reward 943.0, memory_length 2000, epsilon 0.017532132356148294, time 729.0, rides 141\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 4491, reward 897.0, memory_length 2000, epsilon 0.01751635343702776, time 729.0, rides 131\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4492, reward 989.0, memory_length 2000, epsilon 0.017500588718934434, time 731.0, rides 142\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4493, reward 657.0, memory_length 2000, epsilon 0.017484838189087394, time 729.0, rides 135\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 4494, reward 935.0, memory_length 2000, epsilon 0.017469101834717216, time 724.0, rides 123\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 4495, reward 692.0, memory_length 2000, epsilon 0.01745337964306597, time 734.0, rides 124\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 4496, reward 935.0, memory_length 2000, epsilon 0.01743767160138721, time 733.0, rides 124\n",
      "Initial State is  [2, 10, 2]\n",
      "episode 4497, reward 967.0, memory_length 2000, epsilon 0.01742197769694596, time 728.0, rides 129\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 4498, reward 634.0, memory_length 2000, epsilon 0.01740629791701871, time 734.0, rides 143\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 4499, reward 754.0, memory_length 2000, epsilon 0.01739063224889339, time 727.0, rides 142\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 4500, reward 875.0, memory_length 2000, epsilon 0.017374980679869388, time 740.0, rides 112\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4501, reward 980.0, memory_length 2000, epsilon 0.017359343197257505, time 735.0, rides 139\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 4502, reward 1010.0, memory_length 2000, epsilon 0.017343719788379973, time 724.0, rides 125\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4503, reward 825.0, memory_length 2000, epsilon 0.01732811044057043, time 723.0, rides 122\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4504, reward 893.0, memory_length 2000, epsilon 0.017312515141173917, time 731.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 4505, reward 1154.0, memory_length 2000, epsilon 0.01729693387754686, time 728.0, rides 134\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 4506, reward 831.0, memory_length 2000, epsilon 0.017281366637057066, time 731.0, rides 121\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4507, reward 527.0, memory_length 2000, epsilon 0.017265813407083715, time 730.0, rides 128\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 4508, reward 914.0, memory_length 2000, epsilon 0.01725027417501734, time 726.0, rides 126\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 4509, reward 1275.0, memory_length 2000, epsilon 0.017234748928259824, time 724.0, rides 133\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 4510, reward 1018.0, memory_length 2000, epsilon 0.017219237654224392, time 729.0, rides 132\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 4511, reward 888.0, memory_length 2000, epsilon 0.017203740340335588, time 738.0, rides 125\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4512, reward 894.0, memory_length 2000, epsilon 0.017188256974029287, time 725.0, rides 128\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 4513, reward 1084.0, memory_length 2000, epsilon 0.01717278754275266, time 722.0, rides 132\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4514, reward 886.0, memory_length 2000, epsilon 0.017157332033964183, time 725.0, rides 143\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4515, reward 751.0, memory_length 2000, epsilon 0.017141890435133617, time 731.0, rides 127\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 4516, reward 915.0, memory_length 2000, epsilon 0.017126462733741996, time 731.0, rides 129\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 4517, reward 1252.0, memory_length 2000, epsilon 0.01711104891728163, time 722.0, rides 135\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4518, reward 1347.0, memory_length 2000, epsilon 0.017095648973256074, time 726.0, rides 135\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 4519, reward 853.0, memory_length 2000, epsilon 0.017080262889180145, time 733.0, rides 124\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 4520, reward 700.0, memory_length 2000, epsilon 0.01706489065257988, time 727.0, rides 138\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 4521, reward 864.0, memory_length 2000, epsilon 0.01704953225099256, time 729.0, rides 138\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 4522, reward 1003.0, memory_length 2000, epsilon 0.017034187671966666, time 731.0, rides 132\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 4523, reward 1029.0, memory_length 2000, epsilon 0.017018856903061895, time 729.0, rides 145\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 4524, reward 1337.0, memory_length 2000, epsilon 0.017003539931849138, time 727.0, rides 139\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 4525, reward 1081.0, memory_length 2000, epsilon 0.016988236745910473, time 732.0, rides 137\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4526, reward 853.0, memory_length 2000, epsilon 0.016972947332839154, time 728.0, rides 131\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 4527, reward 1034.0, memory_length 2000, epsilon 0.016957671680239598, time 733.0, rides 136\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 4528, reward 1087.0, memory_length 2000, epsilon 0.016942409775727384, time 725.0, rides 156\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 4529, reward 839.0, memory_length 2000, epsilon 0.01692716160692923, time 732.0, rides 125\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 4530, reward 954.0, memory_length 2000, epsilon 0.016911927161482994, time 727.0, rides 150\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4531, reward 1107.0, memory_length 2000, epsilon 0.01689670642703766, time 723.0, rides 140\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 4532, reward 936.0, memory_length 2000, epsilon 0.016881499391253326, time 735.0, rides 150\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 4533, reward 836.0, memory_length 2000, epsilon 0.0168663060418012, time 730.0, rides 126\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4534, reward 769.0, memory_length 2000, epsilon 0.01685112636636358, time 735.0, rides 139\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 4535, reward 1070.0, memory_length 2000, epsilon 0.016835960352633853, time 725.0, rides 138\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 4536, reward 1320.0, memory_length 2000, epsilon 0.01682080798831648, time 729.0, rides 137\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 4537, reward 848.0, memory_length 2000, epsilon 0.016805669261126997, time 722.0, rides 134\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 4538, reward 841.0, memory_length 2000, epsilon 0.016790544158791984, time 726.0, rides 134\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 4539, reward 912.0, memory_length 2000, epsilon 0.01677543266904907, time 727.0, rides 126\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 4540, reward 845.0, memory_length 2000, epsilon 0.016760334779646925, time 724.0, rides 134\n",
      "Initial State is  [3, 1, 1]\n",
      "episode 4541, reward 913.0, memory_length 2000, epsilon 0.01674525047834524, time 732.0, rides 137\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 4542, reward 696.0, memory_length 2000, epsilon 0.016730179752914732, time 730.0, rides 138\n",
      "Initial State is  [3, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4543, reward 946.0, memory_length 2000, epsilon 0.016715122591137107, time 722.0, rides 140\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 4544, reward 843.0, memory_length 2000, epsilon 0.016700078980805083, time 726.0, rides 131\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 4545, reward 1100.0, memory_length 2000, epsilon 0.016685048909722357, time 733.0, rides 138\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 4546, reward 1000.0, memory_length 2000, epsilon 0.016670032365703608, time 732.0, rides 134\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4547, reward 737.0, memory_length 2000, epsilon 0.016655029336574475, time 728.0, rides 132\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 4548, reward 875.0, memory_length 2000, epsilon 0.016640039810171557, time 726.0, rides 126\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 4549, reward 742.0, memory_length 2000, epsilon 0.0166250637743424, time 723.0, rides 128\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4550, reward 710.0, memory_length 2000, epsilon 0.016610101216945495, time 723.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 4551, reward 992.0, memory_length 2000, epsilon 0.016595152125850245, time 728.0, rides 128\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 4552, reward 1112.0, memory_length 2000, epsilon 0.01658021648893698, time 725.0, rides 139\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 4553, reward 1092.0, memory_length 2000, epsilon 0.016565294294096936, time 725.0, rides 118\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 4554, reward 1024.0, memory_length 2000, epsilon 0.01655038552923225, time 735.0, rides 136\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 4555, reward 888.0, memory_length 2000, epsilon 0.01653549018225594, time 732.0, rides 129\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 4556, reward 1024.0, memory_length 2000, epsilon 0.01652060824109191, time 730.0, rides 136\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 4557, reward 886.0, memory_length 2000, epsilon 0.016505739693674925, time 725.0, rides 157\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 4558, reward 886.0, memory_length 2000, epsilon 0.016490884527950618, time 725.0, rides 138\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 4559, reward 1141.0, memory_length 2000, epsilon 0.016476042731875463, time 731.0, rides 142\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 4560, reward 1035.0, memory_length 2000, epsilon 0.016461214293416775, time 730.0, rides 138\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 4561, reward 981.0, memory_length 2000, epsilon 0.0164463992005527, time 729.0, rides 140\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 4562, reward 982.0, memory_length 2000, epsilon 0.016431597441272202, time 724.0, rides 129\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 4563, reward 816.0, memory_length 2000, epsilon 0.016416809003575058, time 728.0, rides 131\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 4564, reward 1048.0, memory_length 2000, epsilon 0.01640203387547184, time 736.0, rides 128\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 4565, reward 1143.0, memory_length 2000, epsilon 0.016387272044983917, time 722.0, rides 140\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4566, reward 996.0, memory_length 2000, epsilon 0.01637252350014343, time 730.0, rides 135\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 4567, reward 1049.0, memory_length 2000, epsilon 0.0163577882289933, time 723.0, rides 135\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 4568, reward 1217.0, memory_length 2000, epsilon 0.016343066219587206, time 730.0, rides 137\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 4569, reward 886.0, memory_length 2000, epsilon 0.016328357459989576, time 733.0, rides 135\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 4570, reward 1220.0, memory_length 2000, epsilon 0.016313661938275586, time 724.0, rides 131\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 4571, reward 812.0, memory_length 2000, epsilon 0.016298979642531138, time 732.0, rides 133\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 4572, reward 934.0, memory_length 2000, epsilon 0.01628431056085286, time 732.0, rides 139\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 4573, reward 943.0, memory_length 2000, epsilon 0.016269654681348094, time 724.0, rides 128\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 4574, reward 795.0, memory_length 2000, epsilon 0.01625501199213488, time 728.0, rides 135\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 4575, reward 977.0, memory_length 2000, epsilon 0.01624038248134196, time 731.0, rides 132\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 4576, reward 985.0, memory_length 2000, epsilon 0.016225766137108754, time 731.0, rides 130\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 4577, reward 878.0, memory_length 2000, epsilon 0.016211162947585355, time 730.0, rides 133\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 4578, reward 1004.0, memory_length 2000, epsilon 0.01619657290093253, time 729.0, rides 139\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4579, reward 861.0, memory_length 2000, epsilon 0.01618199598532169, time 727.0, rides 134\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4580, reward 747.0, memory_length 2000, epsilon 0.0161674321889349, time 728.0, rides 150\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4581, reward 995.0, memory_length 2000, epsilon 0.01615288149996486, time 727.0, rides 134\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 4582, reward 1079.0, memory_length 2000, epsilon 0.01613834390661489, time 724.0, rides 137\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 4583, reward 1292.0, memory_length 2000, epsilon 0.016123819397098938, time 724.0, rides 141\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4584, reward 1275.0, memory_length 2000, epsilon 0.01610930795964155, time 725.0, rides 129\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 4585, reward 1080.0, memory_length 2000, epsilon 0.016094809582477873, time 725.0, rides 142\n",
      "Initial State is  [1, 5, 1]\n",
      "episode 4586, reward 1080.0, memory_length 2000, epsilon 0.016080324253853643, time 731.0, rides 140\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 4587, reward 1045.0, memory_length 2000, epsilon 0.016065851962025174, time 733.0, rides 132\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 4588, reward 1007.0, memory_length 2000, epsilon 0.01605139269525935, time 732.0, rides 135\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 4589, reward 904.0, memory_length 2000, epsilon 0.016036946441833618, time 725.0, rides 123\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 4590, reward 921.0, memory_length 2000, epsilon 0.016022513190035968, time 731.0, rides 132\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 4591, reward 1034.0, memory_length 2000, epsilon 0.016008092928164935, time 724.0, rides 133\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 4592, reward 885.0, memory_length 2000, epsilon 0.015993685644529586, time 729.0, rides 127\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 4593, reward 758.0, memory_length 2000, epsilon 0.015979291327449508, time 730.0, rides 131\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 4594, reward 1062.0, memory_length 2000, epsilon 0.015964909965254803, time 725.0, rides 134\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 4595, reward 1252.0, memory_length 2000, epsilon 0.015950541546286074, time 728.0, rides 129\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 4596, reward 1079.0, memory_length 2000, epsilon 0.015936186058894415, time 733.0, rides 137\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 4597, reward 1052.0, memory_length 2000, epsilon 0.01592184349144141, time 733.0, rides 136\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 4598, reward 853.0, memory_length 2000, epsilon 0.015907513832299113, time 729.0, rides 129\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 4599, reward 1171.0, memory_length 2000, epsilon 0.015893197069850044, time 726.0, rides 146\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 4600, reward 1085.0, memory_length 2000, epsilon 0.015878893192487177, time 730.0, rides 135\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 4601, reward 923.0, memory_length 2000, epsilon 0.01586460218861394, time 723.0, rides 140\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 4602, reward 998.0, memory_length 2000, epsilon 0.015850324046644187, time 733.0, rides 140\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 4603, reward 1064.0, memory_length 2000, epsilon 0.015836058755002207, time 730.0, rides 136\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 4604, reward 609.0, memory_length 2000, epsilon 0.015821806302122706, time 730.0, rides 131\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 4605, reward 882.0, memory_length 2000, epsilon 0.015807566676450797, time 738.0, rides 138\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4606, reward 1048.0, memory_length 2000, epsilon 0.01579333986644199, time 731.0, rides 132\n",
      "Initial State is  [1, 8, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4607, reward 1047.0, memory_length 2000, epsilon 0.015779125860562192, time 725.0, rides 142\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 4608, reward 943.0, memory_length 2000, epsilon 0.015764924647287685, time 730.0, rides 137\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4609, reward 1065.0, memory_length 2000, epsilon 0.015750736215105126, time 731.0, rides 129\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4610, reward 817.0, memory_length 2000, epsilon 0.01573656055251153, time 730.0, rides 123\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4611, reward 651.0, memory_length 2000, epsilon 0.01572239764801427, time 729.0, rides 139\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 4612, reward 792.0, memory_length 2000, epsilon 0.015708247490131055, time 724.0, rides 142\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 4613, reward 1244.0, memory_length 2000, epsilon 0.015694110067389938, time 727.0, rides 145\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 4614, reward 1182.0, memory_length 2000, epsilon 0.015679985368329288, time 734.0, rides 137\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 4615, reward 583.0, memory_length 2000, epsilon 0.015665873381497792, time 723.0, rides 137\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 4616, reward 697.0, memory_length 2000, epsilon 0.015651774095454443, time 729.0, rides 123\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 4617, reward 740.0, memory_length 2000, epsilon 0.015637687498768534, time 733.0, rides 120\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 4618, reward 995.0, memory_length 2000, epsilon 0.015623613580019643, time 730.0, rides 128\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 4619, reward 945.0, memory_length 2000, epsilon 0.015609552327797625, time 732.0, rides 125\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 4620, reward 1280.0, memory_length 2000, epsilon 0.015595503730702606, time 733.0, rides 138\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 4621, reward 937.0, memory_length 2000, epsilon 0.015581467777344973, time 720.0, rides 128\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 4622, reward 1005.0, memory_length 2000, epsilon 0.015567444456345362, time 730.0, rides 128\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4623, reward 879.0, memory_length 2000, epsilon 0.015553433756334651, time 724.0, rides 125\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 4624, reward 941.0, memory_length 2000, epsilon 0.01553943566595395, time 735.0, rides 141\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 4625, reward 1040.0, memory_length 2000, epsilon 0.015525450173854592, time 736.0, rides 135\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 4626, reward 1057.0, memory_length 2000, epsilon 0.015511477268698122, time 734.0, rides 127\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 4627, reward 921.0, memory_length 2000, epsilon 0.015497516939156294, time 723.0, rides 123\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 4628, reward 811.0, memory_length 2000, epsilon 0.015483569173911053, time 736.0, rides 131\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4629, reward 680.0, memory_length 2000, epsilon 0.015469633961654534, time 725.0, rides 133\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 4630, reward 786.0, memory_length 2000, epsilon 0.015455711291089044, time 733.0, rides 135\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 4631, reward 1209.0, memory_length 2000, epsilon 0.015441801150927064, time 726.0, rides 140\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 4632, reward 1236.0, memory_length 2000, epsilon 0.01542790352989123, time 731.0, rides 138\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 4633, reward 798.0, memory_length 2000, epsilon 0.015414018416714328, time 727.0, rides 140\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 4634, reward 897.0, memory_length 2000, epsilon 0.015400145800139285, time 730.0, rides 137\n",
      "Initial State is  [1, 3, 1]\n",
      "episode 4635, reward 697.0, memory_length 2000, epsilon 0.01538628566891916, time 725.0, rides 137\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 4636, reward 915.0, memory_length 2000, epsilon 0.015372438011817131, time 734.0, rides 118\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 4637, reward 853.0, memory_length 2000, epsilon 0.015358602817606495, time 734.0, rides 128\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 4638, reward 990.0, memory_length 2000, epsilon 0.01534478007507065, time 730.0, rides 125\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 4639, reward 916.0, memory_length 2000, epsilon 0.015330969773003087, time 731.0, rides 133\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 4640, reward 1091.0, memory_length 2000, epsilon 0.015317171900207384, time 729.0, rides 140\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 4641, reward 1044.0, memory_length 2000, epsilon 0.015303386445497197, time 729.0, rides 122\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 4642, reward 1129.0, memory_length 2000, epsilon 0.01528961339769625, time 724.0, rides 121\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 4643, reward 955.0, memory_length 2000, epsilon 0.015275852745638323, time 733.0, rides 141\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 4644, reward 1158.0, memory_length 2000, epsilon 0.01526210447816725, time 729.0, rides 136\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 4645, reward 732.0, memory_length 2000, epsilon 0.015248368584136899, time 720.0, rides 141\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 4646, reward 1179.0, memory_length 2000, epsilon 0.015234645052411176, time 726.0, rides 135\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 4647, reward 892.0, memory_length 2000, epsilon 0.015220933871864005, time 727.0, rides 146\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 4648, reward 993.0, memory_length 2000, epsilon 0.015207235031379327, time 729.0, rides 132\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4649, reward 961.0, memory_length 2000, epsilon 0.015193548519851085, time 731.0, rides 132\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 4650, reward 972.0, memory_length 2000, epsilon 0.015179874326183219, time 731.0, rides 139\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 4651, reward 1237.0, memory_length 2000, epsilon 0.015166212439289653, time 725.0, rides 136\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 4652, reward 1263.0, memory_length 2000, epsilon 0.015152562848094292, time 725.0, rides 148\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 4653, reward 808.0, memory_length 2000, epsilon 0.015138925541531007, time 725.0, rides 129\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 4654, reward 1035.0, memory_length 2000, epsilon 0.015125300508543629, time 726.0, rides 130\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 4655, reward 884.0, memory_length 2000, epsilon 0.01511168773808594, time 721.0, rides 134\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 4656, reward 770.0, memory_length 2000, epsilon 0.015098087219121663, time 732.0, rides 129\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 4657, reward 1118.0, memory_length 2000, epsilon 0.015084498940624453, time 729.0, rides 126\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 4658, reward 1085.0, memory_length 2000, epsilon 0.015070922891577892, time 730.0, rides 143\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 4659, reward 1155.0, memory_length 2000, epsilon 0.015057359060975472, time 733.0, rides 133\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 4660, reward 979.0, memory_length 2000, epsilon 0.015043807437820593, time 737.0, rides 128\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 4661, reward 1135.0, memory_length 2000, epsilon 0.015030268011126554, time 728.0, rides 138\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 4662, reward 778.0, memory_length 2000, epsilon 0.01501674076991654, time 729.0, rides 132\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 4663, reward 767.0, memory_length 2000, epsilon 0.015003225703223613, time 736.0, rides 127\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 4664, reward 609.0, memory_length 2000, epsilon 0.014989722800090711, time 727.0, rides 127\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 4665, reward 1046.0, memory_length 2000, epsilon 0.01497623204957063, time 728.0, rides 142\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 4666, reward 605.0, memory_length 2000, epsilon 0.014962753440726015, time 732.0, rides 120\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 4667, reward 932.0, memory_length 2000, epsilon 0.01494928696262936, time 725.0, rides 130\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 4668, reward 967.0, memory_length 2000, epsilon 0.014935832604362995, time 731.0, rides 131\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 4669, reward 924.0, memory_length 2000, epsilon 0.014922390355019069, time 729.0, rides 124\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 4670, reward 638.0, memory_length 2000, epsilon 0.014908960203699551, time 727.0, rides 128\n",
      "Initial State is  [2, 16, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4671, reward 894.0, memory_length 2000, epsilon 0.014895542139516221, time 728.0, rides 128\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 4672, reward 1157.0, memory_length 2000, epsilon 0.014882136151590656, time 739.0, rides 122\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 4673, reward 986.0, memory_length 2000, epsilon 0.014868742229054224, time 728.0, rides 140\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 4674, reward 1122.0, memory_length 2000, epsilon 0.014855360361048075, time 726.0, rides 123\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 4675, reward 748.0, memory_length 2000, epsilon 0.01484199053672313, time 730.0, rides 134\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 4676, reward 929.0, memory_length 2000, epsilon 0.01482863274524008, time 737.0, rides 133\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 4677, reward 1064.0, memory_length 2000, epsilon 0.014815286975769363, time 733.0, rides 126\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 4678, reward 772.0, memory_length 2000, epsilon 0.01480195321749117, time 727.0, rides 126\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 4679, reward 853.0, memory_length 2000, epsilon 0.014788631459595428, time 730.0, rides 120\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 4680, reward 930.0, memory_length 2000, epsilon 0.014775321691281791, time 732.0, rides 131\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 4681, reward 931.0, memory_length 2000, epsilon 0.014762023901759638, time 734.0, rides 126\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 4682, reward 931.0, memory_length 2000, epsilon 0.014748738080248054, time 730.0, rides 122\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 4683, reward 1063.0, memory_length 2000, epsilon 0.014735464215975831, time 731.0, rides 123\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 4684, reward 1007.0, memory_length 2000, epsilon 0.014722202298181452, time 736.0, rides 145\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 4685, reward 812.0, memory_length 2000, epsilon 0.014708952316113088, time 731.0, rides 128\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4686, reward 675.0, memory_length 2000, epsilon 0.014695714259028585, time 723.0, rides 142\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 4687, reward 1167.0, memory_length 2000, epsilon 0.01468248811619546, time 729.0, rides 139\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 4688, reward 1058.0, memory_length 2000, epsilon 0.014669273876890885, time 730.0, rides 144\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 4689, reward 787.0, memory_length 2000, epsilon 0.014656071530401682, time 739.0, rides 133\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 4690, reward 1086.0, memory_length 2000, epsilon 0.014642881066024321, time 734.0, rides 132\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 4691, reward 648.0, memory_length 2000, epsilon 0.0146297024730649, time 722.0, rides 134\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 4692, reward 764.0, memory_length 2000, epsilon 0.01461653574083914, time 733.0, rides 133\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 4693, reward 964.0, memory_length 2000, epsilon 0.014603380858672384, time 736.0, rides 131\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4694, reward 1128.0, memory_length 2000, epsilon 0.01459023781589958, time 721.0, rides 126\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 4695, reward 826.0, memory_length 2000, epsilon 0.01457710660186527, time 735.0, rides 133\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 4696, reward 724.0, memory_length 2000, epsilon 0.014563987205923591, time 727.0, rides 125\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 4697, reward 973.0, memory_length 2000, epsilon 0.01455087961743826, time 731.0, rides 130\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 4698, reward 1014.0, memory_length 2000, epsilon 0.014537783825782564, time 724.0, rides 128\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 4699, reward 1074.0, memory_length 2000, epsilon 0.01452469982033936, time 723.0, rides 139\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 4700, reward 1022.0, memory_length 2000, epsilon 0.014511627590501053, time 728.0, rides 136\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 4701, reward 780.0, memory_length 2000, epsilon 0.014498567125669602, time 729.0, rides 129\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4702, reward 1061.0, memory_length 2000, epsilon 0.014485518415256499, time 728.0, rides 114\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 4703, reward 939.0, memory_length 2000, epsilon 0.014472481448682767, time 731.0, rides 124\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 4704, reward 1010.0, memory_length 2000, epsilon 0.014459456215378952, time 726.0, rides 129\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 4705, reward 781.0, memory_length 2000, epsilon 0.01444644270478511, time 723.0, rides 128\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 4706, reward 1313.0, memory_length 2000, epsilon 0.014433440906350804, time 729.0, rides 127\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 4707, reward 995.0, memory_length 2000, epsilon 0.014420450809535088, time 726.0, rides 132\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 4708, reward 1060.0, memory_length 2000, epsilon 0.014407472403806507, time 731.0, rides 141\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4709, reward 900.0, memory_length 2000, epsilon 0.014394505678643081, time 730.0, rides 131\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4710, reward 1008.0, memory_length 2000, epsilon 0.014381550623532302, time 726.0, rides 129\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 4711, reward 1120.0, memory_length 2000, epsilon 0.014368607227971123, time 724.0, rides 148\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 4712, reward 1012.0, memory_length 2000, epsilon 0.014355675481465949, time 727.0, rides 133\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 4713, reward 900.0, memory_length 2000, epsilon 0.014342755373532629, time 733.0, rides 130\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 4714, reward 887.0, memory_length 2000, epsilon 0.014329846893696449, time 726.0, rides 120\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 4715, reward 1026.0, memory_length 2000, epsilon 0.014316950031492122, time 726.0, rides 121\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 4716, reward 833.0, memory_length 2000, epsilon 0.014304064776463779, time 728.0, rides 130\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4717, reward 758.0, memory_length 2000, epsilon 0.01429119111816496, time 730.0, rides 122\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 4718, reward 961.0, memory_length 2000, epsilon 0.014278329046158611, time 730.0, rides 130\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 4719, reward 1049.0, memory_length 2000, epsilon 0.014265478550017068, time 743.0, rides 144\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 4720, reward 612.0, memory_length 2000, epsilon 0.014252639619322053, time 726.0, rides 146\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 4721, reward 901.0, memory_length 2000, epsilon 0.014239812243664662, time 722.0, rides 139\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 4722, reward 1025.0, memory_length 2000, epsilon 0.014226996412645364, time 728.0, rides 132\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 4723, reward 838.0, memory_length 2000, epsilon 0.014214192115873983, time 732.0, rides 138\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 4724, reward 911.0, memory_length 2000, epsilon 0.014201399342969696, time 725.0, rides 130\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 4725, reward 955.0, memory_length 2000, epsilon 0.014188618083561023, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 4726, reward 860.0, memory_length 2000, epsilon 0.014175848327285818, time 727.0, rides 142\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 4727, reward 944.0, memory_length 2000, epsilon 0.01416309006379126, time 732.0, rides 128\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4728, reward 732.0, memory_length 2000, epsilon 0.014150343282733848, time 730.0, rides 137\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 4729, reward 1322.0, memory_length 2000, epsilon 0.014137607973779387, time 728.0, rides 146\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 4730, reward 996.0, memory_length 2000, epsilon 0.014124884126602986, time 725.0, rides 118\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 4731, reward 1026.0, memory_length 2000, epsilon 0.014112171730889043, time 733.0, rides 140\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 4732, reward 777.0, memory_length 2000, epsilon 0.014099470776331243, time 726.0, rides 137\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 4733, reward 771.0, memory_length 2000, epsilon 0.014086781252632545, time 728.0, rides 137\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 4734, reward 1055.0, memory_length 2000, epsilon 0.014074103149505175, time 726.0, rides 127\n",
      "Initial State is  [2, 7, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4735, reward 1012.0, memory_length 2000, epsilon 0.01406143645667062, time 729.0, rides 136\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 4736, reward 1055.0, memory_length 2000, epsilon 0.014048781163859617, time 730.0, rides 144\n",
      "Initial State is  [1, 11, 0]\n",
      "episode 4737, reward 1197.0, memory_length 2000, epsilon 0.014036137260812143, time 732.0, rides 133\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 4738, reward 1083.0, memory_length 2000, epsilon 0.014023504737277412, time 730.0, rides 126\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4739, reward 991.0, memory_length 2000, epsilon 0.014010883583013861, time 729.0, rides 128\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 4740, reward 955.0, memory_length 2000, epsilon 0.013998273787789148, time 729.0, rides 132\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 4741, reward 715.0, memory_length 2000, epsilon 0.013985675341380139, time 727.0, rides 127\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 4742, reward 1019.0, memory_length 2000, epsilon 0.013973088233572897, time 734.0, rides 129\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4743, reward 1314.0, memory_length 2000, epsilon 0.013960512454162681, time 724.0, rides 119\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4744, reward 912.0, memory_length 2000, epsilon 0.013947947992953935, time 727.0, rides 133\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 4745, reward 831.0, memory_length 2000, epsilon 0.013935394839760275, time 729.0, rides 146\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4746, reward 944.0, memory_length 2000, epsilon 0.013922852984404491, time 724.0, rides 130\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 4747, reward 863.0, memory_length 2000, epsilon 0.013910322416718527, time 727.0, rides 136\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 4748, reward 896.0, memory_length 2000, epsilon 0.01389780312654348, time 730.0, rides 128\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4749, reward 852.0, memory_length 2000, epsilon 0.013885295103729592, time 733.0, rides 130\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 4750, reward 1053.0, memory_length 2000, epsilon 0.013872798338136235, time 731.0, rides 127\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 4751, reward 1184.0, memory_length 2000, epsilon 0.013860312819631912, time 729.0, rides 146\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 4752, reward 948.0, memory_length 2000, epsilon 0.013847838538094244, time 728.0, rides 135\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 4753, reward 1149.0, memory_length 2000, epsilon 0.013835375483409958, time 725.0, rides 131\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 4754, reward 1276.0, memory_length 2000, epsilon 0.01382292364547489, time 723.0, rides 132\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 4755, reward 805.0, memory_length 2000, epsilon 0.013810483014193962, time 734.0, rides 136\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 4756, reward 1180.0, memory_length 2000, epsilon 0.013798053579481188, time 736.0, rides 137\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 4757, reward 982.0, memory_length 2000, epsilon 0.013785635331259654, time 729.0, rides 141\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 4758, reward 1082.0, memory_length 2000, epsilon 0.01377322825946152, time 734.0, rides 136\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 4759, reward 963.0, memory_length 2000, epsilon 0.013760832354028005, time 734.0, rides 128\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 4760, reward 1066.0, memory_length 2000, epsilon 0.01374844760490938, time 745.0, rides 139\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 4761, reward 830.0, memory_length 2000, epsilon 0.013736074002064962, time 732.0, rides 134\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 4762, reward 1015.0, memory_length 2000, epsilon 0.013723711535463104, time 723.0, rides 130\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 4763, reward 893.0, memory_length 2000, epsilon 0.013711360195081186, time 720.0, rides 130\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 4764, reward 1156.0, memory_length 2000, epsilon 0.013699019970905613, time 727.0, rides 132\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 4765, reward 980.0, memory_length 2000, epsilon 0.013686690852931798, time 729.0, rides 133\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 4766, reward 926.0, memory_length 2000, epsilon 0.013674372831164159, time 722.0, rides 129\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 4767, reward 786.0, memory_length 2000, epsilon 0.013662065895616112, time 733.0, rides 138\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 4768, reward 875.0, memory_length 2000, epsilon 0.013649770036310058, time 721.0, rides 124\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 4769, reward 976.0, memory_length 2000, epsilon 0.013637485243277379, time 726.0, rides 128\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 4770, reward 802.0, memory_length 2000, epsilon 0.013625211506558429, time 724.0, rides 127\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 4771, reward 818.0, memory_length 2000, epsilon 0.013612948816202525, time 725.0, rides 141\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 4772, reward 964.0, memory_length 2000, epsilon 0.013600697162267942, time 723.0, rides 136\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 4773, reward 812.0, memory_length 2000, epsilon 0.0135884565348219, time 732.0, rides 135\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 4774, reward 918.0, memory_length 2000, epsilon 0.013576226923940561, time 730.0, rides 131\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 4775, reward 963.0, memory_length 2000, epsilon 0.013564008319709015, time 728.0, rides 127\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 4776, reward 714.0, memory_length 2000, epsilon 0.013551800712221276, time 724.0, rides 134\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 4777, reward 820.0, memory_length 2000, epsilon 0.013539604091580277, time 731.0, rides 126\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 4778, reward 1034.0, memory_length 2000, epsilon 0.013527418447897854, time 737.0, rides 142\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 4779, reward 820.0, memory_length 2000, epsilon 0.013515243771294745, time 728.0, rides 135\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 4780, reward 1036.0, memory_length 2000, epsilon 0.01350308005190058, time 728.0, rides 130\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 4781, reward 1265.0, memory_length 2000, epsilon 0.013490927279853869, time 734.0, rides 125\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 4782, reward 1120.0, memory_length 2000, epsilon 0.013478785445302, time 729.0, rides 129\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 4783, reward 839.0, memory_length 2000, epsilon 0.013466654538401228, time 723.0, rides 129\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 4784, reward 1031.0, memory_length 2000, epsilon 0.013454534549316667, time 735.0, rides 130\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 4785, reward 767.0, memory_length 2000, epsilon 0.013442425468222283, time 724.0, rides 137\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4786, reward 954.0, memory_length 2000, epsilon 0.013430327285300882, time 733.0, rides 127\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 4787, reward 856.0, memory_length 2000, epsilon 0.013418239990744112, time 730.0, rides 123\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 4788, reward 906.0, memory_length 2000, epsilon 0.013406163574752442, time 727.0, rides 123\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 4789, reward 1178.0, memory_length 2000, epsilon 0.013394098027535165, time 729.0, rides 130\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 4790, reward 1187.0, memory_length 2000, epsilon 0.013382043339310383, time 738.0, rides 133\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4791, reward 982.0, memory_length 2000, epsilon 0.013369999500305004, time 728.0, rides 148\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 4792, reward 946.0, memory_length 2000, epsilon 0.01335796650075473, time 727.0, rides 119\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 4793, reward 938.0, memory_length 2000, epsilon 0.013345944330904051, time 731.0, rides 136\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 4794, reward 1008.0, memory_length 2000, epsilon 0.013333932981006238, time 731.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 4795, reward 1176.0, memory_length 2000, epsilon 0.013321932441323332, time 734.0, rides 127\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4796, reward 1006.0, memory_length 2000, epsilon 0.01330994270212614, time 725.0, rides 130\n",
      "Initial State is  [0, 9, 4]\n",
      "episode 4797, reward 834.0, memory_length 2000, epsilon 0.013297963753694226, time 724.0, rides 134\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 4798, reward 1083.0, memory_length 2000, epsilon 0.013285995586315902, time 729.0, rides 123\n",
      "Initial State is  [1, 3, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4799, reward 993.0, memory_length 2000, epsilon 0.013274038190288218, time 732.0, rides 125\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 4800, reward 971.0, memory_length 2000, epsilon 0.013262091555916958, time 733.0, rides 138\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 4801, reward 998.0, memory_length 2000, epsilon 0.013250155673516633, time 727.0, rides 132\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 4802, reward 1166.0, memory_length 2000, epsilon 0.013238230533410467, time 730.0, rides 141\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 4803, reward 793.0, memory_length 2000, epsilon 0.013226316125930398, time 723.0, rides 128\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 4804, reward 716.0, memory_length 2000, epsilon 0.013214412441417061, time 731.0, rides 134\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 4805, reward 824.0, memory_length 2000, epsilon 0.013202519470219786, time 729.0, rides 136\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 4806, reward 802.0, memory_length 2000, epsilon 0.013190637202696589, time 737.0, rides 143\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 4807, reward 741.0, memory_length 2000, epsilon 0.013178765629214162, time 730.0, rides 144\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 4808, reward 1095.0, memory_length 2000, epsilon 0.013166904740147868, time 727.0, rides 132\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 4809, reward 1009.0, memory_length 2000, epsilon 0.013155054525881735, time 730.0, rides 119\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 4810, reward 756.0, memory_length 2000, epsilon 0.013143214976808442, time 726.0, rides 137\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 4811, reward 1100.0, memory_length 2000, epsilon 0.013131386083329314, time 734.0, rides 130\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 4812, reward 1095.0, memory_length 2000, epsilon 0.013119567835854317, time 732.0, rides 129\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 4813, reward 856.0, memory_length 2000, epsilon 0.013107760224802048, time 728.0, rides 137\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 4814, reward 902.0, memory_length 2000, epsilon 0.013095963240599726, time 734.0, rides 153\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 4815, reward 1214.0, memory_length 2000, epsilon 0.013084176873683186, time 724.0, rides 124\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 4816, reward 1120.0, memory_length 2000, epsilon 0.013072401114496871, time 729.0, rides 146\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 4817, reward 1061.0, memory_length 2000, epsilon 0.013060635953493823, time 727.0, rides 128\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 4818, reward 842.0, memory_length 2000, epsilon 0.013048881381135679, time 723.0, rides 136\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 4819, reward 940.0, memory_length 2000, epsilon 0.013037137387892656, time 733.0, rides 138\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4820, reward 1006.0, memory_length 2000, epsilon 0.013025403964243553, time 728.0, rides 120\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 4821, reward 909.0, memory_length 2000, epsilon 0.013013681100675733, time 729.0, rides 128\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4822, reward 967.0, memory_length 2000, epsilon 0.013001968787685125, time 727.0, rides 131\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 4823, reward 626.0, memory_length 2000, epsilon 0.012990267015776208, time 734.0, rides 135\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 4824, reward 894.0, memory_length 2000, epsilon 0.01297857577546201, time 727.0, rides 142\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 4825, reward 973.0, memory_length 2000, epsilon 0.012966895057264094, time 734.0, rides 131\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4826, reward 853.0, memory_length 2000, epsilon 0.012955224851712556, time 735.0, rides 131\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 4827, reward 1321.0, memory_length 2000, epsilon 0.012943565149346015, time 728.0, rides 136\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 4828, reward 1009.0, memory_length 2000, epsilon 0.012931915940711605, time 730.0, rides 136\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4829, reward 1053.0, memory_length 2000, epsilon 0.012920277216364963, time 724.0, rides 132\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 4830, reward 966.0, memory_length 2000, epsilon 0.012908648966870235, time 728.0, rides 124\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 4831, reward 892.0, memory_length 2000, epsilon 0.012897031182800051, time 726.0, rides 119\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 4832, reward 1124.0, memory_length 2000, epsilon 0.01288542385473553, time 733.0, rides 131\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 4833, reward 953.0, memory_length 2000, epsilon 0.01287382697326627, time 722.0, rides 129\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 4834, reward 894.0, memory_length 2000, epsilon 0.01286224052899033, time 730.0, rides 138\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 4835, reward 902.0, memory_length 2000, epsilon 0.012850664512514237, time 728.0, rides 119\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 4836, reward 1301.0, memory_length 2000, epsilon 0.012839098914452974, time 729.0, rides 130\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 4837, reward 797.0, memory_length 2000, epsilon 0.012827543725429966, time 731.0, rides 141\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 4838, reward 1026.0, memory_length 2000, epsilon 0.012815998936077079, time 735.0, rides 133\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 4839, reward 935.0, memory_length 2000, epsilon 0.01280446453703461, time 730.0, rides 129\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 4840, reward 1217.0, memory_length 2000, epsilon 0.012792940518951279, time 736.0, rides 136\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 4841, reward 1126.0, memory_length 2000, epsilon 0.012781426872484222, time 724.0, rides 140\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 4842, reward 942.0, memory_length 2000, epsilon 0.012769923588298987, time 734.0, rides 127\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 4843, reward 672.0, memory_length 2000, epsilon 0.012758430657069518, time 731.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 4844, reward 1093.0, memory_length 2000, epsilon 0.012746948069478155, time 722.0, rides 131\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 4845, reward 867.0, memory_length 2000, epsilon 0.012735475816215624, time 726.0, rides 126\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 4846, reward 815.0, memory_length 2000, epsilon 0.01272401388798103, time 726.0, rides 115\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 4847, reward 892.0, memory_length 2000, epsilon 0.012712562275481848, time 737.0, rides 141\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 4848, reward 1049.0, memory_length 2000, epsilon 0.012701120969433913, time 726.0, rides 140\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 4849, reward 908.0, memory_length 2000, epsilon 0.012689689960561423, time 723.0, rides 123\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 4850, reward 1031.0, memory_length 2000, epsilon 0.012678269239596918, time 726.0, rides 124\n",
      "Initial State is  [0, 15, 4]\n",
      "episode 4851, reward 1127.0, memory_length 2000, epsilon 0.01266685879728128, time 733.0, rides 129\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 4852, reward 1042.0, memory_length 2000, epsilon 0.012655458624363727, time 729.0, rides 121\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 4853, reward 941.0, memory_length 2000, epsilon 0.0126440687116018, time 730.0, rides 135\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 4854, reward 865.0, memory_length 2000, epsilon 0.012632689049761357, time 730.0, rides 124\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4855, reward 755.0, memory_length 2000, epsilon 0.012621319629616571, time 725.0, rides 127\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 4856, reward 1142.0, memory_length 2000, epsilon 0.012609960441949916, time 724.0, rides 125\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 4857, reward 987.0, memory_length 2000, epsilon 0.01259861147755216, time 728.0, rides 123\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 4858, reward 1098.0, memory_length 2000, epsilon 0.012587272727222362, time 730.0, rides 120\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 4859, reward 1116.0, memory_length 2000, epsilon 0.012575944181767862, time 736.0, rides 123\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 4860, reward 1045.0, memory_length 2000, epsilon 0.01256462583200427, time 727.0, rides 127\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 4861, reward 1043.0, memory_length 2000, epsilon 0.012553317668755467, time 727.0, rides 126\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 4862, reward 814.0, memory_length 2000, epsilon 0.012542019682853588, time 729.0, rides 128\n",
      "Initial State is  [1, 3, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4863, reward 1020.0, memory_length 2000, epsilon 0.01253073186513902, time 730.0, rides 127\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 4864, reward 1028.0, memory_length 2000, epsilon 0.012519454206460393, time 734.0, rides 132\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 4865, reward 947.0, memory_length 2000, epsilon 0.012508186697674579, time 736.0, rides 117\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 4866, reward 992.0, memory_length 2000, epsilon 0.012496929329646671, time 732.0, rides 129\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 4867, reward 799.0, memory_length 2000, epsilon 0.012485682093249989, time 726.0, rides 118\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 4868, reward 865.0, memory_length 2000, epsilon 0.012474444979366063, time 731.0, rides 119\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 4869, reward 806.0, memory_length 2000, epsilon 0.012463217978884633, time 724.0, rides 129\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 4870, reward 595.0, memory_length 2000, epsilon 0.012452001082703636, time 728.0, rides 132\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4871, reward 1005.0, memory_length 2000, epsilon 0.012440794281729202, time 731.0, rides 131\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4872, reward 1004.0, memory_length 2000, epsilon 0.012429597566875646, time 734.0, rides 134\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 4873, reward 846.0, memory_length 2000, epsilon 0.012418410929065458, time 727.0, rides 124\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 4874, reward 896.0, memory_length 2000, epsilon 0.012407234359229299, time 726.0, rides 129\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 4875, reward 749.0, memory_length 2000, epsilon 0.012396067848305992, time 731.0, rides 140\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 4876, reward 468.0, memory_length 2000, epsilon 0.012384911387242516, time 729.0, rides 122\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 4877, reward 1206.0, memory_length 2000, epsilon 0.012373764966993998, time 737.0, rides 130\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 4878, reward 961.0, memory_length 2000, epsilon 0.012362628578523703, time 732.0, rides 136\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 4879, reward 1138.0, memory_length 2000, epsilon 0.012351502212803032, time 739.0, rides 139\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 4880, reward 948.0, memory_length 2000, epsilon 0.01234038586081151, time 726.0, rides 144\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 4881, reward 1116.0, memory_length 2000, epsilon 0.01232927951353678, time 727.0, rides 121\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 4882, reward 1149.0, memory_length 2000, epsilon 0.012318183161974597, time 728.0, rides 134\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 4883, reward 1097.0, memory_length 2000, epsilon 0.01230709679712882, time 723.0, rides 123\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 4884, reward 1020.0, memory_length 2000, epsilon 0.012296020410011403, time 731.0, rides 123\n",
      "Initial State is  [4, 1, 6]\n",
      "episode 4885, reward 1018.0, memory_length 2000, epsilon 0.012284953991642393, time 729.0, rides 137\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 4886, reward 1004.0, memory_length 2000, epsilon 0.012273897533049914, time 732.0, rides 138\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 4887, reward 1036.0, memory_length 2000, epsilon 0.01226285102527017, time 722.0, rides 133\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 4888, reward 1450.0, memory_length 2000, epsilon 0.012251814459347426, time 729.0, rides 132\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 4889, reward 1090.0, memory_length 2000, epsilon 0.012240787826334013, time 729.0, rides 128\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 4890, reward 913.0, memory_length 2000, epsilon 0.012229771117290312, time 722.0, rides 147\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 4891, reward 1356.0, memory_length 2000, epsilon 0.01221876432328475, time 723.0, rides 136\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 4892, reward 1232.0, memory_length 2000, epsilon 0.012207767435393794, time 731.0, rides 154\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 4893, reward 915.0, memory_length 2000, epsilon 0.01219678044470194, time 728.0, rides 142\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 4894, reward 867.0, memory_length 2000, epsilon 0.012185803342301708, time 726.0, rides 120\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 4895, reward 1095.0, memory_length 2000, epsilon 0.012174836119293637, time 726.0, rides 130\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 4896, reward 1017.0, memory_length 2000, epsilon 0.012163878766786273, time 725.0, rides 134\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 4897, reward 896.0, memory_length 2000, epsilon 0.012152931275896166, time 728.0, rides 130\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 4898, reward 1118.0, memory_length 2000, epsilon 0.012141993637747858, time 726.0, rides 145\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 4899, reward 1113.0, memory_length 2000, epsilon 0.012131065843473884, time 726.0, rides 137\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 4900, reward 870.0, memory_length 2000, epsilon 0.012120147884214758, time 728.0, rides 132\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 4901, reward 926.0, memory_length 2000, epsilon 0.012109239751118965, time 732.0, rides 142\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 4902, reward 984.0, memory_length 2000, epsilon 0.012098341435342958, time 733.0, rides 125\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 4903, reward 872.0, memory_length 2000, epsilon 0.01208745292805115, time 734.0, rides 131\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 4904, reward 1453.0, memory_length 2000, epsilon 0.012076574220415904, time 723.0, rides 143\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 4905, reward 1078.0, memory_length 2000, epsilon 0.01206570530361753, time 728.0, rides 126\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 4906, reward 869.0, memory_length 2000, epsilon 0.012054846168844275, time 735.0, rides 123\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 4907, reward 1027.0, memory_length 2000, epsilon 0.012043996807292314, time 730.0, rides 130\n",
      "Initial State is  [0, 11, 1]\n",
      "episode 4908, reward 998.0, memory_length 2000, epsilon 0.01203315721016575, time 731.0, rides 119\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 4909, reward 1161.0, memory_length 2000, epsilon 0.0120223273686766, time 729.0, rides 118\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 4910, reward 1037.0, memory_length 2000, epsilon 0.012011507274044791, time 736.0, rides 131\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 4911, reward 822.0, memory_length 2000, epsilon 0.01200069691749815, time 732.0, rides 123\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 4912, reward 1007.0, memory_length 2000, epsilon 0.011989896290272401, time 734.0, rides 122\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 4913, reward 1130.0, memory_length 2000, epsilon 0.011979105383611157, time 727.0, rides 121\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 4914, reward 1145.0, memory_length 2000, epsilon 0.011968324188765906, time 731.0, rides 126\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 4915, reward 1092.0, memory_length 2000, epsilon 0.011957552696996016, time 723.0, rides 133\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 4916, reward 1051.0, memory_length 2000, epsilon 0.01194679089956872, time 734.0, rides 126\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 4917, reward 906.0, memory_length 2000, epsilon 0.01193603878775911, time 723.0, rides 138\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 4918, reward 1008.0, memory_length 2000, epsilon 0.011925296352850126, time 723.0, rides 136\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 4919, reward 1246.0, memory_length 2000, epsilon 0.01191456358613256, time 732.0, rides 140\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 4920, reward 872.0, memory_length 2000, epsilon 0.011903840478905041, time 729.0, rides 135\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 4921, reward 814.0, memory_length 2000, epsilon 0.011893127022474026, time 730.0, rides 130\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 4922, reward 1019.0, memory_length 2000, epsilon 0.0118824232081538, time 734.0, rides 118\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 4923, reward 1040.0, memory_length 2000, epsilon 0.011871729027266461, time 733.0, rides 133\n",
      "Initial State is  [3, 9, 2]\n",
      "episode 4924, reward 1093.0, memory_length 2000, epsilon 0.011861044471141922, time 731.0, rides 132\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 4925, reward 1033.0, memory_length 2000, epsilon 0.011850369531117894, time 725.0, rides 125\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 4926, reward 978.0, memory_length 2000, epsilon 0.011839704198539887, time 731.0, rides 129\n",
      "Initial State is  [0, 1, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4927, reward 1015.0, memory_length 2000, epsilon 0.011829048464761202, time 733.0, rides 141\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4928, reward 1134.0, memory_length 2000, epsilon 0.011818402321142917, time 733.0, rides 130\n",
      "Initial State is  [2, 11, 0]\n",
      "episode 4929, reward 1084.0, memory_length 2000, epsilon 0.011807765759053887, time 732.0, rides 123\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 4930, reward 1310.0, memory_length 2000, epsilon 0.011797138769870739, time 729.0, rides 138\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 4931, reward 944.0, memory_length 2000, epsilon 0.011786521344977855, time 729.0, rides 128\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 4932, reward 742.0, memory_length 2000, epsilon 0.011775913475767374, time 725.0, rides 132\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 4933, reward 760.0, memory_length 2000, epsilon 0.011765315153639183, time 729.0, rides 139\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 4934, reward 994.0, memory_length 2000, epsilon 0.011754726370000908, time 726.0, rides 140\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 4935, reward 1068.0, memory_length 2000, epsilon 0.011744147116267907, time 731.0, rides 118\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 4936, reward 940.0, memory_length 2000, epsilon 0.011733577383863266, time 726.0, rides 133\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 4937, reward 1096.0, memory_length 2000, epsilon 0.01172301716421779, time 731.0, rides 126\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 4938, reward 1013.0, memory_length 2000, epsilon 0.011712466448769993, time 730.0, rides 126\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 4939, reward 710.0, memory_length 2000, epsilon 0.0117019252289661, time 735.0, rides 131\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 4940, reward 1239.0, memory_length 2000, epsilon 0.011691393496260031, time 725.0, rides 135\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 4941, reward 650.0, memory_length 2000, epsilon 0.011680871242113396, time 725.0, rides 132\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 4942, reward 524.0, memory_length 2000, epsilon 0.011670358457995494, time 726.0, rides 125\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 4943, reward 917.0, memory_length 2000, epsilon 0.011659855135383299, time 733.0, rides 139\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 4944, reward 970.0, memory_length 2000, epsilon 0.011649361265761453, time 728.0, rides 134\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 4945, reward 822.0, memory_length 2000, epsilon 0.011638876840622267, time 726.0, rides 120\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 4946, reward 1095.0, memory_length 2000, epsilon 0.011628401851465707, time 731.0, rides 131\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 4947, reward 590.0, memory_length 2000, epsilon 0.011617936289799388, time 730.0, rides 115\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 4948, reward 976.0, memory_length 2000, epsilon 0.011607480147138569, time 732.0, rides 126\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 4949, reward 845.0, memory_length 2000, epsilon 0.011597033415006144, time 730.0, rides 143\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 4950, reward 978.0, memory_length 2000, epsilon 0.011586596084932638, time 729.0, rides 124\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 4951, reward 1170.0, memory_length 2000, epsilon 0.011576168148456198, time 728.0, rides 125\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4952, reward 993.0, memory_length 2000, epsilon 0.011565749597122588, time 723.0, rides 132\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 4953, reward 952.0, memory_length 2000, epsilon 0.011555340422485178, time 732.0, rides 121\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 4954, reward 1012.0, memory_length 2000, epsilon 0.011544940616104941, time 728.0, rides 150\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 4955, reward 843.0, memory_length 2000, epsilon 0.011534550169550448, time 727.0, rides 136\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 4956, reward 829.0, memory_length 2000, epsilon 0.011524169074397852, time 724.0, rides 127\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 4957, reward 1034.0, memory_length 2000, epsilon 0.011513797322230894, time 734.0, rides 146\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 4958, reward 1169.0, memory_length 2000, epsilon 0.011503434904640886, time 726.0, rides 128\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 4959, reward 811.0, memory_length 2000, epsilon 0.011493081813226709, time 730.0, rides 128\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 4960, reward 916.0, memory_length 2000, epsilon 0.011482738039594804, time 732.0, rides 134\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 4961, reward 1088.0, memory_length 2000, epsilon 0.011472403575359169, time 727.0, rides 125\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 4962, reward 825.0, memory_length 2000, epsilon 0.011462078412141346, time 729.0, rides 129\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 4963, reward 874.0, memory_length 2000, epsilon 0.011451762541570418, time 736.0, rides 140\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 4964, reward 999.0, memory_length 2000, epsilon 0.011441455955283003, time 725.0, rides 151\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 4965, reward 756.0, memory_length 2000, epsilon 0.011431158644923249, time 727.0, rides 138\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 4966, reward 1115.0, memory_length 2000, epsilon 0.011420870602142818, time 727.0, rides 146\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 4967, reward 851.0, memory_length 2000, epsilon 0.01141059181860089, time 731.0, rides 130\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 4968, reward 1116.0, memory_length 2000, epsilon 0.011400322285964149, time 732.0, rides 134\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 4969, reward 1022.0, memory_length 2000, epsilon 0.01139006199590678, time 736.0, rides 138\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 4970, reward 917.0, memory_length 2000, epsilon 0.011379810940110464, time 726.0, rides 125\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 4971, reward 946.0, memory_length 2000, epsilon 0.011369569110264365, time 726.0, rides 139\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 4972, reward 939.0, memory_length 2000, epsilon 0.011359336498065127, time 735.0, rides 135\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 4973, reward 1006.0, memory_length 2000, epsilon 0.011349113095216868, time 725.0, rides 137\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 4974, reward 953.0, memory_length 2000, epsilon 0.011338898893431173, time 730.0, rides 129\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 4975, reward 882.0, memory_length 2000, epsilon 0.011328693884427084, time 724.0, rides 128\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 4976, reward 1073.0, memory_length 2000, epsilon 0.0113184980599311, time 729.0, rides 142\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 4977, reward 981.0, memory_length 2000, epsilon 0.01130831141167716, time 733.0, rides 137\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 4978, reward 1068.0, memory_length 2000, epsilon 0.011298133931406652, time 725.0, rides 144\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 4979, reward 668.0, memory_length 2000, epsilon 0.011287965610868386, time 722.0, rides 149\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 4980, reward 1194.0, memory_length 2000, epsilon 0.011277806441818604, time 731.0, rides 132\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 4981, reward 920.0, memory_length 2000, epsilon 0.011267656416020967, time 730.0, rides 130\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 4982, reward 732.0, memory_length 2000, epsilon 0.011257515525246549, time 733.0, rides 137\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 4983, reward 559.0, memory_length 2000, epsilon 0.011247383761273827, time 729.0, rides 123\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 4984, reward 881.0, memory_length 2000, epsilon 0.01123726111588868, time 730.0, rides 144\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 4985, reward 1083.0, memory_length 2000, epsilon 0.01122714758088438, time 724.0, rides 132\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 4986, reward 901.0, memory_length 2000, epsilon 0.011217043148061585, time 728.0, rides 131\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 4987, reward 805.0, memory_length 2000, epsilon 0.01120694780922833, time 730.0, rides 131\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 4988, reward 1004.0, memory_length 2000, epsilon 0.011196861556200024, time 723.0, rides 136\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 4989, reward 845.0, memory_length 2000, epsilon 0.011186784380799444, time 737.0, rides 134\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 4990, reward 973.0, memory_length 2000, epsilon 0.011176716274856724, time 727.0, rides 128\n",
      "Initial State is  [3, 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 4991, reward 608.0, memory_length 2000, epsilon 0.011166657230209353, time 726.0, rides 118\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 4992, reward 966.0, memory_length 2000, epsilon 0.011156607238702165, time 733.0, rides 136\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 4993, reward 1114.0, memory_length 2000, epsilon 0.011146566292187332, time 731.0, rides 147\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 4994, reward 1098.0, memory_length 2000, epsilon 0.011136534382524363, time 729.0, rides 142\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 4995, reward 740.0, memory_length 2000, epsilon 0.01112651150158009, time 723.0, rides 131\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 4996, reward 1154.0, memory_length 2000, epsilon 0.011116497641228669, time 725.0, rides 131\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 4997, reward 1012.0, memory_length 2000, epsilon 0.011106492793351562, time 725.0, rides 129\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 4998, reward 1157.0, memory_length 2000, epsilon 0.011096496949837546, time 727.0, rides 137\n",
      "Initial State is  [0, 2, 3]\n",
      "episode 4999, reward 714.0, memory_length 2000, epsilon 0.011086510102582693, time 731.0, rides 141\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5000, reward 822.0, memory_length 2000, epsilon 0.011076532243490369, time 736.0, rides 137\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5001, reward 963.0, memory_length 2000, epsilon 0.011066563364471227, time 737.0, rides 132\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 5002, reward 730.0, memory_length 2000, epsilon 0.011056603457443203, time 726.0, rides 137\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 5003, reward 922.0, memory_length 2000, epsilon 0.011046652514331503, time 720.0, rides 139\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 5004, reward 955.0, memory_length 2000, epsilon 0.011036710527068604, time 733.0, rides 149\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 5005, reward 914.0, memory_length 2000, epsilon 0.011026777487594243, time 733.0, rides 125\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 5006, reward 929.0, memory_length 2000, epsilon 0.011016853387855408, time 724.0, rides 135\n",
      "Initial State is  [3, 5, 1]\n",
      "episode 5007, reward 820.0, memory_length 2000, epsilon 0.011006938219806337, time 725.0, rides 148\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5008, reward 513.0, memory_length 2000, epsilon 0.010997031975408512, time 720.0, rides 145\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 5009, reward 1041.0, memory_length 2000, epsilon 0.010987134646630644, time 733.0, rides 141\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 5010, reward 853.0, memory_length 2000, epsilon 0.010977246225448677, time 729.0, rides 142\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5011, reward 1004.0, memory_length 2000, epsilon 0.010967366703845773, time 729.0, rides 139\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 5012, reward 1343.0, memory_length 2000, epsilon 0.010957496073812311, time 729.0, rides 148\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 5013, reward 1197.0, memory_length 2000, epsilon 0.010947634327345879, time 724.0, rides 133\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 5014, reward 1104.0, memory_length 2000, epsilon 0.010937781456451268, time 733.0, rides 145\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5015, reward 889.0, memory_length 2000, epsilon 0.010927937453140461, time 731.0, rides 137\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 5016, reward 1073.0, memory_length 2000, epsilon 0.010918102309432635, time 724.0, rides 136\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 5017, reward 990.0, memory_length 2000, epsilon 0.010908276017354146, time 725.0, rides 139\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 5018, reward 1072.0, memory_length 2000, epsilon 0.010898458568938526, time 728.0, rides 136\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 5019, reward 1185.0, memory_length 2000, epsilon 0.010888649956226482, time 728.0, rides 141\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5020, reward 1012.0, memory_length 2000, epsilon 0.010878850171265877, time 731.0, rides 131\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5021, reward 955.0, memory_length 2000, epsilon 0.010869059206111737, time 728.0, rides 156\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 5022, reward 774.0, memory_length 2000, epsilon 0.010859277052826237, time 725.0, rides 143\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 5023, reward 1096.0, memory_length 2000, epsilon 0.010849503703478694, time 726.0, rides 137\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 5024, reward 1131.0, memory_length 2000, epsilon 0.010839739150145562, time 725.0, rides 141\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 5025, reward 928.0, memory_length 2000, epsilon 0.010829983384910431, time 731.0, rides 125\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 5026, reward 814.0, memory_length 2000, epsilon 0.010820236399864012, time 726.0, rides 142\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 5027, reward 1099.0, memory_length 2000, epsilon 0.010810498187104134, time 727.0, rides 127\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 5028, reward 776.0, memory_length 2000, epsilon 0.01080076873873574, time 734.0, rides 123\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 5029, reward 1005.0, memory_length 2000, epsilon 0.010791048046870878, time 726.0, rides 126\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 5030, reward 716.0, memory_length 2000, epsilon 0.010781336103628695, time 730.0, rides 133\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 5031, reward 1004.0, memory_length 2000, epsilon 0.010771632901135428, time 727.0, rides 130\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5032, reward 1084.0, memory_length 2000, epsilon 0.010761938431524407, time 728.0, rides 130\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 5033, reward 590.0, memory_length 2000, epsilon 0.010752252686936034, time 728.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 5034, reward 1204.0, memory_length 2000, epsilon 0.010742575659517792, time 727.0, rides 130\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 5035, reward 903.0, memory_length 2000, epsilon 0.010732907341424226, time 731.0, rides 122\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5036, reward 970.0, memory_length 2000, epsilon 0.010723247724816944, time 732.0, rides 140\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 5037, reward 1051.0, memory_length 2000, epsilon 0.010713596801864608, time 729.0, rides 135\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 5038, reward 837.0, memory_length 2000, epsilon 0.01070395456474293, time 736.0, rides 146\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 5039, reward 948.0, memory_length 2000, epsilon 0.01069432100563466, time 731.0, rides 125\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 5040, reward 944.0, memory_length 2000, epsilon 0.01068469611672959, time 732.0, rides 121\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 5041, reward 1172.0, memory_length 2000, epsilon 0.010675079890224533, time 727.0, rides 144\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 5042, reward 1087.0, memory_length 2000, epsilon 0.010665472318323332, time 728.0, rides 139\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 5043, reward 925.0, memory_length 2000, epsilon 0.01065587339323684, time 727.0, rides 127\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 5044, reward 911.0, memory_length 2000, epsilon 0.010646283107182927, time 726.0, rides 138\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 5045, reward 632.0, memory_length 2000, epsilon 0.010636701452386462, time 725.0, rides 117\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 5046, reward 806.0, memory_length 2000, epsilon 0.010627128421079313, time 724.0, rides 127\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 5047, reward 1315.0, memory_length 2000, epsilon 0.010617564005500343, time 726.0, rides 131\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5048, reward 1193.0, memory_length 2000, epsilon 0.010608008197895391, time 731.0, rides 129\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 5049, reward 887.0, memory_length 2000, epsilon 0.010598460990517285, time 728.0, rides 138\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 5050, reward 761.0, memory_length 2000, epsilon 0.01058892237562582, time 726.0, rides 132\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 5051, reward 1189.0, memory_length 2000, epsilon 0.010579392345487756, time 728.0, rides 123\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 5052, reward 841.0, memory_length 2000, epsilon 0.010569870892376817, time 723.0, rides 122\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 5053, reward 1080.0, memory_length 2000, epsilon 0.010560358008573677, time 729.0, rides 133\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 5054, reward 993.0, memory_length 2000, epsilon 0.010550853686365961, time 730.0, rides 145\n",
      "Initial State is  [2, 14, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5055, reward 1059.0, memory_length 2000, epsilon 0.010541357918048232, time 723.0, rides 125\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 5056, reward 1068.0, memory_length 2000, epsilon 0.010531870695921989, time 722.0, rides 118\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 5057, reward 934.0, memory_length 2000, epsilon 0.01052239201229566, time 736.0, rides 137\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 5058, reward 853.0, memory_length 2000, epsilon 0.010512921859484593, time 727.0, rides 124\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5059, reward 882.0, memory_length 2000, epsilon 0.010503460229811057, time 731.0, rides 125\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 5060, reward 800.0, memory_length 2000, epsilon 0.010494007115604227, time 735.0, rides 126\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 5061, reward 1067.0, memory_length 2000, epsilon 0.010484562509200183, time 723.0, rides 137\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 5062, reward 905.0, memory_length 2000, epsilon 0.010475126402941903, time 735.0, rides 137\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 5063, reward 964.0, memory_length 2000, epsilon 0.010465698789179256, time 728.0, rides 117\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 5064, reward 929.0, memory_length 2000, epsilon 0.010456279660268995, time 728.0, rides 120\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5065, reward 927.0, memory_length 2000, epsilon 0.010446869008574753, time 735.0, rides 142\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 5066, reward 937.0, memory_length 2000, epsilon 0.010437466826467035, time 731.0, rides 126\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5067, reward 894.0, memory_length 2000, epsilon 0.010428073106323214, time 730.0, rides 142\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 5068, reward 851.0, memory_length 2000, epsilon 0.010418687840527522, time 725.0, rides 125\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 5069, reward 813.0, memory_length 2000, epsilon 0.010409311021471046, time 723.0, rides 136\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5070, reward 868.0, memory_length 2000, epsilon 0.010399942641551722, time 739.0, rides 113\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 5071, reward 643.0, memory_length 2000, epsilon 0.010390582693174326, time 723.0, rides 129\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5072, reward 811.0, memory_length 2000, epsilon 0.01038123116875047, time 721.0, rides 136\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 5073, reward 991.0, memory_length 2000, epsilon 0.010371888060698595, time 729.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 5074, reward 750.0, memory_length 2000, epsilon 0.010362553361443965, time 730.0, rides 135\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 5075, reward 923.0, memory_length 2000, epsilon 0.010353227063418666, time 727.0, rides 129\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 5076, reward 999.0, memory_length 2000, epsilon 0.010343909159061589, time 725.0, rides 144\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 5077, reward 1009.0, memory_length 2000, epsilon 0.010334599640818433, time 727.0, rides 127\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 5078, reward 1063.0, memory_length 2000, epsilon 0.010325298501141696, time 726.0, rides 150\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 5079, reward 643.0, memory_length 2000, epsilon 0.010316005732490668, time 726.0, rides 142\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 5080, reward 1075.0, memory_length 2000, epsilon 0.010306721327331427, time 738.0, rides 133\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5081, reward 759.0, memory_length 2000, epsilon 0.010297445278136828, time 733.0, rides 138\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5082, reward 1030.0, memory_length 2000, epsilon 0.010288177577386506, time 733.0, rides 130\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 5083, reward 999.0, memory_length 2000, epsilon 0.010278918217566858, time 735.0, rides 148\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 5084, reward 836.0, memory_length 2000, epsilon 0.010269667191171047, time 727.0, rides 124\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5085, reward 863.0, memory_length 2000, epsilon 0.010260424490698994, time 729.0, rides 142\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 5086, reward 1159.0, memory_length 2000, epsilon 0.010251190108657365, time 727.0, rides 138\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5087, reward 1272.0, memory_length 2000, epsilon 0.010241964037559573, time 722.0, rides 131\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5088, reward 1031.0, memory_length 2000, epsilon 0.010232746269925768, time 727.0, rides 142\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5089, reward 973.0, memory_length 2000, epsilon 0.010223536798282836, time 727.0, rides 125\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5090, reward 696.0, memory_length 2000, epsilon 0.010214335615164381, time 725.0, rides 132\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 5091, reward 776.0, memory_length 2000, epsilon 0.010205142713110732, time 722.0, rides 136\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5092, reward 947.0, memory_length 2000, epsilon 0.010195958084668933, time 732.0, rides 141\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 5093, reward 991.0, memory_length 2000, epsilon 0.010186781722392731, time 735.0, rides 140\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 5094, reward 1093.0, memory_length 2000, epsilon 0.010177613618842578, time 725.0, rides 138\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 5095, reward 1032.0, memory_length 2000, epsilon 0.01016845376658562, time 733.0, rides 130\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5096, reward 951.0, memory_length 2000, epsilon 0.010159302158195693, time 727.0, rides 132\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 5097, reward 942.0, memory_length 2000, epsilon 0.010150158786253317, time 728.0, rides 128\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5098, reward 817.0, memory_length 2000, epsilon 0.010141023643345688, time 731.0, rides 136\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 5099, reward 996.0, memory_length 2000, epsilon 0.010131896722066677, time 724.0, rides 119\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 5100, reward 848.0, memory_length 2000, epsilon 0.010122778015016817, time 731.0, rides 137\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 5101, reward 1075.0, memory_length 2000, epsilon 0.0101136675148033, time 727.0, rides 134\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5102, reward 1037.0, memory_length 2000, epsilon 0.010104565214039978, time 740.0, rides 146\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5103, reward 700.0, memory_length 2000, epsilon 0.010095471105347342, time 725.0, rides 143\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 5104, reward 1334.0, memory_length 2000, epsilon 0.01008638518135253, time 727.0, rides 131\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5105, reward 1005.0, memory_length 2000, epsilon 0.010077307434689313, time 722.0, rides 122\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 5106, reward 961.0, memory_length 2000, epsilon 0.010068237857998092, time 732.0, rides 127\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 5107, reward 1135.0, memory_length 2000, epsilon 0.010059176443925894, time 728.0, rides 118\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 5108, reward 1173.0, memory_length 2000, epsilon 0.01005012318512636, time 737.0, rides 143\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5109, reward 920.0, memory_length 2000, epsilon 0.010041078074259746, time 730.0, rides 128\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5110, reward 962.0, memory_length 2000, epsilon 0.010032041103992912, time 728.0, rides 133\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 5111, reward 948.0, memory_length 2000, epsilon 0.010023012266999318, time 723.0, rides 134\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5112, reward 697.0, memory_length 2000, epsilon 0.010013991555959018, time 728.0, rides 114\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 5113, reward 976.0, memory_length 2000, epsilon 0.010004978963558654, time 724.0, rides 144\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 5114, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 114\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 5115, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 5116, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 5117, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 5118, reward 520.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 112\n",
      "Initial State is  [1, 7, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5119, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 5120, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5121, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 5122, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 5123, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 5124, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 5125, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 5126, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 5127, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 5128, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 5129, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 5130, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 5131, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 5132, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 5133, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 5134, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 5135, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 5136, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 5137, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5138, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 5139, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 5140, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 134\n",
      "Initial State is  [1, 19, 0]\n",
      "episode 5141, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5142, reward 659.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 123\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5143, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5144, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5145, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 5146, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 5147, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 5148, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 5149, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 5150, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 117\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5151, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 5152, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 5153, reward 556.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5154, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 5155, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 5156, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5157, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 5158, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 5159, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 5160, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5161, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 120\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 5162, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 111\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 5163, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5164, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 5165, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 5166, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 5167, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 5168, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 5169, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 5170, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 5171, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 5172, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 5173, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 5174, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5175, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 5176, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 5177, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5178, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 5179, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 5180, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 118\n",
      "Initial State is  [4, 3, 5]\n",
      "episode 5181, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5182, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 5183, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 7, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5184, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 150\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 5185, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 5186, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 5187, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [1, 7, 1]\n",
      "episode 5188, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5189, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 5190, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 5191, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 5192, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 5193, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5194, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 5195, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 5196, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 5197, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5198, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 5199, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 12, 3]\n",
      "episode 5200, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 5201, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5202, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 5203, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 5204, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 5205, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5206, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 5207, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5208, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 5209, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 5210, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 5211, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 5212, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 5213, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 5214, reward 1055.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5215, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 5216, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 5217, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5218, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 5219, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 5220, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 5221, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 5222, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 5223, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 5224, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 5225, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 5226, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5227, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5228, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 5229, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 5230, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5231, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 5232, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 5233, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 5234, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 5235, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 5236, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5237, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5238, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 5239, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 5240, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 5241, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 5242, reward 1462.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 5243, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5244, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5245, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 5246, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 5247, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [2, 10, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5248, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 5249, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5250, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 145\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 5251, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 5252, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5253, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 5254, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 5255, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 5256, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 5257, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 5258, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 5259, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 5260, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 5261, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 5262, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 5263, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5264, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 5265, reward 1446.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5266, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 5267, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 5268, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 5269, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5270, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 5271, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5272, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 157\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 5273, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 5274, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 5275, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 5276, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5277, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 150\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 5278, reward 731.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5279, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 5280, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 5281, reward 784.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5282, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 5283, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5284, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 5285, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 5286, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 5287, reward 1258.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 5288, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 5289, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5290, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 5291, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 5292, reward 607.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 5293, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 5294, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5295, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 5296, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 5297, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 5298, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 152\n",
      "Initial State is  [4, 16, 0]\n",
      "episode 5299, reward 619.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 5300, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 5301, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 153\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 5302, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5303, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 5304, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 5305, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 5306, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 5307, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 5308, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 5309, reward 1271.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 150\n",
      "Initial State is  [1, 1, 4]\n",
      "episode 5310, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 5311, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 5312, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 122\n",
      "Initial State is  [1, 9, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5313, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 5314, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5315, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 5316, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 5317, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5318, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 5319, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5320, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 5321, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5322, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 5323, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 5324, reward 696.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 116\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 5325, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 5326, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 5327, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5328, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 5329, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 125\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 5330, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 137\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 5331, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 5332, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 5333, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 5334, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 5335, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5336, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [0, 6, 4]\n",
      "episode 5337, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 5338, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 5339, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 5340, reward 763.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 5341, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 5342, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 14, 5]\n",
      "episode 5343, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 5344, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 5345, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 147\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 5346, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 5347, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 5348, reward 1312.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5349, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 120\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 5350, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5351, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5352, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 5353, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 5354, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 9, 2]\n",
      "episode 5355, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 745.0, rides 129\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 5356, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5357, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 134\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5358, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 5359, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 5360, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 5361, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5362, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 5363, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5364, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 5365, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5366, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 5367, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 5368, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 5369, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 5370, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5371, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 5372, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 5373, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 5374, reward 688.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 9, 1]\n",
      "episode 5375, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 5376, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 5377, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 2, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5378, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 144\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 5379, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 5380, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 154\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 5381, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 20, 2]\n",
      "episode 5382, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 5383, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 5384, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 130\n",
      "Initial State is  [4, 22, 1]\n",
      "episode 5385, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 5386, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 5387, reward 466.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 5388, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 5389, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 5390, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 5391, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5392, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 5393, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 5394, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 5395, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 161\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 5396, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 5397, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 5398, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 5399, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 5400, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 5401, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 5402, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 117\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 5403, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5404, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 5405, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 5406, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 5407, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 5408, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 5409, reward 560.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 5410, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5411, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5412, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 5413, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 5414, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 5415, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 5416, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 5417, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 5418, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 5419, reward 1338.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5420, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 5421, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 5422, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 130\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5423, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 5424, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 5425, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 8, 3]\n",
      "episode 5426, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 11, 4]\n",
      "episode 5427, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 152\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5428, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 5429, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 5430, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 5431, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 5432, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 5433, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 5434, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5435, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 5436, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5437, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 5438, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 5439, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 5440, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 5441, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5442, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [1, 16, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5443, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 5444, reward 477.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 5445, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 5446, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 127\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 5447, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 5448, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 5449, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5450, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 5451, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 148\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 5452, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 5453, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 5454, reward 1316.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 5455, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 5456, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 5457, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 6, 1]\n",
      "episode 5458, reward 1257.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 5459, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 5460, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 5461, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 5462, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 5463, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5464, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 5465, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 12, 0]\n",
      "episode 5466, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 5467, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 5468, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 5469, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5470, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5471, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5472, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 5473, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 5474, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 5475, reward 645.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 5476, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 6, 0]\n",
      "episode 5477, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 5478, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 5479, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 5480, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 5481, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5482, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 5483, reward 1370.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5484, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 153\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 5485, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 5486, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 5487, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5488, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 5489, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 5490, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 5491, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 5492, reward 1097.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 5493, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 5494, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5495, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5496, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 5497, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 5498, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 5499, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 5500, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 5501, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 143\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 5502, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5503, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 151\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 5504, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5505, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 5506, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 112\n",
      "Initial State is  [4, 7, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5507, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 5508, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 5509, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5510, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 5511, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 5512, reward 618.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 5513, reward 620.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 5514, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 5515, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 117\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 5516, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 5517, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5518, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 5519, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 5520, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 135\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5521, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 5522, reward 1331.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 149\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 5523, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 5524, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 5525, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5526, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 5527, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 5528, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 5529, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 5530, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 5531, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 5532, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 5533, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5534, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 5535, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5536, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 5537, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 5538, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 5539, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 5540, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 5541, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 5542, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 5543, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 5544, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 5545, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 5546, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 5547, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 5548, reward 1252.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 5549, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 5550, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 5551, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 5552, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 5553, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5554, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 5555, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5556, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5557, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [3, 14, 6]\n",
      "episode 5558, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 137\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 5559, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 5560, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 5561, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 5562, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 5563, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 5564, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 5565, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5566, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 139\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 5567, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 5568, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 5569, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 5570, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5571, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 123\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 5572, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 5573, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 5574, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5575, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 117\n",
      "Initial State is  [3, 14, 1]\n",
      "episode 5576, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 5577, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 5578, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 5579, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 5580, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 5581, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 144\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5582, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 15, 4]\n",
      "episode 5583, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 5584, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 5585, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5586, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [0, 14, 2]\n",
      "episode 5587, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 5588, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5589, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 5590, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 156\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 5591, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 136\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 5592, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 5593, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 5594, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 5595, reward 654.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 5596, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5597, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 5598, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5599, reward 862.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 5600, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5601, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5602, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 5603, reward 723.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 19, 4]\n",
      "episode 5604, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 5605, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5606, reward 674.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 148\n",
      "Initial State is  [3, 8, 1]\n",
      "episode 5607, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5608, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 5609, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [3, 2, 5]\n",
      "episode 5610, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 5611, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 5612, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 17, 6]\n",
      "episode 5613, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 140\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 5614, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 5615, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 8, 2]\n",
      "episode 5616, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 130\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 5617, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 5618, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 123\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 5619, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 13, 0]\n",
      "episode 5620, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 153\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5621, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 5622, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 5623, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 5624, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 5625, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 116\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5626, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 5627, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5628, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 5629, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 124\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 5630, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 5631, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 5632, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 5633, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 5634, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 5635, reward 634.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5636, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 5637, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 5638, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 5639, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 5640, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 5641, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5642, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 5643, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 5644, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 5645, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 5646, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 153\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 5647, reward 603.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 5648, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5649, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 5650, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 5651, reward 1340.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 5652, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 5653, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 5654, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 126\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 5655, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 5656, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 129\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 5657, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 150\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 5658, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5659, reward 1248.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 21, 4]\n",
      "episode 5660, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 5661, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 5662, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 5663, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 5664, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 5665, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 5666, reward 764.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 5667, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 5668, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5669, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5670, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 5671, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 153\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 5672, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 5673, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 5674, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 5675, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 126\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 5676, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 12, 6]\n",
      "episode 5677, reward 1259.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 5678, reward 874.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 5679, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 5680, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 5681, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 5682, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 5683, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 156\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 5684, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 156\n",
      "Initial State is  [4, 5, 5]\n",
      "episode 5685, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 5686, reward 1037.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5687, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 5688, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 5689, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 5690, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 5691, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 5692, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 5693, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 5694, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 5695, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 121\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 5696, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 5697, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 5698, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 130\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 5699, reward 1184.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [4, 7, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5700, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 0, 0]\n",
      "episode 5701, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 129\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 5702, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 5703, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 150\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 5704, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 147\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 5705, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5706, reward 1212.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 5707, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 5708, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 5709, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5710, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 5711, reward 1124.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 5712, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 5713, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 5714, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 5715, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 5716, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 5717, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 5718, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 5719, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 5720, reward 807.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 20, 2]\n",
      "episode 5721, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 5722, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 5723, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 5724, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 5725, reward 1291.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 5726, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 129\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 5727, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 0, 6]\n",
      "episode 5728, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 5729, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5730, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 5731, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5732, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 5733, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 5734, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 5735, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 5736, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 5737, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 5738, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 5739, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 5740, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 113\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5741, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5742, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 124\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 5743, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 5744, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 5745, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 5746, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5747, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 5748, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 5749, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 124\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 5750, reward 1272.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 5751, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 5752, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [0, 15, 1]\n",
      "episode 5753, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 21, 4]\n",
      "episode 5754, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 5755, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5756, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 5757, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 5758, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5759, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 5760, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 134\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5761, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 5762, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 5763, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 5764, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [2, 7, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5765, reward 645.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5766, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 5767, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 5768, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 5769, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5770, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 5771, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 5772, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 5773, reward 1334.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 5774, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 136\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 5775, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 5776, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 5777, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 152\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 5778, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 5779, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 5780, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 5781, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [1, 10, 1]\n",
      "episode 5782, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 145\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 5783, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 5784, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 5785, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5786, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 5787, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5788, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 5789, reward 1516.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 145\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 5790, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 5791, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 132\n",
      "Initial State is  [3, 10, 5]\n",
      "episode 5792, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 5793, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 8, 4]\n",
      "episode 5794, reward 633.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 5795, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 5796, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 5797, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 137\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 5798, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 5799, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 5800, reward 601.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 5801, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 5802, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 5803, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5804, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 5805, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 5806, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 5807, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 5808, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 5809, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 5810, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 5811, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 5812, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 5813, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 5814, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 5815, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 5816, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 5817, reward 1066.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 5818, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 121\n",
      "Initial State is  [4, 23, 3]\n",
      "episode 5819, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 5820, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 5821, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [1, 1, 0]\n",
      "episode 5822, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 5823, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 5824, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 11, 0]\n",
      "episode 5825, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 5826, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 5827, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 5828, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 13, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5829, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 5830, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 5831, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 5832, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 5833, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 19, 4]\n",
      "episode 5834, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 5835, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 5836, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 140\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 5837, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 5838, reward 657.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 5839, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 140\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5840, reward 1356.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5841, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 5842, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5843, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 5844, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 5845, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 5846, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 5847, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 5848, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 5849, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 5850, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 5851, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 5852, reward 1235.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 5853, reward 1277.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5854, reward 615.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5855, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 5856, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 5857, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 5858, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 5859, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [3, 21, 3]\n",
      "episode 5860, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 5861, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 148\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 5862, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 5863, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 5864, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 5865, reward 1348.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 5866, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 5867, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 5868, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 5869, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 0, 6]\n",
      "episode 5870, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 5871, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 5872, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 5873, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 5874, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 5875, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 5876, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 5877, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 5878, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 5879, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 5880, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 5881, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 5882, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 5883, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 5884, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 5885, reward 1231.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 139\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 5886, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 5887, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 5888, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 5889, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 5890, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 16, 5]\n",
      "episode 5891, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 5892, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [3, 4, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5893, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 5894, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 5895, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [2, 12, 4]\n",
      "episode 5896, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 5897, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 5898, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 18, 1]\n",
      "episode 5899, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 5900, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 5901, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 5902, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 5903, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 5904, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 5905, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 5906, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 5907, reward 1245.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 5908, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 5909, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 5910, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 5911, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 5912, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 5913, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 5914, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 5915, reward 1298.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 5916, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 5917, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 5918, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 5919, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 5920, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5921, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 5922, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 5923, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 5924, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 5925, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 5926, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 5927, reward 644.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 5928, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 5929, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 5930, reward 1223.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5931, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 5932, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 153\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 5933, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 5934, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 5935, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 5936, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 5937, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 5938, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 5939, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 5940, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 118\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 5941, reward 684.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 5942, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 5943, reward 1186.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 5944, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5945, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 5946, reward 1200.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 5947, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 5948, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 5949, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 120\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 5950, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [2, 22, 1]\n",
      "episode 5951, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 5952, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 5953, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 5954, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 120\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 5955, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 5956, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [4, 14, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 5957, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 5958, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5959, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 5960, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 10, 0]\n",
      "episode 5961, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 5962, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 125\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 5963, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 0, 5]\n",
      "episode 5964, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 5965, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 5966, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 5967, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 5968, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 5969, reward 592.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 5970, reward 1159.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 5971, reward 456.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 5972, reward 1225.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 5973, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 12, 5]\n",
      "episode 5974, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 18, 3]\n",
      "episode 5975, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 5976, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 12, 4]\n",
      "episode 5977, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 5978, reward 625.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 5979, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 5980, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 5981, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 154\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 5982, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 162\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 5983, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 5984, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 5985, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 5986, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 150\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 5987, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 5988, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 19, 3]\n",
      "episode 5989, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 5990, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 5991, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 5992, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 5993, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 5994, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 19, 2]\n",
      "episode 5995, reward 733.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 5996, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 146\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 5997, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 5998, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 5999, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 6000, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 6001, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [4, 1, 0]\n",
      "episode 6002, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 6003, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 6004, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6005, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 6006, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6007, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 6008, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6009, reward 1341.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 16, 5]\n",
      "episode 6010, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 6011, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6012, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 6013, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 6014, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 6015, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 6016, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 6017, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 21, 2]\n",
      "episode 6018, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 149\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 6019, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6020, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [4, 23, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6021, reward 1166.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 149\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6022, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 6023, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 6024, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 6025, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 6026, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 6027, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6028, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 6029, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 6030, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6031, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 15, 0]\n",
      "episode 6032, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6033, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 127\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 6034, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6035, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 6036, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 6037, reward 558.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6038, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 15, 2]\n",
      "episode 6039, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 15, 3]\n",
      "episode 6040, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6041, reward 1056.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 16, 4]\n",
      "episode 6042, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 5, 1]\n",
      "episode 6043, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 6044, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 6045, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 6046, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 6047, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 6048, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [3, 0, 1]\n",
      "episode 6049, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 3, 5]\n",
      "episode 6050, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 6051, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 6052, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 6053, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 6054, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 6055, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6056, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6057, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 6058, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 6059, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 6060, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6061, reward 1329.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [2, 14, 2]\n",
      "episode 6062, reward 573.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 6063, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [3, 20, 4]\n",
      "episode 6064, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 6065, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6066, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6067, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 6068, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6069, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 18, 1]\n",
      "episode 6070, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 6071, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 137\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 6072, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 128\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 6073, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 6074, reward 1232.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6075, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 149\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 6076, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 6077, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [1, 5, 4]\n",
      "episode 6078, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 6079, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6080, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 6081, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 6082, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 6083, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 125\n",
      "Initial State is  [3, 21, 2]\n",
      "episode 6084, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [1, 10, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6085, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 6086, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 6087, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 6088, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [0, 1, 1]\n",
      "episode 6089, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 17, 5]\n",
      "episode 6090, reward 1269.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 6091, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6092, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 6093, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 6094, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6095, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 6096, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 6097, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [1, 17, 2]\n",
      "episode 6098, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 6099, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 6100, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 6101, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 6102, reward 1249.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 148\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6103, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 6104, reward 799.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6105, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6106, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 6107, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6108, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 6109, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 6110, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 20, 1]\n",
      "episode 6111, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 6112, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 6113, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 147\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6114, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 6115, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 6116, reward 603.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 6117, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 6118, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 6119, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 6120, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 6121, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [2, 19, 2]\n",
      "episode 6122, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 6123, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6124, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 6125, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 6126, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 6127, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6128, reward 824.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 6129, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 6130, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 153\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 6131, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 6132, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 6133, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 147\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 6134, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 6135, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [2, 20, 4]\n",
      "episode 6136, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 6137, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 6138, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 14, 4]\n",
      "episode 6139, reward 1274.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 6140, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 6141, reward 1133.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 6142, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 6143, reward 665.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 6144, reward 817.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 6145, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 6146, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 6147, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 6148, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 6149, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 15, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6150, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [0, 7, 2]\n",
      "episode 6151, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 6152, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 6153, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 6154, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6155, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 6156, reward 1171.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 143\n",
      "Initial State is  [2, 1, 3]\n",
      "episode 6157, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 6158, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 6159, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [3, 15, 6]\n",
      "episode 6160, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6161, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 6162, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 6163, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 6164, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 6165, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6166, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 6167, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 6168, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 6169, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 6170, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 6171, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 6172, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 6173, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 148\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6174, reward 1131.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 6175, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 6176, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 149\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 6177, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 130\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 6178, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [0, 11, 3]\n",
      "episode 6179, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 6180, reward 1318.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 6181, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 6182, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 152\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 6183, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 6184, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 6185, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 6186, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6187, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6188, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 6189, reward 1354.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 3, 6]\n",
      "episode 6190, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 6191, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 20, 4]\n",
      "episode 6192, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 138\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 6193, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 6194, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [1, 10, 3]\n",
      "episode 6195, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6196, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 6197, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 6198, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 153\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 6199, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 6200, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 6201, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 6202, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [2, 17, 4]\n",
      "episode 6203, reward 1340.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 6204, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6205, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6206, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 6207, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 6208, reward 1335.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6209, reward 977.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6210, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 6211, reward 776.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6212, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 6213, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6214, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 6215, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 6216, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 6217, reward 1156.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [3, 21, 0]\n",
      "episode 6218, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 6219, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 6220, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 6221, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 14, 6]\n",
      "episode 6222, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 115\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 6223, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6224, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 6225, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6226, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 6227, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6228, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 6229, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 140\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 6230, reward 587.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6231, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [0, 8, 5]\n",
      "episode 6232, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 128\n",
      "Initial State is  [1, 0, 5]\n",
      "episode 6233, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 6234, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6235, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 6236, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 6237, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 6238, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 6239, reward 1180.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 6240, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 142\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 6241, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 6242, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 6243, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 6244, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 6245, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 6246, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 134\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6247, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [0, 23, 1]\n",
      "episode 6248, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6249, reward 1214.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 6250, reward 1101.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6251, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 6252, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6253, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 6254, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 6255, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 3, 4]\n",
      "episode 6256, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 6257, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 6258, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 6259, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6260, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 6261, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 6262, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 6263, reward 1288.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 6264, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 6265, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6266, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 6267, reward 1297.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 6268, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 6269, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 6270, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 8, 1]\n",
      "episode 6271, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 6272, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 23, 2]\n",
      "episode 6273, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 6274, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 6275, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 6276, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 6277, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 6278, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 124\n",
      "Initial State is  [1, 21, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6279, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6280, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6281, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 6282, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 140\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 6283, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [3, 13, 5]\n",
      "episode 6284, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 123\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6285, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 6286, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6287, reward 715.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 6288, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 6289, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 6290, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 16, 1]\n",
      "episode 6291, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 6292, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 6293, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 6294, reward 1061.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 6295, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [3, 5, 0]\n",
      "episode 6296, reward 758.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 6297, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 6298, reward 709.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 6299, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6300, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6301, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 133\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6302, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 6303, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 6304, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 6305, reward 701.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 132\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 6306, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6307, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 6308, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6309, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [2, 14, 3]\n",
      "episode 6310, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 6311, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 6312, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 118\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 6313, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [3, 10, 0]\n",
      "episode 6314, reward 793.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 6315, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 6316, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6317, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 147\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6318, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 6319, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 6320, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 6321, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 133\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6322, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 6323, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6324, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 6325, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 6326, reward 678.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 116\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 6327, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 6328, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 144\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 6329, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 6330, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 135\n",
      "Initial State is  [4, 2, 1]\n",
      "episode 6331, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6332, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6333, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 6334, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 6335, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 145\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 6336, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 6337, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 6338, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 137\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 6339, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 151\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 6340, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 6341, reward 1276.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 142\n",
      "Initial State is  [0, 3, 1]\n",
      "episode 6342, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 6343, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 16, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6344, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 9, 1]\n",
      "episode 6345, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 135\n",
      "Initial State is  [3, 16, 1]\n",
      "episode 6346, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [3, 19, 2]\n",
      "episode 6347, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 6348, reward 1216.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 6349, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6350, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 6351, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 6352, reward 643.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 6353, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 6354, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 146\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 6355, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 6356, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 6357, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 6358, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 149\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 6359, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 6360, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 6361, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 6362, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 6363, reward 1358.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 148\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 6364, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 6365, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6366, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 149\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 6367, reward 1027.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 6368, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 8, 3]\n",
      "episode 6369, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6370, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 6371, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 6372, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 6373, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 6374, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6375, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 6376, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 130\n",
      "Initial State is  [1, 10, 4]\n",
      "episode 6377, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 11, 0]\n",
      "episode 6378, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 6379, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 6380, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 6381, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 6382, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 6383, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 156\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 6384, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 6385, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 6386, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6387, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 6388, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 6389, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6390, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 6391, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6392, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 3, 3]\n",
      "episode 6393, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6394, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6395, reward 596.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 6396, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 6397, reward 892.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 6398, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 6399, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 6400, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 6401, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [1, 8, 3]\n",
      "episode 6402, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 6403, reward 1120.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [4, 7, 6]\n",
      "episode 6404, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6405, reward 1284.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6406, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6407, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 3, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6408, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 6409, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 6410, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 6411, reward 857.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 120\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 6412, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6413, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [3, 4, 5]\n",
      "episode 6414, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 112\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 6415, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6416, reward 615.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 6417, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6418, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [4, 12, 4]\n",
      "episode 6419, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 6420, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 6421, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 7, 3]\n",
      "episode 6422, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 6423, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 6424, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 117\n",
      "Initial State is  [3, 17, 5]\n",
      "episode 6425, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 141\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6426, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 6427, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 6428, reward 669.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6429, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 6430, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 6431, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 6432, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 6433, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 22, 3]\n",
      "episode 6434, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 6435, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 6436, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 6437, reward 1032.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 6, 4]\n",
      "episode 6438, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 6439, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 22, 0]\n",
      "episode 6440, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [4, 7, 2]\n",
      "episode 6441, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6442, reward 635.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 145\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 6443, reward 762.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 6444, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 6445, reward 1242.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 145\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6446, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 6447, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6448, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 6449, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 6450, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 6451, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 6452, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 6453, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6454, reward 640.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 6455, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 6456, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 6457, reward 1080.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 6458, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6459, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 6460, reward 1144.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 117\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 6461, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 6462, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 6463, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [2, 20, 3]\n",
      "episode 6464, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 6465, reward 1261.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 147\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 6466, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 6467, reward 1308.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6468, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 6469, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 119\n",
      "Initial State is  [2, 5, 2]\n",
      "episode 6470, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 6471, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 5, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6472, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 6473, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 6474, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 6475, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 6476, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 18, 0]\n",
      "episode 6477, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 6478, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 6479, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 6480, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 6481, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 6482, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6483, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 6484, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 6485, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [1, 23, 5]\n",
      "episode 6486, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [3, 15, 3]\n",
      "episode 6487, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6488, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [0, 1, 4]\n",
      "episode 6489, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6490, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 6491, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 6492, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 2, 6]\n",
      "episode 6493, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [2, 14, 6]\n",
      "episode 6494, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6495, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 6496, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 6497, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 6498, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 6499, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 6500, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 6501, reward 773.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 6502, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 6503, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 6504, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [3, 6, 5]\n",
      "episode 6505, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 110\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 6506, reward 881.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 6507, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 122\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 6508, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 6509, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 6510, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 16, 0]\n",
      "episode 6511, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6512, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 6513, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 152\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6514, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [2, 18, 4]\n",
      "episode 6515, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 6516, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 6517, reward 551.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 119\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6518, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 6519, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 6520, reward 1282.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 117\n",
      "Initial State is  [2, 5, 3]\n",
      "episode 6521, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 6522, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 6523, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 6524, reward 782.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 6525, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 6526, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 6527, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 120\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 6528, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [4, 20, 1]\n",
      "episode 6529, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 13, 5]\n",
      "episode 6530, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [2, 15, 0]\n",
      "episode 6531, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6532, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6533, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 131\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 6534, reward 819.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 119\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 6535, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 126\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 6536, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 147\n",
      "Initial State is  [3, 9, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6537, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 153\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 6538, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 18, 2]\n",
      "episode 6539, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6540, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [2, 19, 1]\n",
      "episode 6541, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 133\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6542, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 9, 3]\n",
      "episode 6543, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 6544, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 6545, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 6546, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6547, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 6548, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 6549, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6550, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6551, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6552, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 18, 2]\n",
      "episode 6553, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 148\n",
      "Initial State is  [0, 21, 0]\n",
      "episode 6554, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6555, reward 1314.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 6556, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 6557, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 6558, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 6559, reward 1380.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6560, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 6561, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 6562, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6563, reward 730.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 6564, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 116\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6565, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 2, 2]\n",
      "episode 6566, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 146\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 6567, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 19, 1]\n",
      "episode 6568, reward 1226.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 6569, reward 755.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 6570, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 6571, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 6572, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 6573, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 146\n",
      "Initial State is  [4, 15, 3]\n",
      "episode 6574, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 141\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6575, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 146\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 6576, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 6577, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 6578, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 6579, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 6580, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 6581, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 6582, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 6583, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6584, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6585, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 6586, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [4, 4, 5]\n",
      "episode 6587, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6588, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 6589, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6590, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 6591, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 6592, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 8, 3]\n",
      "episode 6593, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6594, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 6595, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 126\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 6596, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 6597, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 6598, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [4, 8, 1]\n",
      "episode 6599, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 142\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6600, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 114\n",
      "Initial State is  [0, 18, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6601, reward 740.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [2, 10, 1]\n",
      "episode 6602, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 6603, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 6604, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 6605, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6606, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 6607, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6608, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6609, reward 767.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 6610, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6611, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 6612, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 6613, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [3, 13, 6]\n",
      "episode 6614, reward 999.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 6615, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 6616, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [0, 2, 1]\n",
      "episode 6617, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 151\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6618, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 6619, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 6620, reward 798.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 6621, reward 920.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 6622, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 6623, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 8, 6]\n",
      "episode 6624, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6625, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 132\n",
      "Initial State is  [2, 1, 6]\n",
      "episode 6626, reward 462.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [1, 12, 0]\n",
      "episode 6627, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 6628, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [1, 7, 2]\n",
      "episode 6629, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 6630, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 118\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 6631, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [1, 14, 5]\n",
      "episode 6632, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6633, reward 624.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 6634, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 6635, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 6636, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 6637, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6638, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 6639, reward 845.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 6640, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 20, 5]\n",
      "episode 6641, reward 1453.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 6642, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 6643, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 6644, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 118\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 6645, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [4, 20, 6]\n",
      "episode 6646, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 6647, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 6648, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [2, 6, 5]\n",
      "episode 6649, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6650, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 9, 6]\n",
      "episode 6651, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 114\n",
      "Initial State is  [4, 23, 2]\n",
      "episode 6652, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 6653, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 6654, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 116\n",
      "Initial State is  [3, 15, 2]\n",
      "episode 6655, reward 853.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 119\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 6656, reward 930.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 6657, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 6658, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [1, 3, 0]\n",
      "episode 6659, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 6660, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6661, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 6662, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 6663, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6664, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 6665, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [0, 11, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6666, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6667, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 6668, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 124\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 6669, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 6670, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 5, 3]\n",
      "episode 6671, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 136\n",
      "Initial State is  [4, 17, 3]\n",
      "episode 6672, reward 735.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 6673, reward 593.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 9, 0]\n",
      "episode 6674, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6675, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 14, 4]\n",
      "episode 6676, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6677, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 6678, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 132\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 6679, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 6680, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 1, 5]\n",
      "episode 6681, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 6682, reward 1158.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 6683, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 6684, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 6685, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6686, reward 1202.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 6687, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 6688, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6689, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 6690, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 7, 1]\n",
      "episode 6691, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 6692, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 6693, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 6694, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 135\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 6695, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [0, 17, 4]\n",
      "episode 6696, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 6697, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 140\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 6698, reward 821.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6699, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 6700, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6701, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 6702, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 6703, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 6704, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 6705, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 6706, reward 778.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 6707, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6708, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 6709, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 6710, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 6711, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 153\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 6712, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 6713, reward 1009.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 6714, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 6715, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 6716, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 6717, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 6718, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 6719, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 6720, reward 648.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 150\n",
      "Initial State is  [4, 13, 3]\n",
      "episode 6721, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 11, 5]\n",
      "episode 6722, reward 966.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [4, 0, 0]\n",
      "episode 6723, reward 1119.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6724, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6725, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 6726, reward 475.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 117\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 6727, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 6728, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 140\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 6729, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 6730, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 11, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6731, reward 481.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 6732, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 6733, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 6734, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 6735, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 148\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 6736, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [0, 15, 3]\n",
      "episode 6737, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 6738, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 6739, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 6740, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 6741, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 6742, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 6743, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 6744, reward 630.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6745, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 147\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 6746, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6747, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 6748, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 6749, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 6750, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 6751, reward 658.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 14, 2]\n",
      "episode 6752, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 6753, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [4, 4, 6]\n",
      "episode 6754, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 6755, reward 1110.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 6756, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 6757, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 6758, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 6759, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 6760, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 144\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 6761, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 6762, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6763, reward 495.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 6764, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 119\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 6765, reward 1310.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 6766, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 6767, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 6768, reward 1270.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6769, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 6770, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 125\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 6771, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 6772, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 6773, reward 691.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 6774, reward 734.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 125\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 6775, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 20, 3]\n",
      "episode 6776, reward 918.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 6777, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 16, 3]\n",
      "episode 6778, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 6779, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 6780, reward 680.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 16, 2]\n",
      "episode 6781, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6782, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 121\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 6783, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [3, 14, 0]\n",
      "episode 6784, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 6785, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 20, 6]\n",
      "episode 6786, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 145\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 6787, reward 970.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 6788, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 6789, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 109\n",
      "Initial State is  [1, 20, 6]\n",
      "episode 6790, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 6791, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [2, 22, 3]\n",
      "episode 6792, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 110\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 6793, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 20, 1]\n",
      "episode 6794, reward 741.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 121\n",
      "Initial State is  [3, 12, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6795, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 6796, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6797, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 6798, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6799, reward 1162.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 14, 4]\n",
      "episode 6800, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 6801, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 6802, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 130\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 6803, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 6804, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6805, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [4, 1, 1]\n",
      "episode 6806, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 6807, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [1, 18, 0]\n",
      "episode 6808, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 6809, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 6810, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 6811, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 114\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 6812, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 6813, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 6814, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 129\n",
      "Initial State is  [1, 23, 4]\n",
      "episode 6815, reward 1172.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [1, 2, 1]\n",
      "episode 6816, reward 832.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 114\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 6817, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 6818, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6819, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 6820, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [2, 13, 2]\n",
      "episode 6821, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 6822, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 6823, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 121\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 6824, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 6825, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 119\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 6826, reward 724.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 6827, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 6828, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 6829, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 6830, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 115\n",
      "Initial State is  [3, 7, 2]\n",
      "episode 6831, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 4, 2]\n",
      "episode 6832, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 6833, reward 683.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 6834, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 3, 2]\n",
      "episode 6835, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 6836, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [4, 9, 6]\n",
      "episode 6837, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6838, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 6839, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [0, 5, 6]\n",
      "episode 6840, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 6841, reward 960.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [2, 19, 0]\n",
      "episode 6842, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [4, 21, 5]\n",
      "episode 6843, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 141\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 6844, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 127\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 6845, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 6846, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 6847, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 6848, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 6849, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 125\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 6850, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 6851, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 21, 6]\n",
      "episode 6852, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 14, 3]\n",
      "episode 6853, reward 1295.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 6854, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 120\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 6855, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 6856, reward 917.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 6857, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 138\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 6858, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 6859, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 123\n",
      "Initial State is  [4, 0, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6860, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 6861, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 6862, reward 667.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 10, 3]\n",
      "episode 6863, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 6864, reward 954.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 6865, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 138\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 6866, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 13, 0]\n",
      "episode 6867, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [2, 11, 1]\n",
      "episode 6868, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 6869, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 6870, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 6871, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 743.0, rides 136\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 6872, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 6873, reward 716.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 134\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 6874, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 152\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 6875, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 148\n",
      "Initial State is  [4, 13, 1]\n",
      "episode 6876, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 6877, reward 713.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 6878, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 6879, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 6880, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 6881, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 7, 0]\n",
      "episode 6882, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 120\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 6883, reward 1139.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 3, 4]\n",
      "episode 6884, reward 692.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6885, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 6886, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [0, 20, 4]\n",
      "episode 6887, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 6888, reward 703.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 6889, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 118\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 6890, reward 1297.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 6891, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 12, 0]\n",
      "episode 6892, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [3, 18, 6]\n",
      "episode 6893, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 6894, reward 637.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 22, 3]\n",
      "episode 6895, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 6896, reward 753.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 132\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 6897, reward 1137.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [3, 22, 5]\n",
      "episode 6898, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 114\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 6899, reward 866.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 6900, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 121\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 6901, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6902, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 123\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 6903, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 6904, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 123\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6905, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 6906, reward 1038.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 131\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 6907, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 6908, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 6909, reward 622.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 6910, reward 697.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 117\n",
      "Initial State is  [1, 14, 2]\n",
      "episode 6911, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 6912, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [4, 1, 5]\n",
      "episode 6913, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 6914, reward 714.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6915, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 128\n",
      "Initial State is  [2, 15, 6]\n",
      "episode 6916, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 6917, reward 1219.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 6918, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 6, 6]\n",
      "episode 6919, reward 1297.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 20, 6]\n",
      "episode 6920, reward 1265.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 138\n",
      "Initial State is  [1, 13, 2]\n",
      "episode 6921, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [4, 2, 4]\n",
      "episode 6922, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6923, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [0, 13, 3]\n",
      "episode 6924, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 11, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6925, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 6926, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 23, 2]\n",
      "episode 6927, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 6928, reward 1296.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 143\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 6929, reward 1255.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 142\n",
      "Initial State is  [2, 14, 0]\n",
      "episode 6930, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 120\n",
      "Initial State is  [4, 9, 2]\n",
      "episode 6931, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 6932, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6933, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 143\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 6934, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 150\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 6935, reward 1148.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [2, 11, 6]\n",
      "episode 6936, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 6937, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 16, 2]\n",
      "episode 6938, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 6939, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 144\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 6940, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 140\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 6941, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 142\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 6942, reward 833.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 6943, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 6944, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 138\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 6945, reward 1052.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 6946, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 6947, reward 1193.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 6948, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 6949, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 121\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 6950, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 6951, reward 848.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 6952, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 8, 3]\n",
      "episode 6953, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 6954, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 6955, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 6956, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [4, 14, 0]\n",
      "episode 6957, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 6958, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 139\n",
      "Initial State is  [3, 3, 5]\n",
      "episode 6959, reward 746.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 6960, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 6961, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 155\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 6962, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 139\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 6963, reward 1287.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 6964, reward 1114.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [0, 6, 1]\n",
      "episode 6965, reward 1306.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 1, 2]\n",
      "episode 6966, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 146\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 6967, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 6968, reward 1039.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 6969, reward 749.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 6970, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 122\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 6971, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 6972, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 6973, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 6974, reward 972.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [3, 17, 1]\n",
      "episode 6975, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 6976, reward 803.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [2, 13, 4]\n",
      "episode 6977, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 6978, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 136\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 6979, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 129\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 6980, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 6981, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 6982, reward 779.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [3, 14, 4]\n",
      "episode 6983, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 6984, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 17, 4]\n",
      "episode 6985, reward 899.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 6986, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 6987, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 6988, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 5, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 6989, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 6990, reward 1349.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 6991, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 6992, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 7, 3]\n",
      "episode 6993, reward 685.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 6994, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 150\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 6995, reward 1413.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 6996, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 6997, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 6998, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 6999, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [1, 14, 1]\n",
      "episode 7000, reward 1355.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 4, 0]\n",
      "episode 7001, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 19, 5]\n",
      "episode 7002, reward 1142.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7003, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 7004, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 0, 1]\n",
      "episode 7005, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 143\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 7006, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 7007, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 10, 4]\n",
      "episode 7008, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 145\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7009, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 126\n",
      "Initial State is  [1, 20, 0]\n",
      "episode 7010, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 7011, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [2, 9, 3]\n",
      "episode 7012, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7013, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 7014, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 7015, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7016, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 7017, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7018, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7019, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 120\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 7020, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 141\n",
      "Initial State is  [2, 6, 2]\n",
      "episode 7021, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7022, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [0, 13, 2]\n",
      "episode 7023, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 7024, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 7025, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 150\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 7026, reward 760.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 7027, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 117\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 7028, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 11, 6]\n",
      "episode 7029, reward 856.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7030, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 7031, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7032, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7033, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 23, 6]\n",
      "episode 7034, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7035, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 7036, reward 664.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7037, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 7038, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 153\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 7039, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7040, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 7041, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 7042, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 125\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 7043, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 7044, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 7045, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7046, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 122\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 7047, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 7048, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [1, 18, 3]\n",
      "episode 7049, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 7050, reward 1342.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 120\n",
      "Initial State is  [3, 0, 2]\n",
      "episode 7051, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7052, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 7053, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 131\n",
      "Initial State is  [1, 6, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7054, reward 768.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 7055, reward 1062.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 7056, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 132\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 7057, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [4, 22, 3]\n",
      "episode 7058, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [4, 12, 0]\n",
      "episode 7059, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 7060, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7061, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [4, 22, 6]\n",
      "episode 7062, reward 1203.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 7063, reward 1104.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 4, 1]\n",
      "episode 7064, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [3, 2, 4]\n",
      "episode 7065, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 11, 6]\n",
      "episode 7066, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 135\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 7067, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7068, reward 791.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7069, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 149\n",
      "Initial State is  [2, 21, 5]\n",
      "episode 7070, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [4, 2, 3]\n",
      "episode 7071, reward 1134.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 7072, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [4, 5, 6]\n",
      "episode 7073, reward 694.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 16, 2]\n",
      "episode 7074, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 145\n",
      "Initial State is  [4, 15, 4]\n",
      "episode 7075, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7076, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 134\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7077, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 7078, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 146\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7079, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 7080, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 1, 0]\n",
      "episode 7081, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 117\n",
      "Initial State is  [0, 17, 2]\n",
      "episode 7082, reward 962.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 7083, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [4, 3, 1]\n",
      "episode 7084, reward 1221.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 7085, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7086, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [1, 15, 0]\n",
      "episode 7087, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [3, 4, 4]\n",
      "episode 7088, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 7089, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 18, 3]\n",
      "episode 7090, reward 783.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 7091, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7092, reward 818.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 138\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7093, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 7094, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 127\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 7095, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 7096, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 7097, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 7098, reward 1108.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 10, 6]\n",
      "episode 7099, reward 865.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [2, 20, 1]\n",
      "episode 7100, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 7101, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7102, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 4, 2]\n",
      "episode 7103, reward 1094.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7104, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 7105, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [1, 9, 5]\n",
      "episode 7106, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 7107, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [1, 0, 4]\n",
      "episode 7108, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7109, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 7110, reward 1240.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 7111, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [1, 0, 1]\n",
      "episode 7112, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 7113, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 127\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 7114, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 7115, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 115\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7116, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [2, 23, 0]\n",
      "episode 7117, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [3, 12, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7118, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 4, 1]\n",
      "episode 7119, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 7120, reward 750.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 127\n",
      "Initial State is  [4, 17, 1]\n",
      "episode 7121, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 135\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 7122, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [0, 6, 2]\n",
      "episode 7123, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [4, 18, 0]\n",
      "episode 7124, reward 831.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 7125, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 7126, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 126\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 7127, reward 636.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [1, 7, 0]\n",
      "episode 7128, reward 834.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 7129, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 7130, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 161\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7131, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 18, 6]\n",
      "episode 7132, reward 1035.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 6, 0]\n",
      "episode 7133, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [4, 0, 5]\n",
      "episode 7134, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [1, 17, 3]\n",
      "episode 7135, reward 1082.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 131\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 7136, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 7137, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 147\n",
      "Initial State is  [1, 19, 1]\n",
      "episode 7138, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7139, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 22, 0]\n",
      "episode 7140, reward 978.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 7141, reward 854.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 5, 4]\n",
      "episode 7142, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7143, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7144, reward 1210.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7145, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 7146, reward 1067.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 7147, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [2, 4, 1]\n",
      "episode 7148, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [2, 2, 5]\n",
      "episode 7149, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [1, 5, 2]\n",
      "episode 7150, reward 604.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 122\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 7151, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [1, 18, 6]\n",
      "episode 7152, reward 1136.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 19, 5]\n",
      "episode 7153, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [2, 3, 5]\n",
      "episode 7154, reward 675.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [4, 5, 3]\n",
      "episode 7155, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7156, reward 615.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 122\n",
      "Initial State is  [2, 3, 6]\n",
      "episode 7157, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 7158, reward 700.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7159, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7160, reward 1300.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 139\n",
      "Initial State is  [3, 4, 0]\n",
      "episode 7161, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 7162, reward 1204.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7163, reward 1195.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [0, 22, 1]\n",
      "episode 7164, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 7165, reward 993.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 7166, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 2, 3]\n",
      "episode 7167, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [3, 14, 5]\n",
      "episode 7168, reward 887.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [3, 8, 2]\n",
      "episode 7169, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 5, 6]\n",
      "episode 7170, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [2, 10, 4]\n",
      "episode 7171, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 130\n",
      "Initial State is  [2, 7, 4]\n",
      "episode 7172, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7173, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 7174, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7175, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 12, 6]\n",
      "episode 7176, reward 1138.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 138\n",
      "Initial State is  [2, 16, 1]\n",
      "episode 7177, reward 795.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 146\n",
      "Initial State is  [0, 2, 5]\n",
      "episode 7178, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7179, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [2, 1, 0]\n",
      "episode 7180, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 7181, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 7182, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [1, 23, 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7183, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7184, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 137\n",
      "Initial State is  [1, 17, 1]\n",
      "episode 7185, reward 1332.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [4, 0, 1]\n",
      "episode 7186, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 7187, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 20, 0]\n",
      "episode 7188, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 120\n",
      "Initial State is  [2, 19, 3]\n",
      "episode 7189, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 125\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7190, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7191, reward 869.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 133\n",
      "Initial State is  [0, 7, 0]\n",
      "episode 7192, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 128\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7193, reward 885.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 13, 3]\n",
      "episode 7194, reward 1181.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [1, 0, 0]\n",
      "episode 7195, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 10, 5]\n",
      "episode 7196, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 125\n",
      "Initial State is  [3, 13, 2]\n",
      "episode 7197, reward 677.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 7198, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 7199, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [0, 3, 2]\n",
      "episode 7200, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 122\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 7201, reward 1146.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7202, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7203, reward 1053.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 7204, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 7205, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [2, 9, 6]\n",
      "episode 7206, reward 1310.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7207, reward 1007.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7208, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7209, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [3, 21, 1]\n",
      "episode 7210, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [4, 6, 3]\n",
      "episode 7211, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 7212, reward 1075.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 163\n",
      "Initial State is  [2, 15, 4]\n",
      "episode 7213, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [3, 20, 0]\n",
      "episode 7214, reward 1040.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 7215, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 119\n",
      "Initial State is  [0, 22, 5]\n",
      "episode 7216, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [0, 4, 6]\n",
      "episode 7217, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [2, 12, 5]\n",
      "episode 7218, reward 748.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 7219, reward 859.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 0, 4]\n",
      "episode 7220, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 7221, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 7222, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 7223, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [2, 23, 4]\n",
      "episode 7224, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 3, 4]\n",
      "episode 7225, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [2, 15, 1]\n",
      "episode 7226, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7227, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 121\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7228, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [0, 13, 0]\n",
      "episode 7229, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [3, 12, 2]\n",
      "episode 7230, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 7231, reward 702.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [2, 16, 5]\n",
      "episode 7232, reward 661.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 12, 1]\n",
      "episode 7233, reward 808.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 7234, reward 754.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 7235, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 145\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 7236, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 123\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 7237, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7238, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [3, 1, 4]\n",
      "episode 7239, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 117\n",
      "Initial State is  [1, 15, 2]\n",
      "episode 7240, reward 672.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [3, 9, 4]\n",
      "episode 7241, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 7242, reward 828.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 124\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 7243, reward 557.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 113\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7244, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7245, reward 951.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 7246, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 119\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7247, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [2, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7248, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 14, 4]\n",
      "episode 7249, reward 843.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 7250, reward 1284.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 7251, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [2, 18, 1]\n",
      "episode 7252, reward 1227.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 124\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7253, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 7254, reward 895.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [0, 2, 0]\n",
      "episode 7255, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7256, reward 1155.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 3, 3]\n",
      "episode 7257, reward 1236.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 7258, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7259, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 6, 2]\n",
      "episode 7260, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 123\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7261, reward 717.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 118\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 7262, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 7263, reward 1085.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 116\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7264, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 7265, reward 1129.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 131\n",
      "Initial State is  [4, 10, 6]\n",
      "episode 7266, reward 742.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 3, 1]\n",
      "episode 7267, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 129\n",
      "Initial State is  [0, 12, 2]\n",
      "episode 7268, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 7269, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 148\n",
      "Initial State is  [0, 10, 4]\n",
      "episode 7270, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 7271, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [4, 15, 6]\n",
      "episode 7272, reward 1086.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 129\n",
      "Initial State is  [1, 7, 5]\n",
      "episode 7273, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7274, reward 1057.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 138\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7275, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 7276, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 147\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7277, reward 825.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 120\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 7278, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 7279, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7280, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [1, 8, 0]\n",
      "episode 7281, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 7282, reward 663.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [4, 0, 6]\n",
      "episode 7283, reward 1070.0, memory_length 2000, epsilon 0.00999597448249145, time 742.0, rides 149\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7284, reward 802.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [0, 12, 1]\n",
      "episode 7285, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7286, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 139\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 7287, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [0, 16, 0]\n",
      "episode 7288, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7289, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [1, 2, 4]\n",
      "episode 7290, reward 836.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 7291, reward 1234.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [0, 5, 5]\n",
      "episode 7292, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [4, 22, 0]\n",
      "episode 7293, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7294, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 7295, reward 1285.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [4, 0, 3]\n",
      "episode 7296, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 120\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 7297, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 21, 0]\n",
      "episode 7298, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 7299, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 122\n",
      "Initial State is  [1, 21, 1]\n",
      "episode 7300, reward 725.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [2, 16, 2]\n",
      "episode 7301, reward 1318.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 7302, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [4, 20, 5]\n",
      "episode 7303, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7304, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 7305, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 7306, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 7307, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 120\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 7308, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 7309, reward 1127.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 133\n",
      "Initial State is  [0, 21, 1]\n",
      "episode 7310, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [0, 14, 1]\n",
      "episode 7311, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 7312, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [2, 23, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7313, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 10, 6]\n",
      "episode 7314, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 7315, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7316, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7317, reward 1059.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 138\n",
      "Initial State is  [4, 21, 2]\n",
      "episode 7318, reward 693.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 133\n",
      "Initial State is  [2, 21, 4]\n",
      "episode 7319, reward 1260.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 8, 6]\n",
      "episode 7320, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 7321, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 7322, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7323, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 7324, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7325, reward 1034.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [2, 18, 6]\n",
      "episode 7326, reward 827.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 23, 6]\n",
      "episode 7327, reward 651.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 146\n",
      "Initial State is  [0, 5, 3]\n",
      "episode 7328, reward 1262.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 137\n",
      "Initial State is  [4, 19, 0]\n",
      "episode 7329, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 7330, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 16, 4]\n",
      "episode 7331, reward 1347.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 133\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 7332, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 130\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7333, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 141\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7334, reward 708.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 7335, reward 1069.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 7336, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 136\n",
      "Initial State is  [4, 8, 4]\n",
      "episode 7337, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [3, 18, 4]\n",
      "episode 7338, reward 1205.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 136\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 7339, reward 729.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [0, 15, 5]\n",
      "episode 7340, reward 797.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 125\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 7341, reward 896.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 139\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 7342, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 133\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 7343, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 7344, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [1, 18, 5]\n",
      "episode 7345, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [0, 12, 6]\n",
      "episode 7346, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 16, 5]\n",
      "episode 7347, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 139\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 7348, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [2, 22, 4]\n",
      "episode 7349, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 151\n",
      "Initial State is  [2, 22, 2]\n",
      "episode 7350, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 18, 1]\n",
      "episode 7351, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 144\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 7352, reward 826.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [3, 4, 6]\n",
      "episode 7353, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7354, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7355, reward 1029.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 157\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 7356, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 7357, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 15, 5]\n",
      "episode 7358, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 131\n",
      "Initial State is  [1, 1, 1]\n",
      "episode 7359, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [0, 2, 6]\n",
      "episode 7360, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 7361, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 123\n",
      "Initial State is  [2, 18, 0]\n",
      "episode 7362, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 7363, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 122\n",
      "Initial State is  [4, 18, 2]\n",
      "episode 7364, reward 1280.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 140\n",
      "Initial State is  [1, 18, 4]\n",
      "episode 7365, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 136\n",
      "Initial State is  [3, 18, 5]\n",
      "episode 7366, reward 698.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 17, 6]\n",
      "episode 7367, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 144\n",
      "Initial State is  [0, 10, 2]\n",
      "episode 7368, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 7369, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 141\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 7370, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7371, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7372, reward 751.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [2, 11, 4]\n",
      "episode 7373, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 154\n",
      "Initial State is  [3, 11, 1]\n",
      "episode 7374, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 7375, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 128\n",
      "Initial State is  [1, 20, 3]\n",
      "episode 7376, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 21, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7377, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7378, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [3, 2, 0]\n",
      "episode 7379, reward 934.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [0, 5, 1]\n",
      "episode 7380, reward 1414.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [3, 19, 4]\n",
      "episode 7381, reward 902.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 16, 3]\n",
      "episode 7382, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7383, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 17, 0]\n",
      "episode 7384, reward 1054.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 12, 4]\n",
      "episode 7385, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 129\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7386, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 123\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7387, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 158\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 7388, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 7389, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [0, 5, 0]\n",
      "episode 7390, reward 1211.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 7391, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7392, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 122\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 7393, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 16, 2]\n",
      "episode 7394, reward 1309.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 145\n",
      "Initial State is  [4, 6, 5]\n",
      "episode 7395, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [3, 1, 5]\n",
      "episode 7396, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 21, 1]\n",
      "episode 7397, reward 1096.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 122\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 7398, reward 875.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 7399, reward 810.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 136\n",
      "Initial State is  [3, 23, 3]\n",
      "episode 7400, reward 1077.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 141\n",
      "Initial State is  [4, 10, 2]\n",
      "episode 7401, reward 732.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 138\n",
      "Initial State is  [3, 17, 3]\n",
      "episode 7402, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [2, 14, 1]\n",
      "episode 7403, reward 864.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 7404, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 7405, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7406, reward 942.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 128\n",
      "Initial State is  [4, 10, 0]\n",
      "episode 7407, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 135\n",
      "Initial State is  [3, 2, 2]\n",
      "episode 7408, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [4, 10, 1]\n",
      "episode 7409, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 131\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7410, reward 666.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [1, 3, 2]\n",
      "episode 7411, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 126\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 7412, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [1, 16, 0]\n",
      "episode 7413, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 7414, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [0, 7, 5]\n",
      "episode 7415, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 131\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7416, reward 815.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [3, 8, 4]\n",
      "episode 7417, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [2, 1, 5]\n",
      "episode 7418, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 1, 2]\n",
      "episode 7419, reward 1215.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [4, 0, 2]\n",
      "episode 7420, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7421, reward 710.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 143\n",
      "Initial State is  [2, 8, 5]\n",
      "episode 7422, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 140\n",
      "Initial State is  [4, 21, 0]\n",
      "episode 7423, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 7424, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [0, 19, 0]\n",
      "episode 7425, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [3, 6, 1]\n",
      "episode 7426, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7427, reward 907.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 7428, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 141\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 7429, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 7430, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 134\n",
      "Initial State is  [4, 9, 3]\n",
      "episode 7431, reward 939.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 120\n",
      "Initial State is  [3, 13, 3]\n",
      "episode 7432, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 139\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7433, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [3, 16, 3]\n",
      "episode 7434, reward 838.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 135\n",
      "Initial State is  [2, 9, 4]\n",
      "episode 7435, reward 774.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7436, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 129\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7437, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 7438, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 7439, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7440, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 143\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 7441, reward 576.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 9, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7442, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7443, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 7444, reward 676.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 5, 0]\n",
      "episode 7445, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [1, 11, 3]\n",
      "episode 7446, reward 646.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 12, 4]\n",
      "episode 7447, reward 883.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 125\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7448, reward 889.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7449, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 127\n",
      "Initial State is  [1, 21, 6]\n",
      "episode 7450, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7451, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 122\n",
      "Initial State is  [2, 21, 1]\n",
      "episode 7452, reward 690.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 125\n",
      "Initial State is  [2, 10, 3]\n",
      "episode 7453, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 130\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7454, reward 1386.0, memory_length 2000, epsilon 0.00999597448249145, time 741.0, rides 130\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 7455, reward 639.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 123\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 7456, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 128\n",
      "Initial State is  [1, 9, 4]\n",
      "episode 7457, reward 689.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [4, 3, 0]\n",
      "episode 7458, reward 610.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [1, 5, 6]\n",
      "episode 7459, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 7460, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 132\n",
      "Initial State is  [1, 10, 5]\n",
      "episode 7461, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 124\n",
      "Initial State is  [1, 6, 5]\n",
      "episode 7462, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 131\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 7463, reward 950.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 146\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 7464, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 125\n",
      "Initial State is  [3, 6, 0]\n",
      "episode 7465, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 134\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 7466, reward 670.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 7467, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [0, 18, 2]\n",
      "episode 7468, reward 736.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 135\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7469, reward 1046.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 7470, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 131\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7471, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 7472, reward 704.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [4, 15, 1]\n",
      "episode 7473, reward 891.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 142\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7474, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [2, 13, 0]\n",
      "episode 7475, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 123\n",
      "Initial State is  [2, 22, 5]\n",
      "episode 7476, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 7477, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7478, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7479, reward 1140.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [0, 17, 5]\n",
      "episode 7480, reward 882.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 127\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 7481, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 142\n",
      "Initial State is  [1, 12, 2]\n",
      "episode 7482, reward 600.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [1, 5, 0]\n",
      "episode 7483, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 16, 4]\n",
      "episode 7484, reward 1238.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 1, 5]\n",
      "episode 7485, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 136\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 7486, reward 1092.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 4, 2]\n",
      "episode 7487, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 120\n",
      "Initial State is  [0, 23, 6]\n",
      "episode 7488, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 125\n",
      "Initial State is  [0, 6, 6]\n",
      "episode 7489, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 7490, reward 794.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 118\n",
      "Initial State is  [0, 11, 4]\n",
      "episode 7491, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 7492, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 129\n",
      "Initial State is  [4, 19, 6]\n",
      "episode 7493, reward 1125.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 134\n",
      "Initial State is  [4, 9, 4]\n",
      "episode 7494, reward 1246.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 126\n",
      "Initial State is  [3, 23, 1]\n",
      "episode 7495, reward 1018.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 7496, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 128\n",
      "Initial State is  [0, 22, 2]\n",
      "episode 7497, reward 937.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [0, 20, 6]\n",
      "episode 7498, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 7499, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 134\n",
      "Initial State is  [4, 16, 1]\n",
      "episode 7500, reward 707.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 141\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 7501, reward 1025.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 117\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 7502, reward 867.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 134\n",
      "Initial State is  [4, 13, 6]\n",
      "episode 7503, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 14, 3]\n",
      "episode 7504, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [4, 8, 6]\n",
      "episode 7505, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 142\n",
      "Initial State is  [2, 17, 6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7506, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 121\n",
      "Initial State is  [1, 15, 4]\n",
      "episode 7507, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 144\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7508, reward 652.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7509, reward 1273.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 23, 2]\n",
      "episode 7510, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [3, 18, 3]\n",
      "episode 7511, reward 1044.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 132\n",
      "Initial State is  [0, 8, 4]\n",
      "episode 7512, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 11, 1]\n",
      "episode 7513, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [2, 1, 1]\n",
      "episode 7514, reward 967.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 121\n",
      "Initial State is  [1, 3, 6]\n",
      "episode 7515, reward 941.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 128\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7516, reward 738.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [0, 13, 4]\n",
      "episode 7517, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 146\n",
      "Initial State is  [0, 17, 6]\n",
      "episode 7518, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 124\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7519, reward 485.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [3, 20, 2]\n",
      "episode 7520, reward 927.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [3, 11, 5]\n",
      "episode 7521, reward 1103.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 143\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 7522, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7523, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [0, 11, 2]\n",
      "episode 7524, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 16, 0]\n",
      "episode 7525, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 124\n",
      "Initial State is  [1, 2, 6]\n",
      "episode 7526, reward 805.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 7527, reward 1116.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 7528, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 137\n",
      "Initial State is  [2, 17, 1]\n",
      "episode 7529, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 139\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 7530, reward 948.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 7531, reward 1001.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7532, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 142\n",
      "Initial State is  [4, 19, 4]\n",
      "episode 7533, reward 903.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7534, reward 761.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [2, 18, 5]\n",
      "episode 7535, reward 1315.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 20, 2]\n",
      "episode 7536, reward 976.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 117\n",
      "Initial State is  [4, 23, 5]\n",
      "episode 7537, reward 765.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 150\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7538, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7539, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 16, 3]\n",
      "episode 7540, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 136\n",
      "Initial State is  [3, 3, 4]\n",
      "episode 7541, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [3, 13, 1]\n",
      "episode 7542, reward 1109.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [3, 19, 0]\n",
      "episode 7543, reward 841.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7544, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 120\n",
      "Initial State is  [1, 2, 3]\n",
      "episode 7545, reward 1117.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7546, reward 721.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 4, 0]\n",
      "episode 7547, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 8, 0]\n",
      "episode 7548, reward 926.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [3, 0, 0]\n",
      "episode 7549, reward 777.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [0, 3, 0]\n",
      "episode 7550, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 0, 0]\n",
      "episode 7551, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 7552, reward 1010.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 147\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 7553, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7554, reward 1128.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 7555, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 138\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 7556, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [3, 9, 3]\n",
      "episode 7557, reward 1141.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 7558, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 131\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 7559, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 7560, reward 938.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 120\n",
      "Initial State is  [3, 9, 5]\n",
      "episode 7561, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 144\n",
      "Initial State is  [1, 22, 1]\n",
      "episode 7562, reward 1190.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7563, reward 1179.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 130\n",
      "Initial State is  [4, 22, 5]\n",
      "episode 7564, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [1, 2, 5]\n",
      "episode 7565, reward 1143.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [1, 13, 4]\n",
      "episode 7566, reward 1266.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 136\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7567, reward 1281.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [2, 7, 2]\n",
      "episode 7568, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 7569, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 7570, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [2, 15, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7571, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [3, 15, 5]\n",
      "episode 7572, reward 1222.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [1, 12, 1]\n",
      "episode 7573, reward 1254.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 150\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7574, reward 632.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 7575, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 127\n",
      "Initial State is  [3, 19, 1]\n",
      "episode 7576, reward 898.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 20, 0]\n",
      "episode 7577, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [3, 13, 4]\n",
      "episode 7578, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 150\n",
      "Initial State is  [2, 9, 2]\n",
      "episode 7579, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 9, 0]\n",
      "episode 7580, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7581, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 147\n",
      "Initial State is  [4, 22, 4]\n",
      "episode 7582, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [0, 19, 6]\n",
      "episode 7583, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 150\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7584, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 120\n",
      "Initial State is  [1, 4, 3]\n",
      "episode 7585, reward 706.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 132\n",
      "Initial State is  [2, 0, 1]\n",
      "episode 7586, reward 943.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 116\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7587, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 7588, reward 727.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7589, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7590, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 133\n",
      "Initial State is  [0, 22, 6]\n",
      "episode 7591, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 151\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7592, reward 1006.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 151\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7593, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 22, 4]\n",
      "episode 7594, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [1, 0, 2]\n",
      "episode 7595, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [1, 18, 2]\n",
      "episode 7596, reward 880.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [0, 7, 1]\n",
      "episode 7597, reward 1060.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [0, 6, 5]\n",
      "episode 7598, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7599, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 140\n",
      "Initial State is  [4, 2, 2]\n",
      "episode 7600, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 145\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 7601, reward 653.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 7602, reward 840.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7603, reward 580.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7604, reward 1021.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 125\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 7605, reward 985.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [2, 23, 3]\n",
      "episode 7606, reward 1031.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 124\n",
      "Initial State is  [1, 6, 6]\n",
      "episode 7607, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 124\n",
      "Initial State is  [1, 11, 1]\n",
      "episode 7608, reward 1253.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [1, 21, 3]\n",
      "episode 7609, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 144\n",
      "Initial State is  [0, 8, 0]\n",
      "episode 7610, reward 1130.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 12, 1]\n",
      "episode 7611, reward 945.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [4, 7, 3]\n",
      "episode 7612, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 6, 1]\n",
      "episode 7613, reward 1264.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 19, 3]\n",
      "episode 7614, reward 785.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 146\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7615, reward 1187.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 141\n",
      "Initial State is  [2, 13, 5]\n",
      "episode 7616, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7617, reward 628.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [2, 2, 1]\n",
      "episode 7618, reward 1293.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 146\n",
      "Initial State is  [1, 4, 5]\n",
      "episode 7619, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [0, 20, 3]\n",
      "episode 7620, reward 944.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 7621, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 155\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 7622, reward 847.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 145\n",
      "Initial State is  [1, 21, 2]\n",
      "episode 7623, reward 830.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 123\n",
      "Initial State is  [0, 0, 4]\n",
      "episode 7624, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [4, 8, 5]\n",
      "episode 7625, reward 1157.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [0, 5, 2]\n",
      "episode 7626, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 141\n",
      "Initial State is  [4, 3, 3]\n",
      "episode 7627, reward 900.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7628, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 7629, reward 1233.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [4, 18, 1]\n",
      "episode 7630, reward 687.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7631, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 135\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7632, reward 1174.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 135\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 7633, reward 1072.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 133\n",
      "Initial State is  [3, 7, 6]\n",
      "episode 7634, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 6, 2]\n",
      "episode 7635, reward 916.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [0, 23, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7636, reward 1243.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [3, 1, 2]\n",
      "episode 7637, reward 1048.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7638, reward 1152.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 142\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 7639, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [2, 6, 4]\n",
      "episode 7640, reward 1002.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7641, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7642, reward 814.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 129\n",
      "Initial State is  [4, 23, 0]\n",
      "episode 7643, reward 1149.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 126\n",
      "Initial State is  [4, 2, 6]\n",
      "episode 7644, reward 1132.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 127\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 7645, reward 1091.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 7646, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7647, reward 965.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [1, 22, 6]\n",
      "episode 7648, reward 1183.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [3, 22, 2]\n",
      "episode 7649, reward 747.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 130\n",
      "Initial State is  [3, 4, 2]\n",
      "episode 7650, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [3, 22, 0]\n",
      "episode 7651, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 132\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 7652, reward 1192.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [4, 18, 3]\n",
      "episode 7653, reward 781.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 4, 5]\n",
      "episode 7654, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 131\n",
      "Initial State is  [0, 16, 4]\n",
      "episode 7655, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 7656, reward 997.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 136\n",
      "Initial State is  [2, 10, 6]\n",
      "episode 7657, reward 669.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 119\n",
      "Initial State is  [0, 0, 5]\n",
      "episode 7658, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 3, 6]\n",
      "episode 7659, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [4, 14, 6]\n",
      "episode 7660, reward 1352.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 7661, reward 759.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [3, 19, 6]\n",
      "episode 7662, reward 679.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [4, 17, 6]\n",
      "episode 7663, reward 995.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 7664, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 145\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 7665, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 7666, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 143\n",
      "Initial State is  [1, 9, 6]\n",
      "episode 7667, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7668, reward 878.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 17, 0]\n",
      "episode 7669, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 143\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7670, reward 1015.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 142\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7671, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7672, reward 801.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 138\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7673, reward 1090.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [4, 10, 3]\n",
      "episode 7674, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 140\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7675, reward 720.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [0, 11, 6]\n",
      "episode 7676, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 2, 1]\n",
      "episode 7677, reward 947.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 139\n",
      "Initial State is  [2, 21, 0]\n",
      "episode 7678, reward 877.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 140\n",
      "Initial State is  [4, 1, 2]\n",
      "episode 7679, reward 863.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 144\n",
      "Initial State is  [2, 3, 3]\n",
      "episode 7680, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 136\n",
      "Initial State is  [2, 9, 5]\n",
      "episode 7681, reward 982.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [1, 11, 6]\n",
      "episode 7682, reward 956.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 121\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7683, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 7684, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 129\n",
      "Initial State is  [0, 6, 3]\n",
      "episode 7685, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [2, 14, 5]\n",
      "episode 7686, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 146\n",
      "Initial State is  [0, 19, 2]\n",
      "episode 7687, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 126\n",
      "Initial State is  [1, 9, 2]\n",
      "episode 7688, reward 757.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [1, 11, 4]\n",
      "episode 7689, reward 835.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7690, reward 1164.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [1, 16, 4]\n",
      "episode 7691, reward 1323.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 125\n",
      "Initial State is  [4, 9, 5]\n",
      "episode 7692, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [2, 20, 0]\n",
      "episode 7693, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7694, reward 772.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 137\n",
      "Initial State is  [2, 11, 3]\n",
      "episode 7695, reward 1003.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [2, 19, 6]\n",
      "episode 7696, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 7697, reward 932.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [0, 13, 1]\n",
      "episode 7698, reward 1201.0, memory_length 2000, epsilon 0.00999597448249145, time 740.0, rides 125\n",
      "Initial State is  [0, 23, 3]\n",
      "episode 7699, reward 739.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [2, 16, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7700, reward 1217.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 143\n",
      "Initial State is  [3, 15, 0]\n",
      "episode 7701, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 146\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 7702, reward 973.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 113\n",
      "Initial State is  [0, 17, 1]\n",
      "episode 7703, reward 852.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 142\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 7704, reward 726.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 138\n",
      "Initial State is  [4, 9, 0]\n",
      "episode 7705, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 7706, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 136\n",
      "Initial State is  [2, 0, 4]\n",
      "episode 7707, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 7708, reward 809.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 144\n",
      "Initial State is  [0, 4, 5]\n",
      "episode 7709, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [1, 9, 3]\n",
      "episode 7710, reward 955.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 7711, reward 876.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 126\n",
      "Initial State is  [4, 17, 2]\n",
      "episode 7712, reward 849.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [3, 19, 5]\n",
      "episode 7713, reward 756.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [0, 11, 0]\n",
      "episode 7714, reward 718.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [2, 13, 6]\n",
      "episode 7715, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 137\n",
      "Initial State is  [4, 14, 3]\n",
      "episode 7716, reward 905.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 146\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 7717, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 165\n",
      "Initial State is  [2, 2, 3]\n",
      "episode 7718, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 23, 5]\n",
      "episode 7719, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 148\n",
      "Initial State is  [3, 5, 4]\n",
      "episode 7720, reward 1093.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 151\n",
      "Initial State is  [2, 23, 6]\n",
      "episode 7721, reward 1343.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7722, reward 1191.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 148\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7723, reward 958.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [4, 4, 4]\n",
      "episode 7724, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 149\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7725, reward 1071.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7726, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 139\n",
      "Initial State is  [1, 23, 1]\n",
      "episode 7727, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 144\n",
      "Initial State is  [0, 18, 5]\n",
      "episode 7728, reward 771.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 133\n",
      "Initial State is  [3, 5, 2]\n",
      "episode 7729, reward 1433.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 149\n",
      "Initial State is  [3, 4, 1]\n",
      "episode 7730, reward 911.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 136\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 7731, reward 1161.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 127\n",
      "Initial State is  [4, 23, 4]\n",
      "episode 7732, reward 1113.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 7733, reward 820.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 7734, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 145\n",
      "Initial State is  [4, 7, 0]\n",
      "episode 7735, reward 873.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 140\n",
      "Initial State is  [0, 12, 0]\n",
      "episode 7736, reward 1102.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 14, 0]\n",
      "episode 7737, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 0, 2]\n",
      "episode 7738, reward 775.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [2, 8, 6]\n",
      "episode 7739, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 135\n",
      "Initial State is  [2, 2, 0]\n",
      "episode 7740, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [4, 15, 5]\n",
      "episode 7741, reward 1173.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 8, 5]\n",
      "episode 7742, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7743, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 136\n",
      "Initial State is  [1, 4, 6]\n",
      "episode 7744, reward 1206.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 149\n",
      "Initial State is  [0, 4, 1]\n",
      "episode 7745, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 18, 4]\n",
      "episode 7746, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 142\n",
      "Initial State is  [3, 0, 4]\n",
      "episode 7747, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [4, 2, 5]\n",
      "episode 7748, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [4, 5, 0]\n",
      "episode 7749, reward 1047.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 129\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 7750, reward 994.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 6, 1]\n",
      "episode 7751, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 131\n",
      "Initial State is  [2, 6, 0]\n",
      "episode 7752, reward 983.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 10, 3]\n",
      "episode 7753, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [0, 19, 4]\n",
      "episode 7754, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 124\n",
      "Initial State is  [2, 22, 6]\n",
      "episode 7755, reward 1251.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 143\n",
      "Initial State is  [0, 1, 0]\n",
      "episode 7756, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 148\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7757, reward 1182.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 8, 6]\n",
      "episode 7758, reward 897.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 143\n",
      "Initial State is  [3, 11, 4]\n",
      "episode 7759, reward 1145.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 134\n",
      "Initial State is  [0, 6, 0]\n",
      "episode 7760, reward 870.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 6, 4]\n",
      "episode 7761, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 12, 3]\n",
      "episode 7762, reward 1081.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 127\n",
      "Initial State is  [4, 1, 4]\n",
      "episode 7763, reward 935.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [2, 21, 3]\n",
      "episode 7764, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 145\n",
      "Initial State is  [3, 7, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7765, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 121\n",
      "Initial State is  [0, 19, 3]\n",
      "episode 7766, reward 1220.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 132\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 7767, reward 912.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [4, 7, 4]\n",
      "episode 7768, reward 1079.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 134\n",
      "Initial State is  [0, 22, 4]\n",
      "episode 7769, reward 806.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 122\n",
      "Initial State is  [4, 6, 6]\n",
      "episode 7770, reward 1106.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [1, 23, 0]\n",
      "episode 7771, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [2, 4, 4]\n",
      "episode 7772, reward 971.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 132\n",
      "Initial State is  [1, 22, 3]\n",
      "episode 7773, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [2, 9, 1]\n",
      "episode 7774, reward 595.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 148\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7775, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 137\n",
      "Initial State is  [3, 23, 4]\n",
      "episode 7776, reward 1247.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 145\n",
      "Initial State is  [4, 10, 4]\n",
      "episode 7777, reward 1013.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [2, 6, 3]\n",
      "episode 7778, reward 812.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 118\n",
      "Initial State is  [0, 20, 5]\n",
      "episode 7779, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 126\n",
      "Initial State is  [0, 10, 0]\n",
      "episode 7780, reward 861.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [2, 8, 4]\n",
      "episode 7781, reward 719.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [2, 17, 2]\n",
      "episode 7782, reward 1083.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [0, 1, 6]\n",
      "episode 7783, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [2, 0, 3]\n",
      "episode 7784, reward 1176.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 127\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7785, reward 766.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 144\n",
      "Initial State is  [2, 5, 5]\n",
      "episode 7786, reward 1115.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [3, 21, 5]\n",
      "episode 7787, reward 931.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 131\n",
      "Initial State is  [4, 20, 4]\n",
      "episode 7788, reward 974.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [3, 8, 5]\n",
      "episode 7789, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 20, 5]\n",
      "episode 7790, reward 1068.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 123\n",
      "Initial State is  [3, 12, 6]\n",
      "episode 7791, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 123\n",
      "Initial State is  [0, 17, 0]\n",
      "episode 7792, reward 1337.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 142\n",
      "Initial State is  [2, 8, 2]\n",
      "episode 7793, reward 964.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [1, 13, 5]\n",
      "episode 7794, reward 855.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 127\n",
      "Initial State is  [3, 16, 6]\n",
      "episode 7795, reward 910.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 143\n",
      "Initial State is  [0, 10, 6]\n",
      "episode 7796, reward 1169.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 130\n",
      "Initial State is  [2, 2, 4]\n",
      "episode 7797, reward 858.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 121\n",
      "Initial State is  [2, 13, 3]\n",
      "episode 7798, reward 1178.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 145\n",
      "Initial State is  [4, 18, 6]\n",
      "episode 7799, reward 816.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7800, reward 888.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 126\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7801, reward 988.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 128\n",
      "Initial State is  [2, 7, 6]\n",
      "episode 7802, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 116\n",
      "Initial State is  [4, 13, 2]\n",
      "episode 7803, reward 1088.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [0, 9, 0]\n",
      "episode 7804, reward 879.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [4, 4, 2]\n",
      "episode 7805, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 21, 6]\n",
      "episode 7806, reward 813.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 139\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 7807, reward 1150.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 14, 1]\n",
      "episode 7808, reward 1099.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 137\n",
      "Initial State is  [1, 17, 0]\n",
      "episode 7809, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 124\n",
      "Initial State is  [1, 13, 1]\n",
      "episode 7810, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [1, 20, 5]\n",
      "episode 7811, reward 1177.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 7812, reward 919.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 7813, reward 1089.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [1, 13, 6]\n",
      "episode 7814, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [2, 2, 2]\n",
      "episode 7815, reward 1539.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7816, reward 737.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [4, 21, 4]\n",
      "episode 7817, reward 1098.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7818, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 139\n",
      "Initial State is  [0, 4, 4]\n",
      "episode 7819, reward 846.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 123\n",
      "Initial State is  [1, 23, 3]\n",
      "episode 7820, reward 804.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 124\n",
      "Initial State is  [4, 21, 3]\n",
      "episode 7821, reward 1122.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 122\n",
      "Initial State is  [4, 19, 3]\n",
      "episode 7822, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7823, reward 979.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 132\n",
      "Initial State is  [2, 3, 0]\n",
      "episode 7824, reward 868.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7825, reward 975.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7826, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 136\n",
      "Initial State is  [4, 19, 5]\n",
      "episode 7827, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [4, 12, 3]\n",
      "episode 7828, reward 1084.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 138\n",
      "Initial State is  [3, 18, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7829, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 133\n",
      "Initial State is  [4, 18, 4]\n",
      "episode 7830, reward 1049.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 135\n",
      "Initial State is  [0, 7, 4]\n",
      "episode 7831, reward 1073.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 122\n",
      "Initial State is  [1, 8, 1]\n",
      "episode 7832, reward 998.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 7833, reward 959.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 7834, reward 990.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 141\n",
      "Initial State is  [2, 7, 0]\n",
      "episode 7835, reward 789.0, memory_length 2000, epsilon 0.00999597448249145, time 747.0, rides 126\n",
      "Initial State is  [0, 0, 6]\n",
      "episode 7836, reward 925.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 12, 3]\n",
      "episode 7837, reward 1078.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [0, 9, 1]\n",
      "episode 7838, reward 1111.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 140\n",
      "Initial State is  [3, 6, 3]\n",
      "episode 7839, reward 844.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 131\n",
      "Initial State is  [3, 5, 5]\n",
      "episode 7840, reward 1087.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [0, 0, 2]\n",
      "episode 7841, reward 1208.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [1, 6, 2]\n",
      "episode 7842, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 137\n",
      "Initial State is  [4, 23, 1]\n",
      "episode 7843, reward 617.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 140\n",
      "Initial State is  [0, 16, 3]\n",
      "episode 7844, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [1, 14, 0]\n",
      "episode 7845, reward 1014.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 127\n",
      "Initial State is  [3, 3, 6]\n",
      "episode 7846, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 129\n",
      "Initial State is  [1, 10, 0]\n",
      "episode 7847, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 141\n",
      "Initial State is  [0, 21, 5]\n",
      "episode 7848, reward 769.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [2, 17, 3]\n",
      "episode 7849, reward 1105.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 133\n",
      "Initial State is  [2, 5, 4]\n",
      "episode 7850, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 141\n",
      "Initial State is  [0, 15, 2]\n",
      "episode 7851, reward 1126.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 133\n",
      "Initial State is  [1, 21, 5]\n",
      "episode 7852, reward 1100.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 139\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7853, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 134\n",
      "Initial State is  [3, 3, 0]\n",
      "episode 7854, reward 940.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 141\n",
      "Initial State is  [3, 7, 1]\n",
      "episode 7855, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 143\n",
      "Initial State is  [1, 20, 2]\n",
      "episode 7856, reward 722.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 127\n",
      "Initial State is  [3, 23, 5]\n",
      "episode 7857, reward 961.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [4, 19, 2]\n",
      "episode 7858, reward 627.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [4, 15, 2]\n",
      "episode 7859, reward 928.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 138\n",
      "Initial State is  [3, 1, 3]\n",
      "episode 7860, reward 1207.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [3, 1, 6]\n",
      "episode 7861, reward 1168.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 138\n",
      "Initial State is  [4, 4, 3]\n",
      "episode 7862, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 132\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 7863, reward 968.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 22, 5]\n",
      "episode 7864, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 147\n",
      "Initial State is  [3, 7, 4]\n",
      "episode 7865, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [2, 12, 2]\n",
      "episode 7866, reward 1045.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [2, 12, 6]\n",
      "episode 7867, reward 1213.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 121\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 7868, reward 1051.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [3, 0, 6]\n",
      "episode 7869, reward 1121.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [4, 20, 3]\n",
      "episode 7870, reward 1020.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 7871, reward 1026.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 141\n",
      "Initial State is  [2, 5, 1]\n",
      "episode 7872, reward 1160.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 134\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 7873, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [0, 8, 1]\n",
      "episode 7874, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 126\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7875, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 135\n",
      "Initial State is  [0, 4, 3]\n",
      "episode 7876, reward 1030.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [0, 18, 0]\n",
      "episode 7877, reward 1064.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 135\n",
      "Initial State is  [2, 21, 6]\n",
      "episode 7878, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 7879, reward 949.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [4, 9, 1]\n",
      "episode 7880, reward 1050.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 132\n",
      "Initial State is  [2, 4, 3]\n",
      "episode 7881, reward 884.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 133\n",
      "Initial State is  [4, 14, 5]\n",
      "episode 7882, reward 991.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [0, 21, 2]\n",
      "episode 7883, reward 963.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [4, 15, 0]\n",
      "episode 7884, reward 922.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 112\n",
      "Initial State is  [3, 10, 1]\n",
      "episode 7885, reward 901.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 128\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 7886, reward 1163.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 135\n",
      "Initial State is  [4, 5, 2]\n",
      "episode 7887, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 137\n",
      "Initial State is  [1, 5, 5]\n",
      "episode 7888, reward 909.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [3, 11, 3]\n",
      "episode 7889, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 734.0, rides 130\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7890, reward 915.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 127\n",
      "Initial State is  [3, 7, 5]\n",
      "episode 7891, reward 1107.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 128\n",
      "Initial State is  [0, 19, 5]\n",
      "episode 7892, reward 1058.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 137\n",
      "Initial State is  [4, 0, 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7893, reward 913.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 128\n",
      "Initial State is  [1, 1, 3]\n",
      "episode 7894, reward 823.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 135\n",
      "Initial State is  [0, 9, 5]\n",
      "episode 7895, reward 1005.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [1, 5, 3]\n",
      "episode 7896, reward 1016.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 4, 0]\n",
      "episode 7897, reward 1230.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 148\n",
      "Initial State is  [0, 9, 6]\n",
      "episode 7898, reward 850.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 131\n",
      "Initial State is  [4, 11, 5]\n",
      "episode 7899, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 136\n",
      "Initial State is  [3, 0, 3]\n",
      "episode 7900, reward 906.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [3, 22, 4]\n",
      "episode 7901, reward 829.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 133\n",
      "Initial State is  [1, 22, 0]\n",
      "episode 7902, reward 1224.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [2, 8, 0]\n",
      "episode 7903, reward 1042.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 138\n",
      "Initial State is  [4, 17, 5]\n",
      "episode 7904, reward 923.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 21, 6]\n",
      "episode 7905, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 131\n",
      "Initial State is  [3, 17, 2]\n",
      "episode 7906, reward 792.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 132\n",
      "Initial State is  [1, 7, 4]\n",
      "episode 7907, reward 894.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 139\n",
      "Initial State is  [3, 6, 6]\n",
      "episode 7908, reward 1074.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 130\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 7909, reward 790.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [0, 8, 2]\n",
      "episode 7910, reward 1135.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 134\n",
      "Initial State is  [2, 23, 1]\n",
      "episode 7911, reward 1153.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 133\n",
      "Initial State is  [1, 1, 6]\n",
      "episode 7912, reward 984.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 147\n",
      "Initial State is  [4, 6, 4]\n",
      "episode 7913, reward 1198.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 142\n",
      "Initial State is  [0, 3, 4]\n",
      "episode 7914, reward 1170.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 132\n",
      "Initial State is  [3, 0, 5]\n",
      "episode 7915, reward 1197.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7916, reward 1012.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 134\n",
      "Initial State is  [1, 12, 3]\n",
      "episode 7917, reward 1123.0, memory_length 2000, epsilon 0.00999597448249145, time 736.0, rides 122\n",
      "Initial State is  [1, 13, 0]\n",
      "episode 7918, reward 1019.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 124\n",
      "Initial State is  [0, 11, 5]\n",
      "episode 7919, reward 1275.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [3, 23, 0]\n",
      "episode 7920, reward 924.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 130\n",
      "Initial State is  [1, 23, 2]\n",
      "episode 7921, reward 1188.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 126\n",
      "Initial State is  [3, 15, 1]\n",
      "episode 7922, reward 1011.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 128\n",
      "Initial State is  [3, 3, 3]\n",
      "episode 7923, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n",
      "Initial State is  [1, 15, 6]\n",
      "episode 7924, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [3, 20, 1]\n",
      "episode 7925, reward 1118.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 130\n",
      "Initial State is  [3, 10, 2]\n",
      "episode 7926, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 744.0, rides 129\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 7927, reward 1076.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 140\n",
      "Initial State is  [2, 4, 6]\n",
      "episode 7928, reward 1244.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 135\n",
      "Initial State is  [0, 2, 2]\n",
      "episode 7929, reward 1154.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 138\n",
      "Initial State is  [4, 17, 4]\n",
      "episode 7930, reward 921.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 125\n",
      "Initial State is  [0, 1, 3]\n",
      "episode 7931, reward 515.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 119\n",
      "Initial State is  [1, 3, 5]\n",
      "episode 7932, reward 770.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 131\n",
      "Initial State is  [1, 10, 2]\n",
      "episode 7933, reward 996.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 142\n",
      "Initial State is  [3, 4, 3]\n",
      "episode 7934, reward 987.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 137\n",
      "Initial State is  [3, 11, 2]\n",
      "episode 7935, reward 904.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 137\n",
      "Initial State is  [3, 12, 5]\n",
      "episode 7936, reward 712.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 137\n",
      "Initial State is  [2, 2, 6]\n",
      "episode 7937, reward 1033.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 123\n",
      "Initial State is  [4, 13, 4]\n",
      "episode 7938, reward 1189.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 134\n",
      "Initial State is  [4, 7, 5]\n",
      "episode 7939, reward 1095.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 136\n",
      "Initial State is  [1, 19, 6]\n",
      "episode 7940, reward 1036.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [0, 0, 3]\n",
      "episode 7941, reward 800.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 122\n",
      "Initial State is  [0, 19, 1]\n",
      "episode 7942, reward 822.0, memory_length 2000, epsilon 0.00999597448249145, time 738.0, rides 136\n",
      "Initial State is  [0, 2, 4]\n",
      "episode 7943, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 4, 4]\n",
      "episode 7944, reward 796.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 124\n",
      "Initial State is  [1, 0, 3]\n",
      "episode 7945, reward 1196.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 139\n",
      "Initial State is  [0, 16, 1]\n",
      "episode 7946, reward 1065.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [0, 23, 0]\n",
      "episode 7947, reward 699.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 127\n",
      "Initial State is  [0, 23, 5]\n",
      "episode 7948, reward 554.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 124\n",
      "Initial State is  [1, 6, 3]\n",
      "episode 7949, reward 914.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 142\n",
      "Initial State is  [1, 7, 3]\n",
      "episode 7950, reward 1008.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [3, 22, 1]\n",
      "episode 7951, reward 908.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 129\n",
      "Initial State is  [0, 13, 6]\n",
      "episode 7952, reward 1112.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 130\n",
      "Initial State is  [4, 12, 5]\n",
      "episode 7953, reward 1165.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [4, 5, 4]\n",
      "episode 7954, reward 1022.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 132\n",
      "Initial State is  [3, 23, 6]\n",
      "episode 7955, reward 872.0, memory_length 2000, epsilon 0.00999597448249145, time 732.0, rides 134\n",
      "Initial State is  [1, 16, 6]\n",
      "episode 7956, reward 786.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 129\n",
      "Initial State is  [3, 1, 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 7957, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 130\n",
      "Initial State is  [4, 11, 3]\n",
      "episode 7958, reward 787.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 139\n",
      "Initial State is  [2, 16, 6]\n",
      "episode 7959, reward 1063.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 125\n",
      "Initial State is  [0, 16, 6]\n",
      "episode 7960, reward 842.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 129\n",
      "Initial State is  [0, 15, 6]\n",
      "episode 7961, reward 1147.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 140\n",
      "Initial State is  [2, 11, 2]\n",
      "episode 7962, reward 1017.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 137\n",
      "Initial State is  [1, 7, 6]\n",
      "episode 7963, reward 946.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 136\n",
      "Initial State is  [1, 17, 6]\n",
      "episode 7964, reward 936.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 128\n",
      "Initial State is  [1, 1, 2]\n",
      "episode 7965, reward 871.0, memory_length 2000, epsilon 0.00999597448249145, time 735.0, rides 133\n",
      "Initial State is  [2, 9, 0]\n",
      "episode 7966, reward 957.0, memory_length 2000, epsilon 0.00999597448249145, time 721.0, rides 123\n",
      "Initial State is  [4, 13, 5]\n",
      "episode 7967, reward 1024.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 131\n",
      "Initial State is  [0, 21, 3]\n",
      "episode 7968, reward 986.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 127\n",
      "Initial State is  [1, 14, 6]\n",
      "episode 7969, reward 929.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 138\n",
      "Initial State is  [0, 7, 3]\n",
      "episode 7970, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 139\n",
      "Initial State is  [2, 7, 5]\n",
      "episode 7971, reward 1167.0, memory_length 2000, epsilon 0.00999597448249145, time 720.0, rides 140\n",
      "Initial State is  [2, 17, 5]\n",
      "episode 7972, reward 728.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 130\n",
      "Initial State is  [2, 1, 4]\n",
      "episode 7973, reward 621.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [1, 14, 3]\n",
      "episode 7974, reward 1000.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 134\n",
      "Initial State is  [0, 10, 5]\n",
      "episode 7975, reward 788.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 129\n",
      "Initial State is  [3, 12, 1]\n",
      "episode 7976, reward 1028.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 15, 5]\n",
      "episode 7977, reward 992.0, memory_length 2000, epsilon 0.00999597448249145, time 733.0, rides 127\n",
      "Initial State is  [4, 10, 5]\n",
      "episode 7978, reward 1237.0, memory_length 2000, epsilon 0.00999597448249145, time 724.0, rides 136\n",
      "Initial State is  [4, 8, 2]\n",
      "episode 7979, reward 811.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 126\n",
      "Initial State is  [1, 2, 0]\n",
      "episode 7980, reward 780.0, memory_length 2000, epsilon 0.00999597448249145, time 725.0, rides 129\n",
      "Initial State is  [0, 10, 1]\n",
      "episode 7981, reward 1004.0, memory_length 2000, epsilon 0.00999597448249145, time 737.0, rides 127\n",
      "Initial State is  [4, 16, 6]\n",
      "episode 7982, reward 980.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 134\n",
      "Initial State is  [3, 8, 0]\n",
      "episode 7983, reward 743.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 128\n",
      "Initial State is  [1, 17, 4]\n",
      "episode 7984, reward 886.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 121\n",
      "Initial State is  [0, 17, 3]\n",
      "episode 7985, reward 860.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 140\n",
      "Initial State is  [2, 3, 2]\n",
      "episode 7986, reward 953.0, memory_length 2000, epsilon 0.00999597448249145, time 726.0, rides 132\n",
      "Initial State is  [0, 21, 4]\n",
      "episode 7987, reward 839.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 129\n",
      "Initial State is  [1, 11, 2]\n",
      "episode 7988, reward 969.0, memory_length 2000, epsilon 0.00999597448249145, time 731.0, rides 139\n",
      "Initial State is  [2, 4, 0]\n",
      "episode 7989, reward 1023.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 135\n",
      "Initial State is  [1, 22, 2]\n",
      "episode 7990, reward 989.0, memory_length 2000, epsilon 0.00999597448249145, time 722.0, rides 128\n",
      "Initial State is  [4, 12, 2]\n",
      "episode 7991, reward 981.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 147\n",
      "Initial State is  [3, 14, 2]\n",
      "episode 7992, reward 890.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 140\n",
      "Initial State is  [3, 3, 1]\n",
      "episode 7993, reward 1151.0, memory_length 2000, epsilon 0.00999597448249145, time 729.0, rides 145\n",
      "Initial State is  [1, 15, 3]\n",
      "episode 7994, reward 1043.0, memory_length 2000, epsilon 0.00999597448249145, time 739.0, rides 142\n",
      "Initial State is  [2, 7, 1]\n",
      "episode 7995, reward 851.0, memory_length 2000, epsilon 0.00999597448249145, time 723.0, rides 125\n",
      "Initial State is  [3, 22, 6]\n",
      "episode 7996, reward 952.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 131\n",
      "Initial State is  [0, 16, 5]\n",
      "episode 7997, reward 752.0, memory_length 2000, epsilon 0.00999597448249145, time 727.0, rides 128\n",
      "Initial State is  [4, 22, 2]\n",
      "episode 7998, reward 893.0, memory_length 2000, epsilon 0.00999597448249145, time 730.0, rides 120\n",
      "Initial State is  [2, 13, 1]\n",
      "episode 7999, reward 933.0, memory_length 2000, epsilon 0.00999597448249145, time 728.0, rides 133\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(36,21)\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    # Call all the initialised variables of the environment\n",
    "    state_space = env.state_space\n",
    "    action_space = env.action_space\n",
    "    state = env.state_init\n",
    "    print(\"Initial State is \",state)\n",
    "    time = 0\n",
    "    #Call the DQN agent\n",
    "    terminal_state = False\n",
    "    score = 0\n",
    "    action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "    score += env.reward_func(state,action_space[action],Time_matrix)\n",
    "    next_state,ride_time = env.next_state_func(state,action_space[action],Time_matrix)\n",
    "    time += ride_time\n",
    "    if time >= 24*30:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),True)\n",
    "    else:\n",
    "        agent.append_sample(env.state_encod_arch1(state),action,score,env.state_encod_arch1(next_state),False)\n",
    "    loop = 0\n",
    "    \n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        \n",
    "        if time >= 24*30:\n",
    "            terminal_state = True\n",
    "            pass\n",
    "        state = next_state\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        action = agent.get_action(env.state_encod_arch1(state),env)\n",
    "        # 2. Evaluate your reward and next state\n",
    "        reward_curr_ride = env.reward_func(state,action_space[action],Time_matrix)\n",
    "        score+= reward_curr_ride\n",
    "        next_state,ride_time = env.next_state_func(next_state,action_space[action],Time_matrix)\n",
    "        time += ride_time\n",
    "        # 3. Append the experience to the memory\n",
    "        if time >= 24*30:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),True)\n",
    "        else:\n",
    "            agent.append_sample(env.state_encod_arch1(state),action,reward_curr_ride,env.state_encod_arch1(next_state),False)\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model(env)\n",
    "        #print('Time elapsed {} and current loop {}'.format(time,loop))\n",
    "        loop+= 1\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "    \n",
    "    rewards_per_episode.append(score)   \n",
    "    episodes.append(episode)\n",
    "    \n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}, time {4}, rides {5}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon,time,loop))\n",
    "    # every few episodes:\n",
    "    if episode % 1000 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "\n",
    "        # save model weights\n",
    "        agent.save(name=\"model_weights.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        -5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        26.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -3.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        14.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -17.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        15.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        -19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        14.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -21.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        14.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        25.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        15.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        27.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        15.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        -12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        8,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        44.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        40.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        44.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        21.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        -7.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        7.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        3.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -6.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        15.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -22.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        -19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        32.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -10.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        5.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        44.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -23.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        17.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -14.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        9.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        -5.0,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        35.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -21.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        21.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        18.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        11.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -5.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        44.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        31.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -17.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -9.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        -4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        9.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        10.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        9.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        12,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        9.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        22.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        18.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        12.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        44.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        7,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        -2.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        17.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        19.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -21.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        18.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        27.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        27.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        11.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        -8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        -6.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -31.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        -7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -15.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        25.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        -14.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        35.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        19.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -17.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -26.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        -39.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        13,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        11,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        4,\n",
       "        17.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        31.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        -10.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        20.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -11.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        13,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        -27.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        -26.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        9,\n",
       "        -8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        27.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        40.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        36.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        14,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        12.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        7.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        16.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        8.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        4.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        11.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        7.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        10,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        14.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        -22.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        3,\n",
       "        -3.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        10,\n",
       "        -8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        28.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        18,\n",
       "        0.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        -6.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        22.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        20.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        4.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        -12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        0.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        9,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        4,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        19,\n",
       "        0.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        11,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        17,\n",
       "        2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        7,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        6,\n",
       "        32.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        20.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        8,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        11,\n",
       "        26.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        10.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        30.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -5.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        -11.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        -3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        True),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        True),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        19.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        28.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        18.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        20.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        27.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        12,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        10,\n",
       "        23.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        7,\n",
       "        4.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -13.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        28.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        7,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        16,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        16.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        24.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        18,\n",
       "        -27.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        8.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        1,\n",
       "        8.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        16,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        35.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        8.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -1.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        15,\n",
       "        -3.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        24.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        12.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        -3.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        3,\n",
       "        32.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        6,\n",
       "        -6.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        19,\n",
       "        -2.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "               0., 0.]),\n",
       "        13,\n",
       "        -12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        5,\n",
       "        3.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        16.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "               0., 0.]),\n",
       "        4,\n",
       "        24.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        9,\n",
       "        15.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        32.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "               0., 0.]),\n",
       "        16,\n",
       "        1.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        18,\n",
       "        4.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        6,\n",
       "        36.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        12,\n",
       "        0.0,\n",
       "        array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        3,\n",
       "        16.0,\n",
       "        array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0.]),\n",
       "        5,\n",
       "        6.0,\n",
       "        array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -6.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        5,\n",
       "        -2.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 1.]),\n",
       "        15,\n",
       "        -7.0,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        -1.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        1,\n",
       "        36.0,\n",
       "        array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        17,\n",
       "        12.0,\n",
       "        array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        2,\n",
       "        24.0,\n",
       "        array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       (array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        0,\n",
       "        -5,\n",
       "        array([0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "               0., 0.]),\n",
       "        False),\n",
       "       ...])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x231a2f3e4a8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episodes,rewards_per_episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above graph shows that the rewards increased and stabilised after 4000 epochs as given by the epsilon function at the end of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon2=[]\n",
    "for i in range(0,10000):\n",
    "    if i==0:\n",
    "        epsilon2.append(1)\n",
    "    else:\n",
    "        epsilon2.append(0.9991 * epsilon2[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above epsilon graph shows epsilon decaying and stabilizing after 4000 epochs as required by the previous epsilon decay graph. This epsilon decay rate has been used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
